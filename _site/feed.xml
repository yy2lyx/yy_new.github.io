<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2026-01-12T23:21:42+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">凡人炼丹传</title><subtitle>欢迎各位看官光临本小站，希望共同学习进步哈！</subtitle><author><name>李小肥的YY</name></author><entry><title type="html">大模型基于检索增强的微调-RAFT</title><link href="http://localhost:4000/raft.html" rel="alternate" type="text/html" title="大模型基于检索增强的微调-RAFT" /><published>2025-11-27T08:00:00+08:00</published><updated>2025-11-27T08:00:00+08:00</updated><id>http://localhost:4000/raft</id><content type="html" xml:base="http://localhost:4000/raft.html"><![CDATA[<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3>

<blockquote>
  <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p>
  <h4 id="11-raft的优势">1.1 RAFT的优势</h4>
  <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p>
</blockquote>

<ol>
  <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li>
  <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li>
  <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势：
    <ul>
      <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li>
      <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li>
    </ul>
  </li>
</ol>

<p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。
<img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p>

<h4 id="12-raft如何训练">1.2 RAFT如何训练</h4>
<p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p>

<ul>
  <li>训练的内容分为2块：
    <ul>
      <li>找到核心依据：QA对 + 标准答案的文档 + 多个误导的文档 + 思维链</li>
      <li>正确的例子：QA对 + 标准答案的文档 + 思维链</li>
    </ul>
  </li>
  <li>训练的核心：通过思维链来解释找到的答案，从而基于上下文信息，思考其答案，并链接到相关文档。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft_train.png" alt="raft_train" /></p>
<h3 id="二-基于unsloth和lamma_index来实现faft">二. 基于unsloth和lamma_index来实现FAFT</h3>
<h4 id="21-基于ollama和lamma_index来构建数据集">2.1 基于ollama和lamma_index来构建数据集</h4>

<p>RAFT的数据集的特点是：</p>
<ul>
  <li>QA对</li>
  <li>正确文档</li>
  <li>错误文档</li>
  <li>思维链</li>
</ul>

<p>所以我们需要一个能够提供思维链的大模型，帮助我们生成上述这些内容。</p>
<ul>
  <li>模型：Qwen3-32B，选择这个千问模型是因为中文很友好+支持思维链+阿里的预训练的数据很顶</li>
  <li>调用框架：ollama，调用比如openai需要花钱，这个本地部署，调用不花钱！</li>
</ul>

<h4 id="22-安装相关依赖">2.2 安装相关依赖</h4>
<p>这里需要使用以下几个深度学习相关的框架：</p>
<ul>
  <li>lamma_index: 和langchain感觉很像，只是这个更加偏重于增强大型语言模型 (LLM) 处理广泛和异构数据集的能力。当然也能帮助我们构建raft数据集咯。</li>
  <li>unsloth: 大模型训练的框架</li>
</ul>

<p>依赖：</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llama_index
llama-index-packs-raft-dataset
llama-index-llms-ollama
llama-index-embeddings-ollama
llama-index-packs-rag-evaluator
unsloth
</code></pre></div></div>
<h4 id="23-构建raft数据集">2.3 构建raft数据集</h4>
<p>我这边选择了法律相关的文书作为文档，然后结合lamma_index来向大模型提问，进而生成训练所需的问题和答案以及思维链。</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">llama_index.packs.raft_dataset</span> <span class="kn">import</span> <span class="n">RAFTDatasetPack</span>
<span class="kn">from</span> <span class="n">llama_index.llms.ollama</span> <span class="kn">import</span> <span class="n">Ollama</span>
<span class="kn">from</span> <span class="n">llama_index.embeddings.ollama</span> <span class="kn">import</span> <span class="n">OllamaEmbedding</span>

<span class="k">def</span> <span class="nf">gen_qa_raft_dataset</span><span class="p">():</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="nc">Ollama</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">qwen3:32b</span><span class="sh">"</span><span class="p">,</span> <span class="n">request_timeout</span><span class="o">=</span><span class="mf">60.0</span><span class="p">)</span>

    <span class="n">embed_model</span> <span class="o">=</span> <span class="nc">OllamaEmbedding</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="sh">"</span><span class="s">modelscope.cn/yingda/gte-Qwen2-1.5B-instruct-GGUF:latest</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">sub_dir</span> <span class="o">=</span> <span class="sh">'</span><span class="s">data/laws/</span><span class="sh">'</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">sub_dir</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">sub_dir</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
        <span class="n">raft_dataset</span> <span class="o">=</span> <span class="nc">RAFTDatasetPack</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span>
                                       <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
                                       <span class="n">embed_model</span><span class="o">=</span><span class="n">embed_model</span><span class="p">,</span>
                                       <span class="n">num_questions_per_chunk</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                       <span class="n">num_distract_docs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                       <span class="n">chunk_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">raft_dataset</span><span class="p">.</span><span class="nf">run</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">to_pandas</span><span class="p">()</span>
        <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">messages</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[{</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">instruction</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s">role</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">user</span><span class="sh">'</span><span class="p">},</span>
                                               <span class="p">{</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">cot_answer</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s">role</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">assistant</span><span class="sh">'</span><span class="p">}],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">df_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="n">df_all</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_pandas</span><span class="p">(</span><span class="n">df_all</span><span class="p">)</span>

    <span class="n">dataset</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">data/法律文书_raft_dataset.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p>然后我们可以打开看下结果，会发现包含了一下列：</p>
<ul>
  <li>question：大模型生成的问题</li>
  <li>context：多个文档（这里就是raft中的正确文档+误导文档）</li>
  <li>cot_answer: 思维链答案</li>
  <li>instruction: 多个文档 + 问题</li>
  <li>message: 完整的基于rag的问答对</li>
</ul>

<h4 id="24-基于lora的sft">2.4 基于lora的sft</h4>
<ol>
  <li>加载上述存储的dataset
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">data/法律文书_raft_dataset.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_pandas</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>构建dataset的template</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span><span class="p">.</span><span class="n">chat_template</span> <span class="o">=</span> <span class="n">DEFAULT_CHAT_TEMPLATE</span>
<span class="n">SYSTEM_PROMPT</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">你是一位很有能力的问题解答者，能够根据问题和相关背景提供答案。</span><span class="sh">"""</span>
<span class="k">def</span> <span class="nf">apply_chat_template</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="sh">"</span><span class="s">messages</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="n">messages</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="nf">eval</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
    <span class="c1"># We add an empty system message if there is none
</span>    <span class="k">if</span> <span class="n">messages</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">messages</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">SYSTEM_PROMPT</span><span class="p">})</span>
    <span class="n">example</span><span class="p">[</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">example</span>
<span class="n">column_names</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">features</span><span class="p">)</span>
<span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">apply_chat_template</span><span class="p">,</span>
                                <span class="n">num_proc</span><span class="o">=</span><span class="nf">cpu_count</span><span class="p">(),</span>
                                <span class="n">fn_kwargs</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">tokenizer</span><span class="sh">"</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">},</span>
                                <span class="n">remove_columns</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
                                <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Applying chat template</span><span class="sh">"</span><span class="p">,)</span>
<span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># create the splits
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">]</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div>

<ol>
  <li>加载模型</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 加载模型 - 使用Unsloth的FastLanguageModel加载预训练的Qwen3-8B模型
</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Qwen/Qwen3-0.6B</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># 模型路径
</span>    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float16</span><span class="p">,</span>  <span class="c1"># 使用float16数据类型以减少内存占用
</span>    <span class="n">max_seq_length</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>  <span class="c1"># 设置最大序列长度为2048
</span>    <span class="n">load_in_4bit</span><span class="o">=</span><span class="bp">False</span>  <span class="c1"># 使用4位量化加载模型，进一步减少显存占用
</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="p">.</span><span class="nf">get_peft_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>           <span class="c1"># Choose any number &gt; 0! Suggested 8, 16, 32, 64, 128
</span>    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">q_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">k_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">v_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">o_proj</span><span class="sh">"</span><span class="p">,</span>
                      <span class="sh">"</span><span class="s">gate_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">up_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">down_proj</span><span class="sh">"</span><span class="p">,],</span>
    <span class="n">lora_alpha</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>  <span class="c1"># Best to choose alpha = rank or rank*2
</span>    <span class="n">lora_dropout</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Supports any, but = 0 is optimized
</span>    <span class="n">bias</span> <span class="o">=</span> <span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>    <span class="c1"># Supports any, but = "none" is optimized
</span>    <span class="c1"># [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
</span>    <span class="n">use_gradient_checkpointing</span> <span class="o">=</span> <span class="sh">"</span><span class="s">unsloth</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># True or "unsloth" for very long context
</span>    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>
    <span class="n">use_rslora</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>   <span class="c1"># We support rank stabilized LoRA
</span>    <span class="n">loftq_config</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>  <span class="c1"># And LoftQ
</span><span class="p">)</span>
</code></pre></div></div>

<ol>
  <li>训练</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="nc">SFTTrainer</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="p">,</span>
    <span class="n">args</span> <span class="o">=</span> <span class="nc">SFTConfig</span><span class="p">(</span>
        <span class="n">dataset_text_field</span> <span class="o">=</span> <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="c1"># Use GA to mimic batch size!
</span>        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="c1"># num_train_epochs = 1, # Set this for 1 full training run.
</span>        <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-4</span><span class="p">,</span> <span class="c1"># Reduce to 2e-5 for long training runs
</span>        <span class="n">logging_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">optim</span> <span class="o">=</span> <span class="sh">"</span><span class="s">adamw_8bit</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Use this for WandB etc
</span>    <span class="p">),</span>
<span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token</span>
<span class="n">train_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="三-raft的总结">三. RAFT的总结</h3>
<p>RAFT和一般的SFT而言，其实本质上没有任何差别，只是说将RAG融合进了有监督微调中，从而达到一种让模型拥有更加准确筛选文档+使用特定领域类文档的能力。而在训练中增加误导的文档，更是能让模型达到一种思考和过滤无关信息的能力。</p>]]></content><author><name>李小肥的YY</name></author><category term="NLP" /><category term="深度学习" /><category term="LLM" /><summary type="html"><![CDATA[记录学习大模型的RAFT]]></summary></entry><entry><title type="html">大模型的检索增强-NanoGraphRAG</title><link href="http://localhost:4000/graphrag.html" rel="alternate" type="text/html" title="大模型的检索增强-NanoGraphRAG" /><published>2025-06-09T08:00:00+08:00</published><updated>2025-06-09T08:00:00+08:00</updated><id>http://localhost:4000/graphrag</id><content type="html" xml:base="http://localhost:4000/graphrag.html"><![CDATA[<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3>

<h4 id="11-什么是rag">1.1 什么是RAG</h4>
<blockquote>
  <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p>
</blockquote>

<p>大模型为什么需要RAG：</p>
<ul>
  <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li>
  <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li>
  <li>外挂知识需要长期实时维护更新的。</li>
</ul>

<h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4>
<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" />
如上图所示，整个RAG的过程分为三个部分：</p>
<ul>
  <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li>
  <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li>
  <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li>
</ul>

<h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4>
<blockquote>
  <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。
论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a></p>
</blockquote>

<p>GraphRAG比RAG优势在哪：</p>
<ul>
  <li>RAG过于局限：RAG仅能检索到与query相速度最高的文本片段，无法从全局出发来看整个本地文本。</li>
  <li>GraphRAG通过构建实体关系图谱实现了信息间的连接，能从全局出发，能更完整地理解和检索复杂的关联信息，从而生成更准确和全局性的结果。</li>
</ul>

<h4 id="14-graphrag的流程">1.4 GraphRAG的流程</h4>
<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/graphrag.png" alt="LangChain" />
如上图所示，就是GraphRAG的处理流程图，其实总结起来就两个部分：
第一部分：构建知识图谱</p>
<ul>
  <li>将本地文本进行分段</li>
  <li>对每个段落进行摘要提取：这里完全依赖于<strong>大模型的提取能力</strong></li>
  <li>实体和关系的提取：这里完全依赖于<strong>大模型的提取能力</strong>，实体和关系抽取可以参考本人之前写的《事件抽取实战》这篇文章</li>
  <li>构建知识图谱，写入数据库</li>
</ul>

<p>第二部分：利用构建的知识图谱回答问题</p>
<ul>
  <li>社区检测：实际就是一种图聚类的方法，这里的“社区”，我们可以将其理解为一类具有相同特性的节点的集合。</li>
  <li>社区总结：给每个社区创建类似报告的摘要。利于理解整体的结构和语义。</li>
  <li>生成全局答案：给定用户查询，基于上一步生成的社区摘要可用于在多阶段过程中生成最终答案。</li>
</ul>

<h3 id="二-graphrag的轻量版本nano-graphrag">二. GraphRAG的轻量版本——nano-GraphRAG</h3>
<p>对于GraphRAG而言，其封装的太死，代码量又很大，对于定制化的任务而言，不太好下手，因此推荐一个轻量化的版本——nano-GraphRAG。</p>

<blockquote>
  <p>代码：https://github.com/gusye1234/nano-graphrag</p>
</blockquote>

<p>相较于GraphRAG的优势：</p>
<ul>
  <li>代码量少：包含了tests + prompt也才只有1100行代码！</li>
  <li>更容易阅读</li>
  <li>给的例子太好用了，直接上手没有难度。</li>
</ul>

<h4 id="21-安装">2.1 安装</h4>
<p>这里推荐不用官方推荐的pip install 来安装。因为这样会对于代码和prompt不好调整。
直接clone项目即可，然后安装其依赖<code class="language-plaintext highlighter-rouge">pip install -r requirements.txt</code></p>

<h4 id="22-基于ollama的nano-graphrag的三国例子">2.2 基于ollama的nano-GraphRAG的三国例子</h4>
<p>由于nano-Graphrag中的例子已经包含ollama形式的调用大模型的方式，因此开箱即用即可：</p>
<ol>
  <li>找到<code class="language-plaintext highlighter-rouge">examples/using_ollama_as_llm_and_embedding.py</code>，这里需要你更改embedding大模型和chat大模型，我这里选择了魔塔社区的embedding模型，注意由于我们使用的是ollama来本地启动大模型，因此需要选择的是GGUF格式的模型。
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MODEL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">deepseek-r1:8b</span><span class="sh">"</span>
<span class="n">EMBEDDING_MODEL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">modelscope.cn/yingda/gte-Qwen2-1.5B-instruct-GGUF:latest</span><span class="sh">"</span>
<span class="n">EMBEDDING_MODEL_DIM</span> <span class="o">=</span> <span class="mi">1536</span>
</code></pre></div>    </div>
  </li>
  <li>配置工程目录：
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">WORKING_DIR</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/LLM/nano-graphrag/three_kingdom_ds</span><span class="sh">"</span>
</code></pre></div>    </div>
  </li>
  <li>修改insert的文件地址：</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">/LLM/nano-graphrag/three_kingdom_ds/三国演义.txt</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">utf-8-sig</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</code></pre></div></div>
<ol>
  <li>使用ollama开启本地模型
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run deepseek-r1:8b
ollama run modelscope.cn/yingda/gte-Qwen2-1.5B-instruct-GGUF:latest
</code></pre></div>    </div>
  </li>
</ol>

<p>然后直接<code class="language-plaintext highlighter-rouge">python examples/using_ollama_as_llm_and_embedding.py</code>就会自动构建知识图谱 + 查询了。</p>

<h4 id="23-爬坑">2.3 爬坑</h4>
<p>之前本人已经实验过<code class="language-plaintext highlighter-rouge">qwen3:8b</code>,亲测会报错<code class="language-plaintext highlighter-rouge">leiden.EmptyNetworkError: EmptyNetworkError</code></p>

<p>然后解决方案有2种：</p>
<ul>
  <li>更换大模型，比如像上面使用<code class="language-plaintext highlighter-rouge">deepseek-r1:8b</code>或者<code class="language-plaintext highlighter-rouge">mistral:7b</code>都可以的</li>
  <li>更改prompt</li>
</ul>

<p>然后推荐测试的话，可以不用上来就用《三国演义》，不然可能跑了好几个小时，发现出现问题，那真的搞心态啊！</p>]]></content><author><name>李小肥的YY</name></author><category term="NLP" /><category term="深度学习" /><category term="LLM" /><summary type="html"><![CDATA[记录学习大模型的RAG]]></summary></entry><entry><title type="html">大模型的微调和推理加速</title><link href="http://localhost:4000/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html" rel="alternate" type="text/html" title="大模型的微调和推理加速" /><published>2025-05-27T08:00:00+08:00</published><updated>2025-05-27T08:00:00+08:00</updated><id>http://localhost:4000/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F</id><content type="html" xml:base="http://localhost:4000/%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"><![CDATA[<h3 id="一-大模型微调">一. 大模型微调</h3>
<h4 id="11-微调的原因">1.1 微调的原因</h4>
<p>在业务中直接使用大模型，往往会发现：</p>
<ul>
  <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li>
  <li>本身能力不满足独有的业务需求</li>
  <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li>
</ul>

<h4 id="12-微调的方式">1.2 微调的方式</h4>
<ul>
  <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li>
  <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li>
  <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。
    <ul>
      <li>适用百亿参数以下的模型</li>
      <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li>
    </ul>
  </li>
  <li>更深层次的微调：
    <ul>
      <li>领域预训练：用无监督领域数据继续训练基座模型</li>
      <li>全参数精调：用有监督领域数据精调基座模型</li>
      <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li>
      <li>多智能体：多模型/agent共同完成任务。</li>
    </ul>
  </li>
</ul>

<h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3>
<blockquote>
  <p>git地址：https://github.com/unslothai/unsloth</p>
</blockquote>

<p>选择unsloth作为微调工具的理由：</p>
<ul>
  <li>训练更快</li>
  <li>显存占用更少</li>
  <li>迭代快，模型适配广，目前都能支持Qwen3了</li>
</ul>

<h4 id="21-依赖的安装">2.1 依赖的安装</h4>
<blockquote>
  <p>这里爬了不少坑，因此记录下</p>
</blockquote>

<ol>
  <li>直接pip安装：<code class="language-plaintext highlighter-rouge">pip install unsloth</code>, 这里会默认安装最新的torch版本，而非适配于自身系统cuda版本的torch（用<code class="language-plaintext highlighter-rouge">nvcc -V</code>可查看cuda版本）</li>
  <li>重新安装torch，本人这里cuda是12.1的：<code class="language-plaintext highlighter-rouge">pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121</code></li>
  <li>重新安装对应cuda版本的xformers：<code class="language-plaintext highlighter-rouge">pip install -U xformers --index-url https://download.pytorch.org/whl/cu121</code></li>
  <li>如果需要微调Qwen3，那么对于transformers有版本要求：<code class="language-plaintext highlighter-rouge">pip install transformers==4.51.0 --no-deps</code></li>
  <li>改了transformers之后，那么也需要对应的trl版本更改：<code class="language-plaintext highlighter-rouge">pip install trl==0.17.0 --no-deps</code></li>
  <li>安装vllm:<code class="language-plaintext highlighter-rouge">pip install vllm==0.7 --no-deps</code></li>
  <li>这里会遇到unsloth和vllm版本不匹配的问题：<code class="language-plaintext highlighter-rouge">No module named vllm.lora.peft_helper</code>,简单的处理方案就是到<code class="language-plaintext highlighter-rouge">site-packages/unsloth_zoo/vllm_lora_worker_manager.py</code>文件中注释掉所有的和<code class="language-plaintext highlighter-rouge">PEFTHelper</code>相关的行即可。</li>
  <li>如果出现<code class="language-plaintext highlighter-rouge">No platform detected, vLLM is running on UnspecifiedPlatform</code>，这里只需要安装<code class="language-plaintext highlighter-rouge">pip install  pynvml==12.0</code>即可。</li>
</ol>

<h4 id="22-微调的例子">2.2 微调的例子</h4>
<p>这里推荐使用官方的基于Qwen3的微调例子：https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb</p>

<p>当然在上述微调的例子中，也存了坑，就在训练模型过程中：</p>
<ul>
  <li>对于高版本的trl而言，参数从<code class="language-plaintext highlighter-rouge">tokenizer</code>变成了<code class="language-plaintext highlighter-rouge">processing_class</code></li>
  <li>如果不指定data_collator的话，会出现padding相关的bug。</li>
</ul>

<p>下面的代码是修复之后的</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 配置训练参数 - 使用SFTTrainer进行监督微调
</span><span class="n">trainer</span> <span class="o">=</span> <span class="nc">SFTTrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>  <span class="c1"># 要训练的模型
</span>    <span class="n">processing_class</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>  <span class="c1"># 分词器
</span>    <span class="n">train_dataset</span><span class="o">=</span><span class="n">combined_dataset</span><span class="p">,</span>  <span class="c1"># 训练数据集
</span>    <span class="n">data_collator</span><span class="o">=</span><span class="nc">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="n">mlm</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="c1"># 定义data_collator，一定是这个不然会报错
</span>    <span class="c1"># max_seq_length=1024,  # 训练时使用的最大序列长度
</span>    <span class="n">args</span><span class="o">=</span><span class="nc">SFTConfig</span><span class="p">(</span>  <span class="c1"># SFT配置参数
</span>        <span class="n">dataset_num_proc</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
        <span class="n">dataset_text_field</span><span class="o">=</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># 数据集中文本字段的名称
</span>        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># 每个设备的训练批次大小
</span>        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="c1"># 梯度累积步数，用于模拟更大的批次大小
</span>        <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># 学习率预热步数
</span>        <span class="c1"># num_train_epochs = 2,  # 训练轮数，这里注释掉了，使用max_steps代替
</span>        <span class="n">max_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c1"># 最大训练步数
</span>        <span class="n">max_seq_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>  <span class="c1"># 学习率，对于长时间训练可以降低到2e-5
</span>        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># 日志记录间隔步数
</span>        <span class="n">optim</span><span class="o">=</span><span class="sh">"</span><span class="s">adamw_8bit</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># 优化器，使用8位AdamW
</span>        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>  <span class="c1"># 权重衰减率
</span>        <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># 学习率调度器类型
</span>        <span class="n">seed</span><span class="o">=</span><span class="mi">3407</span><span class="p">,</span>  <span class="c1"># 随机种子
</span>        <span class="n">report_to</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># 报告工具，可以设置为"wandb"等
</span>    <span class="p">),</span>
<span class="p">)</span>

</code></pre></div></div>

<h3 id="三-推理加速">三. 推理加速</h3>
<p>对于训练完成后的模型，我们需要选择一个合适的加速推理的框架来加速大模型的推理。</p>

<h4 id="31-常用框架">3.1 常用框架</h4>
<p>常用的推理加速框架：</p>
<ul>
  <li>LLM-tensorRT：在TensorRT推理引擎基础上，针对大模型的推理优化框架</li>
  <li>vllm：通过PagedAttention高效地管理attention中缓存的张量</li>
  <li>LLMdeploy：LMDeploy 开发了 Persistent Batch(即 Continuous Batch)，Blocked K/V Cache，动态拆分和融合，张量并行，高效的计算 kernel等重要特性。推理性能是 vLLM 的 1.8 倍</li>
  <li>llama.cpp：针对C/C++的加速推理框架</li>
</ul>

<h4 id="32-vllm的使用">3.2 vLLM的使用</h4>
<p>对于企业级的<strong>服务以及高并发</strong>场景，vLLM会更加适合。</p>

<p>安装：<code class="language-plaintext highlighter-rouge">pip install vllm --extra-index-url https://download.pytorch.org/whl/cu121</code></p>

<p>以下是两种构建服务的方式：</p>
<ul>
  <li>第一种：使用<code class="language-plaintext highlighter-rouge">vllm.entrypoints.openai.api_server</code>，适用curl调用</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> vllm.entrypoints.openai.api_server <span class="nt">--model</span> <span class="s2">"模型地址"</span> <span class="nt">--served-model-name</span> <span class="s2">"模型名字"</span> <span class="nt">--port</span> 8123 <span class="nt">--dtype</span><span class="o">=</span>half
</code></pre></div></div>

<ul>
  <li>第二种：使用<code class="language-plaintext highlighter-rouge">vllm serve</code>，适用于openai的方式调用apikey</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vllm serve <span class="s2">"模型地址"</span> <span class="nt">--tensor-parallel-size</span> 1 <span class="nt">--enforce-eager</span> <span class="nt">--port</span> 8124 <span class="nt">--dtype</span> float16 <span class="nt">--trust-remote-code</span> <span class="nt">--served-model-name</span> 模型名字
</code></pre></div></div>
<p>然后可以使用openai来调用vllm启动模型的接口</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="c1"># Set OpenAI's API key and API base to use vLLM's API server.
</span><span class="n">openai_api_key</span> <span class="o">=</span> <span class="sh">"</span><span class="s">EMPTY</span><span class="sh">"</span>
<span class="n">openai_api_base</span> <span class="o">=</span> <span class="sh">"</span><span class="s">http://localhost:8123/v1</span><span class="sh">"</span>

<span class="n">client</span> <span class="o">=</span> <span class="nc">OpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
    <span class="n">base_url</span><span class="o">=</span><span class="n">openai_api_base</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">chat_response</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
    <span class="c1"># model="Qwen/Qwen3-8B",
</span>    <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">模型名字</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">Give me a short introduction to large language models.</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="c1"># max_tokens=32768,
</span>    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">top_k</span><span class="sh">"</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Chat response:</span><span class="sh">"</span><span class="p">,</span> <span class="n">chat_response</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>李小肥的YY</name></author><category term="NLP" /><category term="深度学习" /><category term="LLM" /><summary type="html"><![CDATA[记录学习大模型的微调和推理加速]]></summary></entry><entry><title type="html">Taskflow 使用小结</title><link href="http://localhost:4000/taskflow.html" rel="alternate" type="text/html" title="Taskflow 使用小结" /><published>2025-04-07T08:00:00+08:00</published><updated>2025-04-07T08:00:00+08:00</updated><id>http://localhost:4000/taskflow</id><content type="html" xml:base="http://localhost:4000/taskflow.html"><![CDATA[<h3 id="一-taskflow的优势和完整的工作流">一. TaskFlow的优势和完整的工作流</h3>
<p>TaskFlow是OpenStack开源的Python库，他的优势：</p>

<ul>
  <li>可伸缩</li>
  <li>简单创建任务级对象</li>
  <li>任务可插拔</li>
  <li>支持回滚容错机制</li>
</ul>

<p>api的文档参考：https://docs.openstack.org/taskflow/ocata/</p>

<p>一个完整的taskflow包含了一下几个环节：</p>

<ul>
  <li>创建task</li>
  <li>声明flow</li>
  <li>构建engine</li>
</ul>

<h4 id="11-构建task">1.1 构建task</h4>

<p>构建task的方式是继承task类，然后修改其excute方法，这里可以指定任务的返回结果为res，注意还可以改写revert函数来重定义回滚的操作。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">task</span>
<span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>
  	<span class="n">default_provides</span> <span class="o">=</span> <span class="sh">'</span><span class="s">res</span><span class="sh">'</span>  
    
    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">a</span>
      <span class="k">return</span> <span class="n">res</span>
    
    <span class="k">def</span> <span class="nf">revert</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
      <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">a执行失败。。。</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="12-构建flow">1.2 构建flow</h4>

<p>在构建完task之后，则是需要定义flow，一般的线性flow的定义如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">linear_flow</span> <span class="k">as</span> <span class="n">lf</span>

<span class="n">flow</span> <span class="o">=</span> <span class="n">lf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">main</span><span class="sh">'</span><span class="p">).</span><span class="nf">add</span><span class="p">(</span>
        <span class="nc">Task1</span><span class="p">(),</span>
    <span class="p">)</span>
</code></pre></div></div>

<h4 id="13-定义engine">1.3 定义engine</h4>

<p>需要定义一个engine来运行整个工作流，用于task的执行、停止、继续和恢复。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">engines</span>

<span class="n">engine</span> <span class="o">=</span> <span class="n">engines</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">flow</span><span class="p">)</span>
<span class="n">engine</span><span class="p">.</span><span class="nf">run</span><span class="p">()</span>

<span class="c1"># 拿到所有的结果
</span><span class="n">context</span> <span class="o">=</span> <span class="n">engine</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">fetch_all</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="二-工作流形式">二. 工作流形式</h3>

<p>taskflow的工作流组合形式分为3种：</p>

<ul>
  <li>串行工作流</li>
  <li>并行工作流</li>
  <li>图流</li>
</ul>

<h4 id="21-串行工作流linear_flow">2.1 串行工作流——linear_flow</h4>
<p>顾名思义，就是多个工作流利用串行的方式将多个flow拼接在一起，然后依次顺序执行，每个flow依赖于他的前一个的flow。</p>

<pre><code class="language-mermaid">graph LR
  A[taskA]:::highlight --&gt; B[TaskB]
  B[TaskB] --&gt; C[TaskC]
</code></pre>

<p>注意：这里在构建串行的工作流后，我们可以选择engine时候，选择<code class="language-plaintext highlighter-rouge">engine='serial'</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">linear_flow</span> <span class="k">as</span> <span class="n">lf</span>
<span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">engines</span>

<span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">task A</span><span class="sh">'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">TaskB</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">task B</span><span class="sh">'</span><span class="p">)</span>

<span class="n">flow</span> <span class="o">=</span> <span class="n">lf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">merge_ab</span><span class="sh">'</span><span class="p">).</span><span class="nf">add</span><span class="p">(</span>
  			<span class="nc">TaskA</span><span class="p">(),</span>
  			<span class="nc">TaskB</span><span class="p">())</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">engines</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="sh">'</span><span class="s">serial</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="22-并行工作流unordered_flow">2.2 并行工作流——unordered_flow</h4>

<p>多个工作流可以被指定为并行执行，python里面的多线程一样，谁先抢到资源谁就先执行，等到三个都执行完毕了，这个流就结束了。</p>

<pre><code class="language-mermaid">graph LR
  A[taskA]:::highlight 
  B[TaskB]
  C[TaskB] 
</code></pre>

<p>注意：这里在构建并行的工作流后，我们可以选择engine时候，选择<code class="language-plaintext highlighter-rouge">engine='parallel'</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">unordered_flow</span> <span class="k">as</span> <span class="n">uf</span>
<span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">engines</span>

<span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">task A</span><span class="sh">'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">TaskB</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">task B</span><span class="sh">'</span><span class="p">)</span>

<span class="n">flow</span> <span class="o">=</span> <span class="n">uf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">merge_ab</span><span class="sh">'</span><span class="p">).</span><span class="nf">add</span><span class="p">(</span>
  			<span class="nc">TaskA</span><span class="p">(),</span>
  			<span class="nc">TaskB</span><span class="p">())</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">engines</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="sh">'</span><span class="s">parallel</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="23-图流graph_flow">2.3 图流——graph_flow</h4>

<p>对于两两有相关关联的工作流，比如图结构中的两个节点，两个节点之间有一条边（这里指代两节点有依赖关系），即taskA执行的时候需要taskB，而taskB执行的时候依赖了taskA。一般来说这种方式用的最少。</p>

<pre><code class="language-mermaid">graph TD
  A[taskA] &lt;--&gt; B[taskB]
</code></pre>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">task</span>
<span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">graph_flow</span> <span class="k">as</span> <span class="n">gf</span>
<span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">engines</span>


<span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TaskA executed</span><span class="sh">"</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TaskB</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">requires</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="sh">'</span><span class="s">data_a</span><span class="sh">'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data_a</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TaskB executed</span><span class="sh">"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">build_flow</span><span class="p">():</span>
    <span class="n">flow</span> <span class="o">=</span> <span class="n">gf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">demo_flow</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># 获取节点对象
</span>    <span class="n">a_node</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">TaskA</span><span class="p">())</span>
    <span class="n">b_node</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">TaskB</span><span class="p">())</span>

    <span class="c1"># 节点间建立依赖
</span>    <span class="n">a_node</span><span class="p">.</span><span class="nf">precede</span><span class="p">(</span><span class="n">b_node</span><span class="p">)</span>  <span class="c1"># 正确调用层级
</span>
    <span class="k">return</span> <span class="n">flow</span>


<span class="n">engines</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="nf">build_flow</span><span class="p">())</span>
</code></pre></div></div>

<h3 id="三-完整的项目的例子">三. 完整的项目的例子</h3>

<h4 id="31-串行和并行工作流混合">3.1 串行和并行工作流混合</h4>

<p>对于需要构建多个并行工作流得到多个各自的结果后，然后需要构建一个基于三者结果合并计算的工作流，那么这里可以构建串行和并行的混合工作流，如下所示</p>

<pre><code class="language-mermaid">graph LR
  A[taskA]:::highlight --&gt; D[taskD]
  B[TaskB]--&gt; D[taskD]
  C[TaskB] --&gt; D[taskD]
</code></pre>

<p>那么对于上述串并行混合的工作流而言，可以参考下面代码，其中包含了项目中可能用到的：</p>

<ul>
  <li>多线程并行运行</li>
  <li>多flow组合形式</li>
  <li>每个task结合了输入和输出</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">task</span>
<span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">unordered_flow</span> <span class="k">as</span> <span class="n">uf</span>
<span class="kn">from</span> <span class="n">taskflow.patterns</span> <span class="kn">import</span> <span class="n">linear_flow</span> <span class="k">as</span> <span class="n">lf</span>
<span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">engines</span>
<span class="kn">from</span> <span class="n">concurrent.futures.thread</span> <span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>

<span class="n">pool_executor</span> <span class="o">=</span> <span class="nc">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>


<span class="c1"># 定义并行任务类，继承 task.Task 并声明 provides
</span><span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
        <span class="n">res_a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">a</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">task a result:</span><span class="si">{</span><span class="n">res_a</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res_a</span>

<span class="k">class</span> <span class="nc">TaskB</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
        <span class="n">res_b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">b</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">task b result:</span><span class="si">{</span><span class="n">res_b</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res_b</span>

<span class="k">class</span> <span class="nc">TaskC</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">res_c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">task c result:</span><span class="si">{</span><span class="n">res_c</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res_c</span>

<span class="k">class</span> <span class="nc">FinalTask</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">res_a</span><span class="p">,</span> <span class="n">res_b</span><span class="p">,</span> <span class="n">res_c</span><span class="p">):</span>
        <span class="n">final_res</span> <span class="o">=</span> <span class="n">res_a</span> <span class="o">+</span> <span class="n">res_b</span> <span class="o">+</span> <span class="n">res_c</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">task final result:</span><span class="si">{</span><span class="n">final_res</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">final_res</span>

<span class="c1"># 创建主流程
</span><span class="k">def</span> <span class="nf">build_flow</span><span class="p">():</span>
    <span class="n">parallel_flow</span> <span class="o">=</span> <span class="n">uf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">parallel_tasks</span><span class="sh">'</span><span class="p">).</span><span class="nf">add</span><span class="p">(</span>
     <span class="nc">TaskA</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">taska</span><span class="sh">'</span><span class="p">,</span>
                    <span class="n">provides</span><span class="o">=</span><span class="sh">'</span><span class="s">res_a</span><span class="sh">'</span><span class="p">),</span>
            <span class="nc">TaskB</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">taskb</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">provides</span><span class="o">=</span><span class="sh">'</span><span class="s">res_b</span><span class="sh">'</span><span class="p">),</span>
            <span class="nc">TaskC</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">taskc</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">provides</span><span class="o">=</span><span class="sh">'</span><span class="s">res_c</span><span class="sh">'</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">main_flow</span> <span class="o">=</span> <span class="n">lf</span><span class="p">.</span><span class="nc">Flow</span><span class="p">(</span><span class="sh">'</span><span class="s">main</span><span class="sh">'</span><span class="p">).</span><span class="nf">add</span><span class="p">(</span>
        <span class="n">parallel_flow</span><span class="p">,</span>
        <span class="nc">FinalTask</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">final</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">provides</span><span class="o">=</span><span class="sh">'</span><span class="s">final_res</span><span class="sh">'</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">main_flow</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">store</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">:</span><span class="mi">3</span>
    <span class="p">}</span>
    <span class="n">flow</span> <span class="o">=</span> <span class="nf">build_flow</span><span class="p">()</span>
    <span class="n">eng</span> <span class="o">=</span> <span class="n">engines</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="sh">'</span><span class="s">parallel</span><span class="sh">'</span><span class="p">,</span> <span class="n">executor</span><span class="o">=</span><span class="n">pool_executor</span><span class="p">)</span>
    <span class="n">eng</span><span class="p">.</span><span class="nf">run</span><span class="p">()</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">eng</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">fetch_all</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">final_res</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">a_res</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">res_a</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">task A res: </span><span class="si">{</span><span class="n">a_res</span><span class="si">}</span><span class="s">, final_res: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>李小肥的YY</name></author><category term="代码" /><summary type="html"><![CDATA[记录学习taskflow的心得]]></summary></entry><entry><title type="html">知识图谱的小结</title><link href="http://localhost:4000/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html" rel="alternate" type="text/html" title="知识图谱的小结" /><published>2024-12-25T08:00:00+08:00</published><updated>2024-12-25T08:00:00+08:00</updated><id>http://localhost:4000/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html"><![CDATA[<h3 id="一-定义">一. 定义</h3>
<p>知识图谱是一种二元的图网络，用以描述客观世界中的实体信息及其相互关系规律的知识化体系。它的基本组成单元包括：</p>
<ul>
  <li>实体-关系-实体</li>
  <li>实体-属性-属性值</li>
</ul>

<h3 id="二-知识图谱的构建">二. 知识图谱的构建</h3>
<h4 id="21-知识建模">2.1 知识建模</h4>
<p>对于构建知识图谱的时候，一般我们都是针对所在的特定领域进行建模，所以一般称为“本体建模”或者“领域建模”。</p>

<p>这里构建本体模型一般分为3类技术：</p>
<ul>
  <li>RDF：Resource Description Framework，即资源描述框架。采用“资源-属性-属性值”的“主谓宾”结构（或称三元组），提供一种框架容器，并通过XML定义了一套形式化的方法，为机器语义理解的结构基础。</li>
  <li>RDFS：RDFS是RDF的一个扩展，它提供了一些基本的类和属性，以及它们之间的关系。</li>
  <li>OWL：Web Ontology Language，Web本体语言，它是基于RDF和RDFS的一种更加丰富的知识表示语言。在OWL中，我们可以定义类、属性以及它们的约束和关系。此外，OWL还支持对知识的推理。</li>
</ul>

<h4 id="22-知识获取">2.2 知识获取</h4>
<p>构建好需要的本体模型后，那么就需要把数据构建成对应的模型的输入了。我们知识的来源基本分为以下几类：</p>
<ul>
  <li>私有数据
    <ul>
      <li>企业的文档</li>
      <li>企业私有的用户数据</li>
      <li>企业私有的非结构化数据</li>
    </ul>
  </li>
  <li>公有数据
    <ul>
      <li>新闻</li>
      <li>百科</li>
      <li>公有语料</li>
    </ul>
  </li>
</ul>

<p>那么对于一些上述这些数据拆分为两大类，来进行<strong>数据处理</strong>：</p>
<ul>
  <li>非结构化数据：一般指的是无任何标识的文本，我们可以采用相关的NLP算法，比如实体识别和关系抽取（或者直接使用事件抽取，这里事件抽取可以参考我之前写的一篇博客）来构建实体关系的三元组。</li>
  <li>结构化数据：由于本身就是标准化的数据，我们只需要通过D2R服务器将数据库的内容转成RDF的形式。</li>
</ul>

<h4 id="23-知识融合">2.3 知识融合</h4>
<blockquote>
  <p>知识融合是将不同来源的知识整合到一起的过程，用以解决知识的冲突和重复。</p>
</blockquote>

<p>以下是基于知识融合步骤：</p>
<ol>
  <li>实体识别和链接：首先需要识别出不同数据源的相同实体，并将其链接。比如这里的“Tesla”和“特斯拉”应该识别并链接为同一实体。</li>
  <li>重复实体的合并：可以基于文本相似度来将不同数据源的重复实体进行合并</li>
  <li>关系融合：识别并合并描述相同实体之间的关系。</li>
</ol>

<h4 id="24-知识存储">2.4 知识存储</h4>
<p>一般来说，会将知识利用图的形式进行存储，因此，我们需要将抽取的实体关系构建成图的形式：</p>
<ul>
  <li>图的节点：实体</li>
  <li>图的边：关系</li>
</ul>

<p>图的存储一般使用的是Neo4j图数据库，据说其图的搜索的性能比mysql快1000倍！</p>

<h4 id="25-知识计算">2.5 知识计算</h4>
<blockquote>
  <p>知识计算是基于已构建的知识图谱进行能力输出的过程，它以图谱质量提升、潜在关系挖掘与补全、知识统计与知识推理作为主要研究内容。</p>
</blockquote>

<p>基于图论的相关挖掘算法：</p>
<ul>
  <li>图匹配</li>
  <li>图查询</li>
  <li>频繁子图</li>
  <li>图聚类</li>
</ul>

<p>知识推理是指从知识库中已有的实体关系数据出发，进行计算机推理，建立实体间的新关联，从而拓展和丰富知识网络。以下是基于知识推理的计算方法：</p>
<ul>
  <li>JENA：最常见的OWL推理工具是Jena，Jena2支持基于规则的简单推理，它的推理机制支持将推理器（inference reasoners）导入Jena，创建模型时将推理器与模型关联以实现推理。</li>
  <li>JESS：使用规则引擎进行推理，同 大多数专家系统工具一样，Jess的核心也是由事实库、规则库、推理机三大部分组成，并采用产生式规则作为基本的知识表达模式。</li>
  <li>ProLog：Prolog作为一种声明式逻辑编程语言，非常适合用于实现专家系统中的知识表示和推理。专家系统通过模拟人类专家的知识和决策过程来解决特定领域的复杂问题。在专家系统中，知识通常以事实（facts）和规则（rules）的形式表示，而Prolog的逻辑声明特性使得它成为实现专家系统的理想选择。</li>
  <li>DataLog:是一种基于逻辑的编程语言。它是一阶谓词逻辑中Horn子句逻辑的一种受限形式，只允许变量或常量作为谓词的自变元，不允许函数作为谓词的自变元。Datalog的语句由事实和规则组成，同Prolog一样，它可以实现对知识库的演绎推理，即可以从已知事实中根据跟着推理得到新的事实。</li>
</ul>

<h3 id="三-知识图谱的应用">三. 知识图谱的应用</h3>
<h4 id="31-安防领域">3.1 安防领域</h4>
<p>对于传销组织而言，其实其特征信息是潜藏在通话网络中，我们可以利用构建通话网络的图谱，利用子图识别和匹配的挖掘手段找到十分特殊的传销子图。</p>

<h4 id="32-金融领域">3.2 金融领域</h4>
<p>在金融领域中，根据获取用户的身份信息、授权信息以及长生命周期的信贷信息，构建的知识图谱，用于推断借款人的欺诈风险。</p>

<h4 id="33-智能客服">3.3 智能客服</h4>
<p>在大模型出现之前，其实可以根据自身垂类信息来构建企业垂类的知识图谱，用于简单的人机对话及检索。但是随着AI大模型的广泛应用，现在在智能客服上，完全可以用垂类大模型对其进行替换。</p>]]></content><author><name>李小肥的YY</name></author><category term="机器学习" /><category term="NLP" /><summary type="html"><![CDATA[记录学习知识图谱的一些总结]]></summary></entry><entry><title type="html">写专利心得</title><link href="http://localhost:4000/%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html" rel="alternate" type="text/html" title="写专利心得" /><published>2024-11-08T08:00:00+08:00</published><updated>2024-11-08T08:00:00+08:00</updated><id>http://localhost:4000/%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97</id><content type="html" xml:base="http://localhost:4000/%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html"><![CDATA[<h2 id="写专利心得">写专利心得</h2>

<blockquote>
  <p>最近2个月一口气写了9篇专利，近些年加起来也写了近20篇AI算法类专利了，所以想写点自己对于写专利的一些心得体会。</p>
</blockquote>

<h3 id="一-专利相关知识">一. 专利相关知识</h3>

<h4 id="11-专利是什么">1.1 专利是什么</h4>

<p>专利是专利权的简称，主要分为发明、实用新型及工业设计三种类型：</p>

<ul>
  <li>
    <p>发明：产品、方法及其改进的技术方案</p>
  </li>
  <li>
    <p>使用新型：产品的形状、结构或其结合的技术方案</p>
  </li>
  <li>
    <p>外观设计：产品外部形状、图案、色彩及其组合，如外包装。</p>
  </li>
</ul>

<h4 id="12-专利申请流程">1.2 专利申请流程</h4>

<ul>
  <li>
    <p>想好idea，确保哪些可以写，哪些写不了</p>
  </li>
  <li>
    <p>利用专利检索的工具（比如google学术），查看别人是否写过</p>
  </li>
  <li>
    <p>写交底书（简写）</p>
  </li>
  <li>
    <p>第三方机构代理人撰写</p>
  </li>
  <li>
    <p>专利递交专利局</p>
  </li>
  <li>
    <p>官方受理、初审、公开、实审</p>
  </li>
  <li>
    <p>官方授权</p>
  </li>
  <li>
    <p>专利维持</p>
  </li>
</ul>

<h4 id="13-写专利好处">1.3 写专利好处</h4>

<ul>
  <li>
    <p>拓展和发散思维</p>
  </li>
  <li>
    <p>锻炼文笔</p>
  </li>
  <li>
    <p>了解当前行业已有的技术</p>
  </li>
</ul>

<p>其实说了这么多，还是因为写专利可以<strong>赚钱</strong>啦！</p>

<h3 id="二-专利挖掘-算法类">二. 专利挖掘-算法类</h3>

<p>对于算法工程师而言，其实写发明类专利还是很简单的。个人感觉就和写小论文差不太多，甚至于比写小论文还简单，因为写专利其实可以不需要数据支持，只需要把自己的解决方案写出来就好了！</p>

<h4 id="21-创新点">2.1 创新点</h4>

<ul>
  <li>
    <p>专利审查时判断创造性的逻辑，是用你的方案和现有的技术比对，看有哪些区别点，然后判断在现有技术的基础上，做出这些区别点的改变得到你的方案是否是容易想到的，有没有一些难度。</p>
  </li>
  <li>
    <p>如果都是一些常规的方案，并且应用到我们这里也没什么难度的话，创造性高度就比较低，如果并不是简单的能运用到我们的方案，需要做一些相应的技术难点的解决的话，创新性就比较好。</p>
  </li>
</ul>

<h4 id="22-可写的几类算法专利">2.2 可写的几类算法专利</h4>

<ul>
  <li>
    <p>改进发明：这里最好详尽描述下现有技术，当前改进的技术</p>

    <ul>
      <li>
        <p>改进的数据处理</p>
      </li>
      <li>
        <p>改进的数据挖掘</p>
      </li>
      <li>
        <p>改进的数据标注</p>
      </li>
      <li>
        <p>改进的模型结构</p>
      </li>
      <li>
        <p>改进的算法公式</p>
      </li>
    </ul>
  </li>
  <li>
    <p>转用发明：现有算法应用在本发明的场景，说明克服了什么技术难点，增加了什么技术特征</p>
  </li>
  <li>
    <p>组合发明：1+1 &gt; 2，意料不到的技术上效果。聚焦到实际解决什么问题，不能写过于宽泛</p>
  </li>
</ul>

<pre><code class="language-flowchart">start=&gt;start: 老场景特征抽取及模型训练
  info=&gt;operation: 新场景特征抽取
  setCache=&gt;operation: 基于新场景特征及老场景模型合并得到压缩后的新特征
  end=&gt;end: 基于压缩过的新特征进行训练，得到新场景模型
  start-&gt;info-&gt;setCache-&gt;end
</code></pre>

<h4 id="23-算法关键点">2.3 算法关键点</h4>

<ul>
  <li>
    <p>用几句白话概括算法的关键点，相对于现有技术创新的地方</p>
  </li>
  <li>
    <p>流程图绘制整体流程</p>
  </li>
  <li>
    <p>模型架构图</p>
  </li>
  <li>
    <p>模型layer的创新点</p>
  </li>
  <li>
    <p>算法中构建的公式</p>
  </li>
</ul>

<h4 id="24-交底书编写-算法类">2.4 交底书编写-算法类</h4>

<p>我们在写交底书的时候，需要注意把以下环节都写上：</p>

<ul>
  <li>
    <p>描述现有场景下的问题</p>
  </li>
  <li>
    <p>本发明用什么样的方案解决了什么样的问题</p>
  </li>
  <li>
    <p>本发明在产品上属于什么环节</p>
  </li>
  <li>
    <p>本发明具体在技术上的创新点</p>
  </li>
  <li>
    <p>本发明所产生的有益效果</p>
  </li>
  <li>
    <p>参考文献</p>
  </li>
</ul>

<h3 id="三-总结">三. 总结</h3>

<p>其实，写专利的最大的难点就是创新点，可能你感觉自己好不容想出来的点，一查专利网站，别人老早就写了，这就很蛋疼了。</p>

<p>所以，一定要乘早写，尽量脑海中有一点灵光的时候，就开动吧！</p>]]></content><author><name>李小肥的YY</name></author><category term="机器学习" /><summary type="html"><![CDATA[记录写专利期间的心得体会]]></summary></entry><entry><title type="html">pyspark使用总结-第二篇</title><link href="http://localhost:4000/pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html" rel="alternate" type="text/html" title="pyspark使用总结-第二篇" /><published>2024-11-07T08:00:00+08:00</published><updated>2024-11-07T08:00:00+08:00</updated><id>http://localhost:4000/pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"><![CDATA[<h3 id="一-常见的oom">一. 常见的OOM</h3>

<h4 id="11-常用的解决方案">1.1 常用的解决方案</h4>

<p>我们在使用spark的时候，经常在save数据的时候，都会遇到内存溢出的问题，这通常是由于数据量过大导致的。以下是一些可能的解决方案：</p>

<ol>
  <li>增加分区数：如果数据集非常大，可以尝试增加分区数。可以使用<code class="language-plaintext highlighter-rouge">repartition()</code>或<code class="language-plaintext highlighter-rouge">coalesce()</code>函数来增加分区数。增加分区数可以将数据均匀地分布在更多的节点上，从而减少每个节点上的内存压力。</li>
  <li>压缩数据：如果数据集包含大量重复的值，可以考虑使用压缩算法来减少内存使用。Pyspark提供了多种压缩算法，如Snappy、Gzip等。可以使用<code class="language-plaintext highlighter-rouge">option("compression", "snappy")</code>来设置压缩算法。</li>
  <li>增加集群资源：可以考虑增加集群资源。可以增加集群的节点数或增加每个节点的内存。可以通过调整<code class="language-plaintext highlighter-rouge">spark.driver.memory</code>和<code class="language-plaintext highlighter-rouge">spark.executor.memory</code>参数来增加内存分配，特别对于driver而言，最好把内存设置大一些。</li>
</ol>

<h4 id="12-代码方面的优化">1.2 代码方面的优化</h4>

<p>如果以上常用的解决方案依旧无法解决OOM的问题，那么我们可能需要考虑是否需要优化pyspark的代码了</p>

<ul>
  <li>UDF过于复杂：尽可能将结果拆分不同的列，然后再用简单的udf来组合这些列进行计算。</li>
  <li>多用filter算子：提前将大量数据剔除</li>
  <li>多用select算子：只保留需要的列，减少内存的使用</li>
  <li>尽量少用collect、count算子：像这些action算子基本都会把executor的数据全部加载回driver上，导致driver的内存吃紧。</li>
  <li>当发现在某个udf环节只有一个节点在跑的时候，可以使用.cache()来分布式跑任务。</li>
</ul>

<h4 id="13-数据倾斜导致的oom和心跳时间超时">1.3 数据倾斜导致的OOM和心跳时间超时</h4>
<p>通常我们会发现有些时候，数据本身并没有很大，但是要运行很长时间，而且最终还因为heart beat时间过长或则oom而失败。</p>

<p><strong>发生</strong>
数据倾斜一般发生在：</p>
<ul>
  <li>join两个df的时候</li>
  <li>groupby某一列，然后这一列（包含了a，b，c等元素）中，很不巧，a有非常多（1000），而b和c等元素仅有2个</li>
</ul>

<p><strong>验证</strong>
这时候我们可以直接通过yarn日志中的shuffer resize/records看到很多excutors中会发现极个别失败的excutor的size非常大（10w个），而其他的excutor的size可能只有10个。那么这个时候无疑是发生数据倾斜了。</p>

<p><strong>解决</strong>
这里推荐使用<strong>加盐</strong>处理，比什么加excutor的内存和核数更加有效</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">salted_a</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">lit</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">salt_num</span><span class="p">).</span><span class="nf">cast</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">df2</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">salted_a</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">lit</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">salt_num</span><span class="p">).</span><span class="nf">cast</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span><span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">salted_a</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div>

<h3 id="二-在集群上使用自建的python环境">二. 在集群上使用自建的python环境</h3>

<h4 id="21-构建python环境">2.1 构建python环境</h4>

<p>由于集群是centos，那么我们构建python环境的时候最好选择也是centos。</p>

<ul>
  <li>
    <p>conda构建python3.8：<code class="language-plaintext highlighter-rouge">conda create -n yy_env python=3.8</code></p>
  </li>
  <li>
    <p>安装相关包：<code class="language-plaintext highlighter-rouge">pip intall -r requirements.txt</code></p>
  </li>
  <li>
    <p>进入miniconda目录下：<code class="language-plaintext highlighter-rouge">cd /root/miniconda3/envs</code></p>
  </li>
  <li>
    <p>压缩python环境：<code class="language-plaintext highlighter-rouge">tar zcvf yy_env.tar.gz yy_env/</code></p>
  </li>
</ul>

<h4 id="22-从本地传到指定文件目录">2.2 从本地传到指定文件目录</h4>

<ul>
  <li>
    <p>如果需要推送到mdfs上，需要用mdfs和hdfs之间的映射关系</p>
  </li>
  <li>
    <p>利用hadoop脚本上传至hdfs上</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sh hadoop.sh fs <span class="nt">-Dipc</span>.client.fallback-to-simple-auth-allowed<span class="o">=</span><span class="nb">true</span> <span class="nt">-put</span> file:///yy_env.tar.gz hdfs://env/
</code></pre></div></div>

<h4 id="23-编写spark_conf">2.3 编写spark_conf</h4>

<pre><code class="language-bashag-0-1ibvlmakrag-1-1ibvlmakr">spark.yarn.dist.archives=mdfs:///env/yy_env.tar.gz;
spark.yarn.appMasterEnv.PYSPARK_PYTHON=./yy_env.tar.gz/yy_env/bin/python3;
spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON=./yy_env.tar.gz/yy_env/bin/python3;
spark.executorEnv.PYSPARK_PYTHON=./yy_env.tar.gz/yy_env/bin/python3;
spark.sql.broadcastTimeout=800;
spark.sql.broadcastMaxRetries=3;
spark.executor.heartbeatInterval=100000
</code></pre>

<h3 id="三-pandas和pyspark的dataframe转换">三. pandas和pyspark的dataframe转换</h3>

<blockquote>
  <p>两者之间的转换，代码很简单，但是实际中就会发现，当海量数据需要进行转换的时候，消耗时间成本是多么大！</p>
</blockquote>

<h4 id="31-转换的代码">3.1 转换的代码</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pandas ==&gt; pyspark
</span><span class="n">pyspark_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">pandas_df</span><span class="p">)</span>

<span class="c1"># pyspark ==&gt; pandas
</span><span class="n">pandas_df</span> <span class="o">=</span> <span class="n">pyspark_df</span><span class="p">.</span><span class="nf">toPandas</span><span class="p">()</span> 
</code></pre></div></div>

<h4 id="32-爬坑">3.2 爬坑</h4>

<p>在转化代码中有哪些坑呢？</p>

<ol>
  <li>
    <p>pandas转pyspark的时候，如果你的pandas的版本过低，就会报错，这里你可以选择以下2个方案解决：</p>

    <ul>
      <li>
        <p>升级pandas</p>
      </li>
      <li>
        <p>在代码中添加：<code class="language-plaintext highlighter-rouge">pd.DataFrame.iteritems = pd.DataFrame.items</code></p>
      </li>
    </ul>
  </li>
  <li>
    <p>耗时过长，这里也有以下方案能缩减耗时：</p>

    <ul>
      <li>
        <p>减少df的列和行 ==&gt; 减少数据</p>
      </li>
      <li>
        <p>利用pyArrow加速：<code class="language-plaintext highlighter-rouge">pip install pyarrow</code></p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.execution.arrow.pyspark.enabled</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># 加速转pandasdf的速度
</span></code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ol>

<h3 id="四-常用脚本">四. 常用脚本</h3>

<h4 id="41-加载数据">4.1 加载数据</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 加载mdfs文件，无表头
</span><span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
            <span class="nc">StructField</span><span class="p">(</span><span class="sh">"</span><span class="s">link_id</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
        <span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>

<span class="c1"># 加载mdfs文件，有表头
</span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 加载hive表
</span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"</span><span class="s">select a,b from save_tabel where </span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">iceberg</span><span class="sh">"</span><span class="p">).</span><span class="nf">load</span><span class="p">(</span><span class="n">hive_tabel</span><span class="p">).</span><span class="nf">where</span><span class="p">(</span><span class="sh">"</span><span class="s">a = a</span><span class="sh">"</span><span class="p">).</span><span class="nf">select</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="42-保存数据">4.2 保存数据</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 保存mdfs
</span><span class="n">df</span><span class="p">.</span><span class="nf">repartition</span><span class="p">(</span><span class="n">partition_num</span><span class="p">).</span><span class="n">write</span><span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">header</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">).</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">csv</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">overwrite</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>


<span class="c1"># 保存hive表: append是添加，overwrite是覆盖
</span><span class="n">df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">iceberg</span><span class="sh">"</span><span class="p">).</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">mergeSchema</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">).</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">).</span><span class="nf">save</span><span class="p">(</span><span class="n">save_tabel</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="43-常用代码">4.3 常用代码</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 1. 根据某一或者几列去重
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">dropDuplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">])</span>


<span class="c1"># 2. df上下拼接（保证两个df的列名和顺序一致）
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">.</span><span class="nf">union</span><span class="p">(</span><span class="n">df_2</span><span class="p">)</span>

<span class="c1"># 3. df横向拼接
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">df_2</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span> <span class="sh">'</span><span class="s">inner</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># 4. 构建常数列
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">lit</span><span class="p">(</span><span class="sh">'</span><span class="s">0</span><span class="sh">'</span><span class="p">))</span>

<span class="c1"># 5. groupby多列，其他的列聚合成list
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">).</span><span class="nf">agg</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">collect_list</span><span class="p">(</span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">),</span><span class="n">F</span><span class="p">.</span><span class="nf">collect_list</span><span class="p">(</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">),</span><span class="n">F</span><span class="p">.</span><span class="nf">collect_list</span><span class="p">(</span><span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">'</span><span class="s">collect_list(c)</span><span class="sh">'</span><span class="p">).</span><span class="nf">cast</span><span class="p">(</span><span class="nc">StringType</span><span class="p">()))</span>
<span class="c1"># 当有多个collect_list，然后需要保证数据同步的时候可以用F.struct
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupBy</span><span class="p">([</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">]).</span><span class="nf">agg</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">collect_list</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">struct</span><span class="p">(</span><span class="sh">"</span><span class="s">aa</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">bb</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">cc</span><span class="sh">"</span><span class="p">)))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">'</span><span class="s">values</span><span class="sh">'</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">'</span><span class="s">collect_list(struct(aa,bb, cc))</span><span class="sh">'</span><span class="p">).</span><span class="nf">cast</span><span class="p">(</span><span class="nc">StringType</span><span class="p">()))</span>

<span class="c1"># 6. filter过滤多个条件
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">filter</span><span class="p">((</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># 且
</span>
<span class="c1"># 7. 两个df按照某一列进行计算差集
</span><span class="n">diff_df</span> <span class="o">=</span> <span class="n">df_1</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">).</span><span class="nf">subtract</span><span class="p">(</span><span class="n">df_2</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">)).</span><span class="nf">distinct</span><span class="p">()</span>

<span class="c1"># 8. explode with split
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">aa</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">),</span> <span class="sh">'</span><span class="s">;</span><span class="sh">'</span><span class="p">)))</span>

<span class="c1"># 9. substr
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a_str</span><span class="sh">"</span><span class="p">).</span><span class="nf">substr</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">==</span> <span class="sh">"</span><span class="s">1234</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># a = 12345678
</span></code></pre></div></div>

<h4 id="44-udf使用">4.4 udf使用</h4>

<p>可能在一个处理的过程中往往会使用多个自定义的udf函数，但是当项目非常大的时候，最好还是把归属于这个处理类的udf集成到类中：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">A</span><span class="p">:</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@F.udf</span><span class="p">(</span><span class="n">returnType</span><span class="o">=</span><span class="nc">IntegerType</span><span class="p">())</span>
    <span class="k">def</span> <span class="nf">is_a_equal0</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
</code></pre></div></div>

<p>需要返回多列</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">aaa</span><span class="p">(</span><span class="n">var_list</span><span class="p">):</span>

        <span class="nd">@F.udf</span><span class="p">(</span><span class="n">returnType</span><span class="o">=</span><span class="nc">StringType</span><span class="p">())</span>
        <span class="k">def</span> <span class="nf">bbb</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="c1"># 在这里可以对每个值进行自定义的处理操作
</span>            <span class="n">rs</span> <span class="o">=</span> <span class="sh">''</span>
            <span class="n">value_js</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">var_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">rs</span><span class="p">:</span>
                    <span class="n">rs</span> <span class="o">+=</span> <span class="p">(</span><span class="sh">'</span><span class="s">;</span><span class="sh">'</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">value_js</span><span class="p">[</span><span class="n">v</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">rs</span> <span class="o">+=</span> <span class="nf">str</span><span class="p">(</span><span class="n">value_js</span><span class="p">[</span><span class="n">v</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">rs</span>

        <span class="k">return</span> <span class="n">bbb</span>

    <span class="n">need_vars</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">need_data</span><span class="sh">"</span><span class="p">,</span> <span class="nf">aaa</span><span class="p">(</span><span class="n">need_vars</span><span class="p">)(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">)))</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">s</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">],</span> <span class="sh">"</span><span class="s">;</span><span class="sh">"</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">need_vars</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">s</span><span class="sh">'</span><span class="p">].</span><span class="nf">getItem</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</code></pre></div></div>]]></content><author><name>李小肥的YY</name></author><category term="机器学习" /><category term="代码" /><summary type="html"><![CDATA[记录pyspark的使用过程心得体会]]></summary></entry><entry><title type="html">LLM的应用开发框架——Langchain</title><link href="http://localhost:4000/langchain.html" rel="alternate" type="text/html" title="LLM的应用开发框架——Langchain" /><published>2024-07-04T08:00:00+08:00</published><updated>2024-07-04T08:00:00+08:00</updated><id>http://localhost:4000/langchain</id><content type="html" xml:base="http://localhost:4000/langchain.html"><![CDATA[<h3 id="一-langchain是什么">一. Langchain是什么</h3>

<blockquote>
  <p>Langchain 官网文档：https://python.langchain.com/v0.2/docs/introduction/</p>
</blockquote>

<h4 id="llm崛起出现了哪些需求">LLM崛起出现了哪些需求？</h4>

<ul>
  <li>
    <p>格式化输出：希望给的输出格式是json、csv、db格式</p>
  </li>
  <li>
    <p>输出很长的提示词文本：如何总结一本书的内容？</p>
  </li>
  <li>
    <p>多次API调用：两次调用api，前后两次需要结合的</p>
  </li>
  <li>
    <p>外部调用：比如需要进行web 搜索</p>
  </li>
  <li>
    <p>标准化开发</p>
  </li>
  <li>
    <p>快速切换模型：有多个大模型可用，支持代码不变，快速切换</p>
  </li>
</ul>

<h3 id="二-langchain支撑llm的应用">二. Langchain支撑LLM的应用</h3>

<h4 id="21-支持多种llm">2.1 支持多种LLM</h4>

<p>无论是国外的GPT4、LLaMa，还是国内的ChatGLM、Baichuan，都支持调用api和huggingface模型的使用，下面主要介绍HF模型的下载使用。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">huggingface_hub</span> <span class="kn">import</span> <span class="n">snapshot_download</span>
<span class="kn">from</span> <span class="n">langchain.llms.base</span> <span class="kn">import</span> <span class="n">LLM</span> 
<span class="c1"># 指定下载目录（在当前文件夹下）
</span><span class="nf">snapshot_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="sh">"</span><span class="s">baichuan-inc/Baichuan2-7B-Chat-4bits</span><span class="sh">"</span><span class="p">,</span> <span class="n">local_dir</span><span class="o">=</span><span class="sh">"</span><span class="s">baichuan-inc/Baichuan2-7B-Chat-4bits</span><span class="sh">"</span><span class="p">)</span> 

<span class="k">class</span> <span class="nc">baichuan2_LLM</span><span class="p">(</span><span class="n">LLM</span><span class="p">):</span>
     <span class="c1"># 基于本地 Baichuan 自定义 LLM 类
</span>     <span class="n">tokenizer</span><span class="p">:</span> <span class="n">AutoTokenizer</span> <span class="o">=</span> <span class="bp">None</span>
     <span class="n">model</span><span class="p">:</span> <span class="n">AutoModelForCausalLM</span> <span class="o">=</span> <span class="bp">None</span> 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">):</span>
         <span class="c1"># model_path: Baichuan-7B-chat模型路径
</span>         <span class="c1"># 从本地初始化模型
</span>         <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
         <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">正在从本地加载模型...</span><span class="sh">"</span><span class="p">)</span>
         <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
         <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
         <span class="n">torch_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span><span class="p">)</span>
         <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">generation_config</span> <span class="o">=</span> <span class="n">GenerationConfig</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
         <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
         <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">完成本地模型的加载</span><span class="sh">"</span><span class="p">)</span> 

    <span class="k">def</span> <span class="nf">_call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">stop</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
         <span class="n">run_manager</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CallbackManagerForLLMRun</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
         <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
         <span class="c1"># 重写调用函数
</span>         <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
         <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}</span>
         <span class="p">]</span>
         <span class="c1"># 重写调用函数
</span>         <span class="n">response</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">chat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">messages</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">response</span> 

    <span class="nd">@property</span>
     <span class="k">def</span> <span class="nf">_llm_type</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">"</span><span class="s">baichuan2_LLM</span><span class="sh">"</span>
</code></pre></div></div>

<h4 id="22-零样本少样本提示">2.2 零样本少样本提示</h4>

<p>对于LLM来说，尽可能的使用prompt来尝试解决问题，而非直接对LLM进行训练。</p>

<p>因此对于少数据或者没有数据来利用prompt来解决问题：</p>

<ul>
  <li>
    <p>zero-shot prompting：直接问模型，最低成本获取答案</p>
  </li>
  <li>
    <p>few-shot prompting：给模型几个例子，引导它做的更好</p>
  </li>
</ul>

<p>在Langchain中已经集成了few-shot prompting，如下例子</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.prompts.few_shot</span> <span class="kn">import</span> <span class="n">FewShotPromptTemplate</span>
<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">你好吗？</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">帅哥，我很好</span><span class="sh">"</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">今天周几？</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">帅哥，今天周日</span><span class="sh">"</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">天气好吗？</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">帅哥，是的，今天天气很不错</span><span class="sh">"</span>
        <span class="p">}</span>
    <span class="p">]</span>

    <span class="n">example_prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span><span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">answer</span><span class="sh">"</span><span class="p">],</span> <span class="n">template</span><span class="o">=</span><span class="sh">"</span><span class="s">提问: {question}</span><span class="se">\n</span><span class="s">回答:{answer}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="nc">FewShotPromptTemplate</span><span class="p">(</span><span class="n">examples</span><span class="o">=</span><span class="n">examples</span><span class="p">,</span>
                                   <span class="n">example_prompt</span><span class="o">=</span><span class="n">example_prompt</span><span class="p">,</span>
                                   <span class="n">suffix</span><span class="o">=</span><span class="sh">"</span><span class="s">提问: {input}</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span>
                                   <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="sh">"</span><span class="s">我怎么这么丑</span><span class="sh">"</span><span class="p">))</span>

    <span class="c1"># 这里相当于将前缀的这些少样本和当前问题全部放入llm，让其知道前后关系或者学习规则
</span>    <span class="nf">print</span><span class="p">(</span><span class="n">llm</span><span class="p">.</span><span class="nf">predict</span><span class="p">((</span><span class="n">prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="sh">"</span><span class="s">我怎么这么丑</span><span class="sh">"</span><span class="p">))))</span>
</code></pre></div></div>

<h4 id="23-文档问答">2.3 文档问答</h4>

<p>方案：LangChain + ChatGLM，<a href="https://github.com/chatchat-space/Langchain-Chatchat">GitHub - chatchat-space/Langchain-Chatchat</a></p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/2024/07/04/1720076916450-5f8f9bb0-a4ce-4e21-adab-6ba043264124.jpg" alt="" /></p>

<p>整体流程：</p>

<ul>
  <li>
    <p>本地文档通过Loader读入</p>
  </li>
  <li>
    <p>利用文档分割器对其文字进行分割，不然文字太长无法输入llm</p>
  </li>
  <li>
    <p>利用Embedding Model（直接利用Huggingface下载相关词嵌入模型）对分割后的文档chunk进行向量化操作</p>
  </li>
  <li>
    <p>利用VectorStore（可以选择Chroma或者FAISS作为DB）对向量进行存储</p>
  </li>
  <li>
    <p>对于新的query而言，向量化后对Vecorstore进行搜索其相似度高的chunk</p>
  </li>
  <li>
    <p>最后将chunk文档同样放入prompt中，输入模型，得到结果</p>
  </li>
</ul>

<p>Langchain支持的优势：</p>

<ul>
  <li>
    <p>支持相关模块，比如TextSplitter、Loader、Embedding、Vector</p>
  </li>
  <li>
    <p>在文档中直接找到相似度最关联的chunk，减少输入llm的文字，从而缩短推理时长</p>
  </li>
</ul>

<p>从 LangChain + LLM 的流程图可以看出，<strong>embedding 的召回率、LLM 的回答能力都会影响到最终回答的准确率</strong>。所以，要如果你遇到了 bad case ，你应该先确认这个 bad case 是召回错误，还是模型回答错误。</p>

<p>下面使用庆余年这本书示范的例子，这里的LLM和Embedding模型均来自于Huggingface。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.indexes.vectorstore</span> <span class="kn">import</span> <span class="n">VectorStoreIndexWrapper</span>
<span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="n">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span> <span class="n">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>


<span class="k">def</span> <span class="nf">load_text_save_index</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span><span class="n">index_name</span><span class="p">):</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">TextLoader</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">text_qyn</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>

    <span class="n">splitter</span> <span class="o">=</span> <span class="nc">RecursiveCharacterTextSplitter</span><span class="p">(</span>
            <span class="n">chunk_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># 分割出来的文本长度
</span>            <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># 块之间的重叠文字
</span>            <span class="n">length_function</span><span class="o">=</span><span class="nb">len</span><span class="p">,</span> <span class="c1"># 计算每个块的长度
</span>            <span class="n">add_start_index</span><span class="o">=</span><span class="bp">True</span> <span class="c1"># 决定是否在metadata中包含每个块在原始文档中的起始位置
</span>        <span class="p">)</span>

    <span class="n">texts</span> <span class="o">=</span> <span class="n">splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">text_qyn</span><span class="p">)[:</span><span class="mi">100</span><span class="p">]</span>

    <span class="n">faiss_db</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">hf_embeddings</span><span class="p">)</span>
    <span class="n">faiss_db</span><span class="p">.</span><span class="nf">save_local</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">local_persist_path</span><span class="p">,</span><span class="n">index_name</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">faiss db saved !</span><span class="sh">'</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">load_index</span><span class="p">(</span><span class="n">index_name</span><span class="p">):</span>
    <span class="n">index_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">local_persist_path</span><span class="p">,</span> <span class="n">index_name</span><span class="p">)</span>
    <span class="n">faiss_db</span> <span class="o">=</span> <span class="n">FAISS</span><span class="p">.</span><span class="nf">load_local</span><span class="p">(</span><span class="n">index_path</span><span class="p">,</span><span class="n">embeddings</span><span class="o">=</span><span class="n">hf_embeddings</span><span class="p">,</span><span class="n">allow_dangerous_deserialization</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="nc">VectorStoreIndexWrapper</span><span class="p">(</span><span class="n">vectorstore</span> <span class="o">=</span> <span class="n">faiss_db</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">index</span>


<span class="n">file_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">庆余年.txt</span><span class="sh">'</span>
<span class="n">local_persist_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./vector_store</span><span class="sh">'</span>

<span class="c1"># load_text_save_index(file_path,index_name='庆余年')
</span><span class="n">index</span> <span class="o">=</span> <span class="nf">load_index</span><span class="p">(</span><span class="n">index_name</span><span class="o">=</span><span class="sh">'</span><span class="s">庆余年</span><span class="sh">'</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="sh">"</span><span class="s">五竹是谁</span><span class="sh">"</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="24-搜索助手">2.4 搜索助手</h4>

<p>对于Langchain而言，有专门的Agent模块，其支持对指令进行外部搜索。因此需要申请google搜索的APIkey，这里推荐<a href="https://serpapi.com/">SerpAPI</a>的key。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span>
<span class="kn">from</span> <span class="n">langchain_community.agent_toolkits.load_tools</span> <span class="kn">import</span> <span class="n">load_tools</span>


<span class="n">tools</span> <span class="o">=</span> <span class="nf">load_tools</span><span class="p">([</span><span class="sh">'</span><span class="s">serpapi</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">llm-math</span><span class="sh">'</span><span class="p">],</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tools</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">name</span><span class="p">,</span><span class="n">tools</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">description</span><span class="p">)</span>

<span class="n">agent</span> <span class="o">=</span> <span class="nf">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span><span class="n">llm</span><span class="p">,</span><span class="n">agent</span> <span class="o">=</span> <span class="sh">'</span><span class="s">zero-shot-react-description</span><span class="sh">'</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">agent</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="sh">'</span><span class="s">苹果的CEO，他10年后多少岁？</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="25-文章总结">2.5 文章总结</h4>

<p>对于一个大型的文章而言，如果直接全部扔给LLM，无疑是会报显存错误的，因此需要将大的文本切分成小的docs，Langchain支持一下三种<strong>总结链</strong>方式将docs输入给LLM：</p>

<ul>
  <li>
    <p>stuff：将所有的docs汇总成一个总的提示直接塞给LLM，这里可能会字数太长而报错。</p>
  </li>
  <li>
    <p>map_reduce：每个docs 依次输入LLM进行总结，并将每个总结的结果拼接后再次输入LLM作为汇总。</p>
  </li>
  <li>
    <p>refine：通过循环遍历输入doc并逐步更新其答案来构建响应。对于每个doc，它将所有非文档输入、当前文档和最新的中间答案传递给LLM链以获得新的答案。</p>
  </li>
</ul>

<p>下面是对URL网页的文章做一个汇总的过程</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">UnstructuredURLLoader</span>
<span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="n">langchain.chains.summarize</span> <span class="kn">import</span> <span class="n">load_summarize_chain</span>
<span class="kn">from</span> <span class="n">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="k">def</span> <span class="nf">load_news</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">RecursiveCharacterTextSplitter</span><span class="p">(</span>
                                                   <span class="c1"># separators=['正文','撰稿'],
</span>                                                   <span class="n">chunk_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                                                   <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="nc">UnstructuredURLLoader</span><span class="p">([</span><span class="n">url</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load_and_split</span><span class="p">(</span><span class="n">text_splitter</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">doc lenth is </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">summary_news</span><span class="p">():</span>
    <span class="n">map_prompt_temp</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">总结这段新闻的内容在50字以内：{text}, 总结：</span><span class="sh">"""</span>
    <span class="n">ch_prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">map_prompt_temp</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="nf">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="sh">'</span><span class="s">map_reduce</span><span class="sh">'</span><span class="p">,</span> <span class="n">map_prompt</span><span class="o">=</span><span class="n">ch_prompt</span><span class="p">,</span> <span class="n">combine_prompt</span><span class="o">=</span><span class="n">ch_prompt</span><span class="p">)</span>
    <span class="c1"># summary = chain_ch.run(doc)
</span>    <span class="n">summary</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">({</span><span class="sh">"</span><span class="s">input_documents</span><span class="sh">"</span><span class="p">:</span> <span class="n">doc</span><span class="p">})[</span><span class="sh">'</span><span class="s">output_text</span><span class="sh">'</span><span class="p">]</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>  <span class="c1"># 这里展示的是中文的总结
</span></code></pre></div></div>

<h4 id="26-输出解析">2.6 输出解析</h4>

<p>往往我们希望对于LLM生成的结果，能输出成我们预先定义好的格式。下面是对文章指定生成剧本的形式的过程。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.output_parsers</span> <span class="kn">import</span> <span class="n">PydanticOutputParser</span>
<span class="kn">from</span> <span class="n">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span><span class="n">Field</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="c1"># 注意：这里的BaseModel的类的description 不能用中文，因为到template的prompt的时候，会乱码，导致模型不懂描述的是什么
</span><span class="k">class</span> <span class="nc">Line</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="c1"># character:str = Field(description=u"说这句台词的角色名字",)
</span>    <span class="n">character</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sa">u</span><span class="sh">"</span><span class="s">The name of the character who said this line</span><span class="sh">"</span><span class="p">,)</span>
    <span class="c1"># content:str = Field(description=u"台词的具体内容，其中不再包含角色的名字")
</span>    <span class="n">content</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sa">u</span><span class="sh">"</span><span class="s">The specific content of the line, which no longer contains the character</span><span class="sh">'</span><span class="s">s name</span><span class="sh">"</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">JuBen</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="c1"># script: List[Line] = Field(description=u"一段的台词剧本")
</span>    <span class="n">script</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Line</span><span class="p">]</span> <span class="o">=</span> <span class="nc">Field</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sa">u</span><span class="sh">"</span><span class="s">A talk script</span><span class="sh">"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">parse_process</span><span class="p">():</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">我将给你一段文章，请按照要求把这段文章改写成一个电视剧的剧本。

                    文章：</span><span class="sh">"</span><span class="s">{docs}</span><span class="sh">"</span><span class="s">
                    要求：</span><span class="sh">"</span><span class="s">{request}</span><span class="sh">"</span><span class="s">
                    {output_instructions}

            </span><span class="sh">"""</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="nc">PydanticOutputParser</span><span class="p">(</span><span class="n">pydantic_object</span><span class="o">=</span><span class="n">JuBen</span><span class="p">)</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">temp</span><span class="p">,</span>
                               <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">docs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">request</span><span class="sh">'</span><span class="p">],</span>
                               <span class="n">partial_variables</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">output_instructions</span><span class="sh">"</span><span class="p">:</span> <span class="n">parser</span><span class="p">.</span><span class="nf">get_format_instructions</span><span class="p">()},</span>
                               <span class="c1"># pattern = re.compile('\n')
</span>                               <span class="p">)</span>
    <span class="n">jb_content</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">.</span><span class="nf">format_prompt</span><span class="p">(</span><span class="n">docs</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span> <span class="n">request</span><span class="o">=</span><span class="sh">"</span><span class="s">风格大胆悲情，剧本对话角色不少于三个人，以他们的自我介绍为开头</span><span class="sh">"</span><span class="p">)</span>

    <span class="c1"># msg = [HumanMessage(content=jb_content)]
</span>    <span class="c1"># rs = llm.predict_messages(msg)
</span>    <span class="n">rs</span> <span class="o">=</span> <span class="nf">llm</span><span class="p">(</span><span class="n">jb_content</span><span class="p">.</span><span class="nf">to_string</span><span class="p">())</span>
    <span class="n">jb</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span>


    <span class="c1"># chain = jb_prompt | llm | parser
</span>    <span class="c1"># xiangsheng = chain.invoke({
</span>    <span class="c1">#     "docs" : docs,
</span>    <span class="c1">#     "request" : "风格大胆悲情，剧本对话角色不少于三个人，以他们的自我介绍为开头"
</span>    <span class="c1"># })
</span>    <span class="c1"># print(jb)
</span>    <span class="k">return</span> <span class="n">jb</span>
</code></pre></div></div>]]></content><author><name>李小肥的YY</name></author><category term="深度学习" /><category term="NLP" /><category term="LLM" /><summary type="html"><![CDATA[记录Langchain的使用过程心得体会]]></summary></entry><entry><title type="html">pytorch_lightning使用体验</title><link href="http://localhost:4000/pytorch_lightning%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C.html" rel="alternate" type="text/html" title="pytorch_lightning使用体验" /><published>2024-01-18T08:00:00+08:00</published><updated>2024-01-18T08:00:00+08:00</updated><id>http://localhost:4000/pytorch_lightning%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C</id><content type="html" xml:base="http://localhost:4000/pytorch_lightning%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C.html"><![CDATA[<blockquote>
  <p>如果是一些小模型想要快速实验，不想怎么写代码的，可以通过pytorch_lightning快速搭建模型，但是如果涉及到大模型，以及分布式训练预测，咱还是老老实实用pytorch吧。</p>
</blockquote>

<h3 id="一-使用体验">一. 使用体验</h3>

<p>就像很多年前写过tensorflow之后看到keras后的欣喜，当我看到pytorch_lightning后瞬间就喜欢上了它！对于pytorch的重度使用者来说，每次都要写很多重复的训练预测代码，总感觉代码复用起来很麻烦，于是pytorch_lightning它来啦！</p>

<p><strong>pytorch_lightning的优势：</strong></p>

<ul>
  <li>
    <p>代码可读性、复用性高</p>
  </li>
  <li>
    <p>自由度和pytorch一样高，并没有像使用keras一样感觉封装过死的感觉。</p>
  </li>
  <li>
    <p>能像keras一样快速搭建模型，简化模型训练和预测的过程</p>
  </li>
  <li>
    <p>支持分布式训练</p>
  </li>
</ul>

<h3 id="二-安装和使用">二. 安装和使用</h3>

<p>官网地址是：https://lightning.ai/</p>

<p>pip进行安装：<code class="language-plaintext highlighter-rouge">pip show pytorch_lightning</code></p>

<p>下面使用MNIST来展示如何使用pytorch_lightning来简化自己的代码</p>

<h4 id="21-数据模块lightningdatamodule">2.1 数据模块LightningDataModule</h4>

<p>通常情况下，我们需要做一些预处理，以及在定义完自己的dataset后，需要定义dataloader，这里可以直接继承LightningDataModule模块，直接重写其中的方法即可。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">root_dir</span><span class="p">,</span><span class="n">val_size</span><span class="p">,</span><span class="n">num_workers</span><span class="p">,</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MNISTDataModule</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        download data once
        </span><span class="sh">"""</span>
        <span class="nc">MNIST</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="nc">MNIST</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        setup dataset for each machine
        </span><span class="sh">"""</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">root_dir</span><span class="p">,</span>
                        <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">download</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                        <span class="n">transform</span><span class="o">=</span><span class="n">T</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">())</span>
        <span class="n">train_length</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">val_dataset</span> <span class="o">=</span> \
            <span class="nf">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                         <span class="p">[</span><span class="n">train_length</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">val_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">val_size</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_dataset</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">num_workers</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
                          <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">val_dataset</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">num_workers</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
                          <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="22-训练和预测模块lightningmodule">2.2 训练和预测模块LightningModule</h4>

<p>之前每次训练和预测模型的时候，我都会写一个该过程的一个基类，来封装每个epoch模型训练、验证的过程，其实每次不同的项目、不同的模型继承了上述的基类，但是基本上也就是改变其中的每个batch训练、验证的方法，然后看到了一个别人封装的这么完美的训练预测基类，简直开心的不要不要的。。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MNISTModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">save_hyperparameters</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">validation_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">self</span><span class="p">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="p">.</span><span class="nc">Accuracy</span><span class="p">(</span>
            <span class="n">task</span><span class="o">=</span><span class="sh">"</span><span class="s">multiclass</span><span class="sh">"</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">num_classes</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">f1_score</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="p">.</span><span class="nc">F1Score</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="sh">"</span><span class="s">multiclass</span><span class="sh">"</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">net</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="nc">CosineAnnealingLR</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">,</span>
                                      <span class="n">T_max</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">,</span>
                                      <span class="n">eta_min</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">lr</span> <span class="o">/</span> <span class="mf">1e2</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_common_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logits_predicted</span> <span class="o">=</span> <span class="nf">self</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">logits_predicted</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">accuracy</span><span class="p">(</span><span class="n">logits_predicted</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="c1"># acc = torch.sum(torch.eq(torch.argmax(logits_predicted, -1), labels).to(torch.float32)) / len(labels)
</span>        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_common_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">batch_idx</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">,</span> <span class="nf">get_learning_rate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">'</span><span class="s">train_step_loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

        <span class="n">train_rs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
               <span class="sh">'</span><span class="s">train_acc</span><span class="sh">'</span><span class="p">:</span> <span class="n">acc</span><span class="p">}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">training_step_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_rs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">rs</span> <span class="o">=</span> <span class="nf">self</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">rs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">rs</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_common_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
               <span class="sh">'</span><span class="s">val_acc</span><span class="sh">'</span><span class="p">:</span> <span class="n">acc</span><span class="p">}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">validation_step_outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">log</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log</span>
</code></pre></div></div>

<h4 id="23-callbacks">2.3 callbacks</h4>

<p>这里如果我们觉得上面这些无法满足我们的日常训练、预测的需求，那么完全可以再增加一些其他需要的第三方和自己定义的callbacks，当然pytorch_lightning其实已经封装了很多常用的callbacks了，比如下面的几个常用的：</p>

<ul>
  <li>
    <p>模型定义怎么保存ckpt：<code class="language-plaintext highlighter-rouge">ModelCheckpoint</code></p>
  </li>
  <li>
    <p>如何定义训练及早停止：<code class="language-plaintext highlighter-rouge">MINISTCallBack</code></p>
  </li>
  <li>
    <p>定义进度条：<code class="language-plaintext highlighter-rouge">TQDMProgressBar</code></p>
  </li>
</ul>

<p>当然了，我们想定义属于自己的callback怎么弄呢：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MINISTCallBack</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">MINISTCallBack</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="sh">"</span><span class="s">pl.Trainer</span><span class="sh">"</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="sh">"</span><span class="s">pl.LightningModule</span><span class="sh">"</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Predict is ending</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">trainer</span> <span class="p">:</span> <span class="sh">"</span><span class="s">pl.Trainer</span><span class="sh">"</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="sh">"</span><span class="s">pl.LightningModule</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">epoch_mean_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pl_module</span><span class="p">.</span><span class="n">training_step_outputs</span><span class="p">]).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">epoch_mean_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">train_acc</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pl_module</span><span class="p">.</span><span class="n">training_step_outputs</span><span class="p">]).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">pl_module</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">"</span><span class="s">train/loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">epoch_mean_loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">pl_module</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">"</span><span class="s">train/acc</span><span class="sh">"</span><span class="p">,</span> <span class="n">epoch_mean_acc</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">pl_module</span><span class="p">.</span><span class="n">training_step_outputs</span><span class="p">.</span><span class="nf">clear</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">on_validation_epoch_end</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="sh">"</span><span class="s">pl.Trainer</span><span class="sh">"</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">:</span> <span class="sh">"</span><span class="s">pl.LightningModule</span><span class="sh">"</span><span class="p">):</span>
        <span class="n">epoch_mean_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pl_module</span><span class="p">.</span><span class="n">validation_step_outputs</span><span class="p">]).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">epoch_mean_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">val_acc</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pl_module</span><span class="p">.</span><span class="n">validation_step_outputs</span><span class="p">]).</span><span class="nf">mean</span><span class="p">()</span>

        <span class="n">pl_module</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">'</span><span class="s">val/loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">epoch_mean_loss</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">pl_module</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="sh">'</span><span class="s">val/acc</span><span class="sh">'</span><span class="p">,</span> <span class="n">epoch_mean_acc</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">pl_module</span><span class="p">.</span><span class="n">validation_step_outputs</span><span class="p">.</span><span class="nf">clear</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="24-调用">2.4 调用</h4>

<p>当我们都写完了上述我们定义好的数据模块，训练预测模块，那么如何使用呢？pytorch_lightning这里用了一个专门的类Trainer来调用。</p>

<p><strong>训练调用</strong>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">,</span>
                      <span class="c1"># resume_from_checkpoint = 'ckpts/exp3/epoch=7.ckpt', # 断点续训
</span>                      <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                      <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
                      <span class="n">enable_model_summary</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># 显示模型构造
</span>                      <span class="n">accelerator</span><span class="o">=</span><span class="sh">'</span><span class="s">auto</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">devices</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># 多少个设备
</span>                      <span class="n">deterministic</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                      <span class="n">num_sanity_val_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># 正式训练之前跑一次validation 测试程序是否出错
</span>                      <span class="n">benchmark</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># cudnn加速训练（要确保每个batch同一个大小）
</span>                      <span class="p">)</span>
    <span class="c1"># mnist_model.load_from_checkpoint('ckpts/exp3/epoch=7.ckpt')
</span>    <span class="n">trainer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">mnist_model</span><span class="p">,</span><span class="n">mnist_data</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>预测调用</strong>，可以定义一个dataloader，也可以定义测试的数据模块，同时也能直接对单一一个tensor作为输入，进行预测：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rs</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">mnist_model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">test_loader</span><span class="p">)</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">mnist_model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">test_datamodule</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="三-分布式训练">三. 分布式训练</h3>

<p>pytorch_lightning也支持分布式，但是它只支持pytorch原生的DDP，作为被HuggingFace的accelerate圈粉的我。。。只能退坑了，拜拜👋🏻</p>]]></content><author><name>李小肥的YY</name></author><category term="深度学习" /><summary type="html"><![CDATA[记录pytorch_lightning的使用过程心得体会]]></summary></entry><entry><title type="html">配置python远程环境</title><link href="http://localhost:4000/%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html" rel="alternate" type="text/html" title="配置python远程环境" /><published>2023-12-28T08:00:00+08:00</published><updated>2023-12-28T08:00:00+08:00</updated><id>http://localhost:4000/%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83</id><content type="html" xml:base="http://localhost:4000/%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html"><![CDATA[<blockquote>
  <p>由于工作基本基于python，所以本文主要记录配置远程linux的python环境</p>
</blockquote>

<h3 id="一-定义docker位置">一. 定义Docker位置</h3>

<blockquote>
  <p>为什么要修改docker存储的位置？ 因为往往docker的缓存过大，导致最后打的镜像多了，最后占满空间了</p>
</blockquote>

<p>步骤：</p>

<ul>
  <li>获取当前docker所在存储位置：<code class="language-plaintext highlighter-rouge">docker info | grep "Docker Root Dir"</code></li>
  <li>停止docker服务：<code class="language-plaintext highlighter-rouge">systemctl stop docker</code></li>
  <li>移动整个路径至新路径：<code class="language-plaintext highlighter-rouge">mv /var/lib/docker /data/docker</code></li>
  <li>创建软连接：<code class="language-plaintext highlighter-rouge">ln -s /data/docker /var/lib/docker</code></li>
  <li>重启docker服务：<code class="language-plaintext highlighter-rouge">systemctl start docker</code></li>
  <li>可以通过第一个命令查看现在的docker存储路径</li>
</ul>

<h3 id="二-安装python3或则conda">二. 安装python3或则conda</h3>

<blockquote>
  <p>这里推荐安装conda，环境切换方便</p>
</blockquote>

<h4 id="21-python3的安装">2.1 python3的安装</h4>

<h5 id="211-前期准备">2.1.1 前期准备</h5>

<blockquote>
  <p>注意这里需要将openssl升级到1.0.2，因为不然pip3 安装包的时候会出现无法访问http请求。</p>
</blockquote>

<p>步骤：</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#安装openssl 1.0.2r版本</span>
<span class="nb">cd</span> /home/install
wget http://www.openssl.org/source/openssl-1.0.2r.tar.gz <span class="c">#下载openssl包</span>
<span class="nb">tar</span> <span class="nt">-zxvf</span> openssl-1.0.2r.tar.gz <span class="c">#解压</span>
<span class="nb">cd </span>openssl-1.0.2r    <span class="c">#进入文件夹</span>
./config shared zlib <span class="c">#配置</span>
make <span class="o">&amp;&amp;</span> make <span class="nb">install</span> <span class="c">#解析和安装</span>
make clean //清除掉配置编译的一些文件
<span class="nb">rm</span> <span class="nt">-rf</span> openssl<span class="k">*</span> <span class="c">#删除 可以保留</span>
<span class="nb">mv</span> /usr/bin/openssl /usr/bin/openssl.bak <span class="c">#复制老的做备份</span>
<span class="nb">mv</span> /usr/include/openssl /usr/include/openssl.bak <span class="c">#复制老的做备份</span>
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/local/ssl/bin/openssl /usr/bin/openssl <span class="c">#建立新的软链接 usr/local/ssl/为安装路径</span>
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/local/ssl/include/openssl /usr/include/openss <span class="c">#建立新的软链接 usr/local/ssl/为安装路径</span>
<span class="nb">echo</span> <span class="s2">"/usr/local/ssl/lib"</span> <span class="o">&gt;&gt;</span> /etc/ld.so.conf <span class="c">#写入openssl库文件的搜索路径</span>
ldconfig <span class="nt">-v</span> <span class="c">#使修改后的/etc/ld.so.conf生效</span>
openssl version <span class="c">#查看新版号</span>
</code></pre></div></div>

<h5 id="212-安装python38">2.1.2 安装python3.8</h5>

<ul>
  <li>安装依赖包：<code class="language-plaintext highlighter-rouge">yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make libffi-devel</code></li>
  <li>安装wget：<code class="language-plaintext highlighter-rouge">yum install wget</code></li>
  <li>下载python3.8源码包：<code class="language-plaintext highlighter-rouge">wget https://www.python.org/ftp/python/3.8.1/Python-3.8.1.tgz</code></li>
  <li>解压压缩包：<code class="language-plaintext highlighter-rouge">tar -zxvf Python-3.8.1.tgz</code></li>
  <li>进入文件夹：<code class="language-plaintext highlighter-rouge">cd Python-3.8.1</code></li>
  <li>配置安装目录并指定使用openssl： <code class="language-plaintext highlighter-rouge">./configure --prefix=/usr/local/python3 --with-openssl=/usr/local/ssl</code></li>
  <li>编译安装：<code class="language-plaintext highlighter-rouge">make &amp;&amp; make install</code></li>
  <li>查看python3的路径：<code class="language-plaintext highlighter-rouge">which python3</code> 我们可以看到在<code class="language-plaintext highlighter-rouge">/usr/local/bin/python3</code></li>
  <li>添加python3的软链接：<code class="language-plaintext highlighter-rouge">ln -s /usr/local/python3/bin/python3.8 /usr/local/bin/python3</code></li>
  <li>添加 pip3 的软链接：<code class="language-plaintext highlighter-rouge">ln -s /usr/local/python3/bin/pip3.8 /usr/local/bin/pip3</code></li>
  <li>如果上述无法添加软连接，直接删除之前创建的软连接再次添加即可：<code class="language-plaintext highlighter-rouge">rm -rf /usr/local/bin/python3</code>和<code class="language-plaintext highlighter-rouge">rm -rf /usr/local/bin/pip3</code></li>
</ul>

<h5 id="213-设定pippip3源">2.1.3 设定pip/pip3源</h5>

<blockquote>
  <p>为什么要指定源，下载速度更快</p>
</blockquote>

<p>步骤：</p>

<ul>
  <li>进入个人目录：<code class="language-plaintext highlighter-rouge">cd ~</code></li>
  <li>创建文件夹：<code class="language-plaintext highlighter-rouge">mkdir .pip</code></li>
  <li>进入pip文件夹：<code class="language-plaintext highlighter-rouge">cd .pip</code></li>
  <li>编辑文件pip.conf：</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>global]
index-url<span class="o">=</span>https://pypi.mirrors.ustc.edu.cn/simple
</code></pre></div></div>

<h4 id="22-安装conda">2.2 安装conda</h4>

<h5 id="221-下载minicoda并安装">2.2.1 下载minicoda并安装</h5>

<blockquote>
  <p>官网地址：<a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda — conda documentation</a></p>
</blockquote>

<ul>
  <li>
    <p>下载安装包之后，执行命令：<code class="language-plaintext highlighter-rouge">sh Miniconda3-latest-Linux-x86_64.sh</code></p>
  </li>
  <li>
    <p>安装完成后，查看conda版本是否安装成功，这里最好关掉当前窗口，新开一个：<code class="language-plaintext highlighter-rouge">conda --version</code></p>
  </li>
</ul>

<h5 id="222-创建虚拟环境">2.2.2 创建虚拟环境</h5>

<ul>
  <li>
    <p>安装python3.8的python环境：<code class="language-plaintext highlighter-rouge">conda create -n chatglm python=3.8</code></p>
  </li>
  <li>
    <p>查看虚拟环境（当前是在base环境）：<code class="language-plaintext highlighter-rouge">conda env list</code></p>
  </li>
  <li>
    <p>进入创建的chatglm环境：<code class="language-plaintext highlighter-rouge">conda activate chatglm</code></p>
  </li>
  <li>
    <p>推出chatglm环境：<code class="language-plaintext highlighter-rouge">conda deactivate</code></p>
  </li>
  <li>
    <p>删除chatglm环境：<code class="language-plaintext highlighter-rouge">conda remove -n chatglm --all</code></p>
  </li>
  <li>
    <p>退出conda的所有环境（首先要先回到conda的base环境）：<code class="language-plaintext highlighter-rouge">conda deactivate</code></p>
  </li>
  <li>
    <p>直接进入conda的指定环境：<code class="language-plaintext highlighter-rouge">conda activate chatglm</code></p>
  </li>
  <li>
    <p>复制conda环境：<code class="language-plaintext highlighter-rouge">conda create -n new_env --clone base</code></p>
  </li>
</ul>

<h5 id="223-自动切换到指定的env环境">2.2.3 自动切换到指定的env环境</h5>

<p>由于每次连上linux后，发现conda的环境都是base环境，但是想要自己工作的env环境就需要来回切换，很不方便。所以这里推荐设置每次自动切换到指定的env环境</p>

<ul>
  <li>新增<code class="language-plaintext highlighter-rouge">.zshrc</code>一行：<code class="language-plaintext highlighter-rouge">source activate my_env</code></li>
</ul>

<h3 id="三-配置vscode远程pycharm远程">三. 配置vscode远程+pycharm远程</h3>

<h4 id="31-vscode远程免密登陆">3.1 vscode远程+免密登陆</h4>

<p>步骤：</p>

<ul>
  <li>在本地机器生成密钥对(公钥+私钥)：ssh-keygen</li>
  <li>私钥放本机，公钥放远程(~/.ssh路径下)</li>
  <li>在远程机器用公钥生成authorized_keys：</li>
  <li>进入home目录下的.ssh文件夹：cd ~/.ssh <code class="language-plaintext highlighter-rouge">cat id_rsa.pub &gt;&gt; authorized_keys</code></li>
  <li>vscode config文件加入本机私钥路径</li>
</ul>

<h4 id="32-pycharm远程">3.2 pycharm远程</h4>

<p>步骤：</p>

<ul>
  <li>
    <p>新建一个工作目录，同时在远端也新建一个同名目录</p>
  </li>
  <li>
    <p>然后选择远程conda的python解释器，同时将本地目录和远程目录进行映射</p>
  </li>
  <li>
    <p>在deployment的configuration下配置登录远程的账号密码</p>
  </li>
</ul>

<h3 id="四-美化terminal">四. 美化terminal</h3>

<ul>
  <li>安装 zsh：<code class="language-plaintext highlighter-rouge">yum install -y zsh</code></li>
  <li>切换默认 Shell 为 zsh：<code class="language-plaintext highlighter-rouge">chsh -s /bin/zsh</code></li>
  <li>安装 Oh My Zsh：<code class="language-plaintext highlighter-rouge">sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"</code></li>
  <li>显示绝对路径：<code class="language-plaintext highlighter-rouge">vim ~/.oh-my-zsh/themes/robbyrussell.zsh-theme</code></li>
  <li>修改这行，把c改成d：<code class="language-plaintext highlighter-rouge">PROMPT+=' %{$fg[cyan]%}%d%{$reset_color%} $(git_prompt_info)'</code></li>
</ul>]]></content><author><name>李小肥的YY</name></author><category term="代码" /><summary type="html"><![CDATA[记录配置远程linux的python环境]]></summary></entry></feed>