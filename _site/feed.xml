<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-12-29T22:27:45+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">凡人炼丹传</title><subtitle>欢迎各位看官光临本小站，希望共同学习进步哈！</subtitle><author><name>李小肥的YY</name></author><entry><title type="html">面试基础总结</title><link href="http://localhost:4000/%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html" rel="alternate" type="text/html" title="面试基础总结" /><published>2021-12-13T05:11:00+08:00</published><updated>2021-12-13T05:11:00+08:00</updated><id>http://localhost:4000/%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93</id><content type="html" xml:base="http://localhost:4000/%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html"><![CDATA[<h3 id="一-操作系统">一. 操作系统</h3>

<h4 id="11-并行和并发">1.1 并行和并发</h4>

<p><strong>并发</strong>：在操作系统中，某一时间段，几个程序在同一个CPU上运行，但在任意一个时间点上，只有一个程序在CPU上运行。</p>

<p><strong>并行</strong>：当操作系统有多个CPU时，一个CPU处理A线程，另一个CPU处理B线程，<strong>两个线程互相不抢占CPU资源，可以同时进行</strong>，这种方式成为并行。</p>

<p>知乎的例子：</p>

<ul>
  <li>你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。</li>
  <li>你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。</li>
  <li>你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。</li>
</ul>

<h4 id="12-进程和线程">1.2 进程和线程</h4>

<h5 id="121-进程">1.2.1 进程</h5>

<p>​	<strong>进程是资源分配的基本单位，理解为一个程序</strong>。所以我们一般都要求进程池的进程数小于等于CPU的核心数。</p>

<p>​	如果问<strong>单核CPU能否运行多进程？</strong>答案又是肯定的。单核CPU也可以运行多进程，只不过不是同时的，而是极快地在<strong>进程间来回切换实现的多进程</strong>。进<strong>程拥有自己的地址空间，全局变量，文件描述符，各种硬件等等资源</strong>。</p>

<h5 id="122-线程">1.2.2 线程</h5>

<p>​	<strong>线程</strong>：线程是依赖于进程的。<strong>如果说进程和进程之间相当于程序与程序之间的关系，那么线程与线程之间就相当于程序内的任务和任务之间的关系。</strong></p>

<p>​	一个程序内包含了多种任务。加上了线程之后，线程能够共享进程的大部分资源，并参与CPU的调度。意味着它能够在<strong>进程间进行切换，实现并发</strong>。</p>

<h5 id="123-为什么要用多进程适用条件">1.2.3 为什么要用多进程，适用条件</h5>

<p>​	总是在运行一个进程上的任务，就会出现一个现象。就是任务不一定总是在执行 ”计算型“ 的任务，会有很大可能是在执行网络调用，阻塞了，CPU 岂不就浪费了？</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_1.jpg" alt="" /></p>

<p>因此，多进程适用于<strong>CPU密集型任务(各种循环处理、计算等等)</strong>。多线程适用于<strong>IO密集型任务(文件处理、网络爬虫等)</strong>。</p>

<h5 id="124-多进程通信">1.2.4 多进程通信</h5>

<p><strong>管道pipe</strong>：管道是一种<strong>半双工</strong>的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指<strong>父子进程关系</strong>。类似于python的<code class="language-plaintext highlighter-rouge">multiprocessing.Pipe()</code></p>

<p><strong>消息队列MessageQueue</strong>：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。类似于python的<code class="language-plaintext highlighter-rouge">multiprocessing.Queue()</code></p>

<p><strong>共享存储SharedMemory</strong>：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。<strong>共享内存是最快的 IPC 方式</strong>，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。</p>

<h5 id="125-python的多线程是真的多线程么">1.2.5 python的多线程是真的多线程么</h5>

<p>​	Python在设计之初就考虑要在主循环中，同时只有一个线程在执行，就像单CPU的系统中运行多个进程那样，内存中可以存放多个程序，但任意时刻，只有一个程序在CPU中运行。同样地，虽然Python解释器可以运行多个线程，只有一个线程在解释器中运行。</p>

<p>​	Python虚拟机的访问由<strong>全局解释器锁（GIL）</strong>来控制，正是这个锁能保证同时只有一个线程在运行。</p>

<p><strong>Python的多进程多线程测试</strong>：</p>

<ul>
  <li>
    <p>在一个4核CPU上开4线程，发现电脑的CPU利用率没有占满，大致相当于单核水平。</p>
  </li>
  <li>
    <p>在一个4核CPU上开4进程，发现CPU直接飙到了100%，说明进程是可以利用多核的！</p>

    <p>Python多线程相当于单核多线程，多线程有两个好处：<strong>CPU并行，IO并行</strong>，单核多线程相当于自断一臂。所以，在Python中，可以使用多线程，但不要指望能有效利用多核。</p>
  </li>
</ul>

<h5 id="126-多线程如何保证线程安全">1.2.6 多线程如何保证线程安全</h5>

<p>当<strong>多个线程同时操作同一个共享全局变量</strong>的时候，就容易出现线程安全问题，线程安全问题只会影响到线程对同一个共享的全局变量的<strong>写操作</strong>。</p>

<p>利用<strong>线程锁</strong>来保证同一个时刻，有且仅有一个线程对共享的全局变量进行写操作。且开始写操作前，需要<strong>加锁</strong>，完成后，需要<strong>解锁</strong>，让其他线程再对其进行写操作。</p>

<h5 id="127-死锁问题">1.2.7 死锁问题</h5>

<p>​	<strong>死锁</strong>是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于<strong>彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去</strong>。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_2.jpg" alt="" /></p>

<p>死锁的<strong>4个必要条件</strong>：</p>

<ul>
  <li>互斥条件：线程(进程)对于所分配到的资源具有排它性，即<strong>一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放</strong>。</li>
  <li>请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，<strong>对已获得的资源保持不放</strong>。</li>
  <li>不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，<strong>只有自己使用完毕后才释放资源</strong>。</li>
  <li>循环等待条件：当发生死锁时，所等待的线程(进程)必定会<strong>形成一个环路（类似于死循环），造成永久阻塞</strong></li>
</ul>

<p><strong>如何避免死锁？</strong></p>

<p>只要破坏产生死锁的四个条件中的其中一个就可以了。</p>

<ul>
  <li><strong>破坏互斥条件</strong>：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。</li>
  <li><strong>破坏请求与保持条件</strong>：一次性申请所有的资源。</li>
  <li><strong>破坏不剥夺条件</strong>：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</li>
  <li><strong>破坏循环等待条件</strong>：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。</li>
</ul>

<h4 id="13-同步和异步">1.3 同步和异步</h4>

<h5 id="131-阻塞和非阻塞">1.3.1 阻塞和非阻塞</h5>

<ul>
  <li>
    <p>阻塞：指调用线程或者进程被操作系统挂起。</p>
  </li>
  <li>
    <p>非阻塞：指调用线程或者进程不会被操作系统挂起。</p>
  </li>
</ul>

<h5 id="132-同步和异步">1.3.2 同步和异步</h5>

<p>同步是阻塞模式，异步是非阻塞模式。</p>

<ul>
  <li>同步：指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么<strong>这个进程将会一直等待下去，直到收到返回信息才继续执行下去</strong>。</li>
  <li>异步：指<strong>进程不需要一直等下去，而是继续执行下面的操作</strong>，不管其他进程的状态。当有消息返回式系统会通知进程进行处理，这样可以提高执行的效率。</li>
</ul>

<h4 id="14-协程">1.4 协程</h4>

<p>协程是一种用户态的轻量级线程。</p>

<p>子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。<strong>所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。</strong></p>

<p>协程看上去也是子程序，但执行过程中，在<strong>子程序内部可中断</strong>，然后转而执行别的子程序，在适当的时候再返回来接着执行。</p>

<p>例子：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">A</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">2</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">3</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">B</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p>假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 2 x y 3 z
</code></pre></div></div>

<p>但是在A中是没有调用B的，<strong>看起来A、B的执行有点像多线程，但协程的特点在于是一个线程执行</strong></p>

<p><strong>协程的优势：</strong></p>

<ul>
  <li>极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</li>
  <li>不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</li>
</ul>

<h4 id="14-内存分配管理">1.4 内存分配管理</h4>

<h5 id="141-分段和分页">1.4.1 分段和分页</h5>

<p><strong>分段</strong>：在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个<strong>二维地址空间</strong>，相互独立，互不干扰。</p>

<p><strong>分页</strong>：在页式存储管理中，将程序的<strong>逻辑地址划分为固定大小的页（page）</strong>，而<strong>物理内存</strong>划分为同样大小的<strong>帧</strong>，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。</p>

<h5 id="142-分段和分页不同点">1.4.2 分段和分页不同点</h5>

<ul>
  <li>段是信息的<strong>逻辑单位</strong>，它是根据<strong>用户的需要</strong>划分的，因此段对用户是可见的 ；页是信息的<strong>物理单位</strong>，是为了<strong>管理主存</strong>的方便而划分的，对用户是透明的。</li>
  <li>段的大小<strong>不固定</strong>，有它所完成的功能决定；页大大小<strong>固定</strong>，由系统决定</li>
  <li>段向用户提供<strong>二维地址空间</strong>；页向用户提供的是<strong>一维地址空间</strong></li>
  <li>段是信息的逻辑单位，便于<strong>存储保护和信息的共享</strong>，页的保护和共享<strong>受到限制</strong>。</li>
  <li>段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）；页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）</li>
</ul>

<h5 id="143-堆和栈">1.4.3 堆和栈</h5>

<p>对于一个由C/C++编译的程序，其所占用的内存可以划分为以下几个部分：</p>

<ul>
  <li>
    <p><strong>栈区（stack）</strong>—— 由操作系统自动分配和释放，主要用于存放<strong>函数参数值，局部变量</strong>等。其操作方式类似于数据结构中的栈。</p>
  </li>
  <li>
    <p><strong>堆区（heap）</strong>—— 一般由<strong>程序员动态分配和释放(malloc，free)</strong>，若程序员不主动释放，则程序结束后由操作系统回收。注意，它与数据结构中的堆是不同的，分配方式类似于链表。</p>
  </li>
  <li>
    <p><strong>BSS段</strong>——主要用于存放未<strong>初始化的静态变量和全局变量</strong>，可读写，它在程序结束后由操作系统进行释放。</p>
  </li>
  <li><strong>数据段（data）</strong>——主要用于<strong>存放已初始化的静态变量和全局变量</strong>，可读写，它在程序结束后由操作系统释放。</li>
  <li><strong>代码段（text）</strong>——主要用于<strong>保存程序代码，包括CPU执行的机器指令，同时全局常量也是保存在代码段的，如字符串字面值</strong>。</li>
</ul>

<h5 id="144-一个进程的内存结构">1.4.4 一个进程的内存结构</h5>
<pre><code class="language-C++">/main.cpp
int a = 0;                       // 全局初始化区域
char *p1;                        // 全局未初始化区域
int main(){
    int b;                       // 栈
    char s[] = "adoryn";         // 栈
    char *p2;                    // 栈
    char *p3 = "zhaobryant";     // 字符串字面量存放在常量区，p3存放在栈上
    static int c = 0;            // 全局（静态）初始化区域
    p1 = (char *)malloc(10);
    p2 = (char *)malloc(20);     // 分配获得的10和20字节的内存区放在堆区
    strcpy(p1, "zhaobryant");    // 字符串字面量存放在常量区，编译器可能会将它与p3所指向的"zhaobryant"优化为同一个地址
    return 0;
}
</code></pre>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_3.jpg" alt="" /></p>

<h3 id="二-linux相关">二. linux相关</h3>

<h4 id="21-查看cpu和内存占用情况">2.1 查看CPU和内存占用情况</h4>

<ul>
  <li>
    <p>查看物理内存使用情况：<code class="language-plaintext highlighter-rouge">free</code></p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_4.jpg" alt="" /></p>
  </li>
  <li>
    <p>查看目前正在运行的进程所占的内存百分比和CPU百分比：<code class="language-plaintext highlighter-rouge">top</code>。<strong>假如某个进程显示400%，说明该程序利用了4核CPU。</strong></p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_5.jpg" alt="" /></p>
  </li>
  <li>
    <p>查看磁盘使用情况：<code class="language-plaintext highlighter-rouge">df</code></p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_6.jpg" alt="" /></p>
  </li>
  <li>
    <p>查看当前进程：<code class="language-plaintext highlighter-rouge">ps</code>，<code class="language-plaintext highlighter-rouge">ps -aux</code>则是当前所有的正在内存当中的程序</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_7.jpg" alt="" /></p>
  </li>
</ul>

<h4 id="22-查找匹配">2.2 查找匹配</h4>

<ul>
  <li>
    <p>在某个路径下查找是否有某个<strong>文件</strong>：<code class="language-plaintext highlighter-rouge">find 路径 -name 文件名</code></p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_8.jpg" alt="" /></p>
  </li>
  <li>
    <p>根据<strong>字符串</strong>查找相应匹配的<strong>文件</strong>：<code class="language-plaintext highlighter-rouge">grep</code>。它是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。</p>

    <ul>
      <li>
        <p>查找后缀有 py 字样的文件中包含 print 字符串的文件（当前路径下）：<code class="language-plaintext highlighter-rouge">grep print *.py</code></p>

        <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_9.jpg" alt="" /></p>
      </li>
      <li>
        <p>递归查找符合条件的<strong>文件</strong>，这里是查找指定目录（git_repo）下及其子目录所有文件中包含helloworld字符串的文件</p>

        <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_10.jpg" alt="" /></p>
      </li>
      <li>
        <p>联合<code class="language-plaintext highlighter-rouge">ps</code>检查当前进程中python3进程是否运行：<code class="language-plaintext highlighter-rouge">ps -aux | grep python3</code>。其中<code class="language-plaintext highlighter-rouge">|</code>是管道命令 是指ps命令与grep同时执行。</p>

        <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_11.jpg" alt="" /></p>
      </li>
    </ul>
  </li>
</ul>

<h4 id="23-网络相关">2.3 网络相关</h4>

<ul>
  <li>
    <p>显示各种网络相关信息：<code class="language-plaintext highlighter-rouge">netstat</code></p>

    <ul>
      <li>列出所有处于监听状态的Sockets</li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>netstat <span class="nt">-l</span> <span class="c"># 只显示监听端口</span>
netstat <span class="nt">-lt</span> <span class="c">#只列出所有监听 tcp 端口</span>
netstat <span class="nt">-lu</span> <span class="c">#只列出所有监听 udp 端口</span>
netstat <span class="nt">-lx</span> <span class="c">#只列出所有监听 UNIX 端口</span>
</code></pre></div>    </div>

    <ul>
      <li>配合<code class="language-plaintext highlighter-rouge">grep</code>查找tcp下的指定端口号信息</li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>netstat <span class="nt">-plnt</span> | <span class="nb">grep</span> :53
<span class="c"># -p 输出中显示 PID 和进程名称</span>
<span class="c"># -l 仅列出有在 Listen (监听) 的服务状态</span>
<span class="c"># -n 不想让主机，端口和用户名显示，而是用ip显示</span>
<span class="c"># -t 只列出所有监听 tcp 端口</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="24-selectpoll和epoll">2.4 select、poll和epoll</h4>

<h5 id="用户空间和内核空间">用户空间和内核空间</h5>

<p>操作系统的核心是<strong>内核</strong>，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。</p>

<p>为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为<strong>内核空间（供内核使用）</strong>，一部分为<strong>用户空间（供进程使用）</strong>。</p>

<h5 id="进程切换">进程切换</h5>

<p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为<strong>进程切换</strong>。</p>

<p>进程的切换需要经过以下变换：</p>

<ol>
  <li>保存处理机上下文，包括程序计数器和其他寄存器。</li>
  <li>更新PCB信息。</li>
  <li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</li>
  <li>选择另一个进程执行，并更新其PCB。</li>
  <li>更新内存管理的数据结构。</li>
  <li>恢复处理机上下文。</li>
</ol>

<h5 id="进程阻塞">进程阻塞</h5>

<p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。</p>

<p>进程的阻塞是进程自身的一种<strong>主动行为</strong>，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p>

<h5 id="文件描述符fd">文件描述符fd</h5>

<p>文件描述符在形式上是一个非负整数。实际上，它是一个<strong>索引值</strong>，指向内核为每一个进程所维护的该进程打开文件的记录表。</p>

<p>当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。</p>

<h5 id="缓存io">缓存IO</h5>

<p>在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p>

<p><strong>缓存 I/O 的缺点：</strong>数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p>

<h5 id="socket">Socket</h5>

<p>socket是一种”打开—读/写—关闭”模式的实现，服务器和客户端各自维护一个”文件”，在建立连接打开后，可以向自己文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。</p>

<h5 id="io多路复用">IO多路复用</h5>

<p>IO multiplexing就是我们说的select，poll，epoll。</p>

<p>select/epoll的好处就在于<strong>单个process就可以同时处理多个网络连接的IO</strong>。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。</p>

<h5 id="select">select</h5>

<p>调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。</p>

<p>select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024</p>

<h5 id="poll">poll</h5>

<p>不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。</p>

<p>pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</p>

<blockquote>
  <p>从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。</p>
</blockquote>

<h5 id="epoll">epoll</h5>

<p>相对于select和poll来说，epoll更加灵活，没有描述符限制。<strong>epoll使用一个文件描述符管理多个描述符</strong>，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。</p>

<p>epoll对文件描述符的操作有两种模式，<strong>LT（level trigger）</strong>和<strong>ET（edge trigger）</strong>。LT模式是默认模式，LT模式与ET模式的区别如下：　　</p>

<ul>
  <li><strong>LT模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。　　</li>
  <li><strong>ET模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</li>
</ul>

<p>在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而<strong>epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知</strong>。</p>

<p><strong>epoll的优点主要是以下个方面：</strong></p>

<ol>
  <li>监视的描述符数量不受限制</li>
  <li>IO的效率不会随着监视fd的数量的增长而下降</li>
</ol>

<h4 id="25-tcp三握四挥">2.5 TCP三握四挥</h4>

<h5 id="三次握手">三次握手</h5>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_12.jpg" alt="" /></p>

<p>如图所示，双方之间的三个蓝色箭头就表示了三次握手过程中所发生的数据交换：</p>

<ol>
  <li>第一次握手：客户端向服务器发送报文段1，其中的 SYN 标志位 (前文已经介绍过各种标志位的作用)的值为 1，表示这是一个用于请求发起连接的报文段，其中的序号字段 (Sequence Number，图中简写为seq)被设置为初始序号x (Initial Sequence Number，ISN)，TCP 连接双方均可随机选择初始序号。发送完报文段1之后，客户端进入 SYN-SENT 状态，等待服务器的确认。</li>
  <li>第二次握手：服务器在收到客户端的连接请求后，向客户端发送报文段2作为应答，其中 ACK 标志位设置为 1，表示对客户端做出应答，其确认序号字段 (Acknowledgment Number，图中简写为小写 ack) 生效，该字段值为 x + 1，也就是从客户端收到的报文段的序号加一，代表服务器期望下次收到客户端的数据的序号。此外，报文段2的 SYN 标志位也设置为1，代表这同时也是一个用于发起连接的报文段，序号 seq 设置为服务器初始序号y。发送完报文段2后，服务器进入 SYN-RECEIVED 状态。</li>
  <li>第三次握手：客户端在收到报文段2后，向服务器发送报文段3，其 ACK 标志位为1，代表对服务器做出应答，确认序号字段 ack 为 y + 1，序号字段 seq 为 x + 1。此报文段发送完毕后，双方都进入 ESTABLISHED 状态，表示连接已建立。</li>
</ol>

<p><strong>常见面试题 1：</strong> TCP 建立连接为什么要三次握手而不是两次？</p>

<ul>
  <li>防止已过期的连接请求报文突然又传送到服务器，因而产生错误</li>
  <li>三次握手才能让双方均确认自己和对方的发送和接收能力都正常</li>
  <li>告知对方自己的初始序号值，并确认收到对方的初始序号值</li>
</ul>

<p><strong>常见面试题2：</strong> TCP 建立连接为什么要三次握手而不是四次？</p>

<ul>
  <li>相比上个问题而言，这个问题就简单多了。因为三次握手已经可以确认双方的发送接收能力正常，双方都知道彼此已经准备好，而且也可以完成对双方初始序号值得确认，也就无需再第四次握手了。</li>
</ul>

<h5 id="四次挥手">四次挥手</h5>

<p>建立一个连接需要三次握手，而终止一个连接要经过 4次握手。这由 TCP 的半关闭( half-close) 造成的。既然一个 TCP 连接是全双工 (即数据在两个方向上能同时传递)， 因此每个方向必须单独地进行关闭。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_13.jpg" alt="" /></p>

<p>四次挥手详细过程如下：</p>

<ol>
  <li>客户端发送关闭连接的报文段，FIN 标志位1，请求关闭连接，并停止发送数据。序号字段 seq = x (等于之前发送的所有数据的最后一个字节的序号加一)，然后客户端会进入 FIN-WAIT-1 状态，等待来自服务器的确认报文。</li>
  <li>服务器收到 FIN 报文后，发回确认报文，ACK = 1， ack = x + 1，并带上自己的序号 seq = y，然后服务器就进入 CLOSE-WAIT 状态。服务器还会通知上层的应用程序对方已经释放连接，此时 TCP 处于半关闭状态，也就是说客户端已经没有数据要发送了，但是服务器还可以发送数据，客户端也还能够接收。</li>
  <li>客户端收到服务器的 ACK 报文段后随即进入 FIN-WAIT-2 状态，此时还能收到来自服务器的数据，直到收到 FIN 报文段。</li>
  <li>服务器发送完所有数据后，会向客户端发送 FIN 报文段，各字段值如图所示，随后服务器进入 LAST-ACK 状态，等待来自客户端的确认报文段。</li>
  <li>客户端收到来自服务器的 FIN 报文段后，向服务器发送 ACK 报文，随后进入 TIME-WAIT 状态，等待 2MSL(2 * Maximum Segment Lifetime，两倍的报文段最大存活时间) ，这是任何报文段在被丢弃前能在网络中存在的最长时间，常用值有30秒、1分钟和2分钟。如无特殊情况，客户端会进入 CLOSED 状态。</li>
  <li>服务器在接收到客户端的 ACK 报文后会随即进入 CLOSED 状态，由于没有等待时间，一般而言，服务器比客户端更早进入 CLOSED 状态。</li>
</ol>

<h3 id="三-c">三. C++</h3>

<h4 id="31-stl中listvectormapset区别">3.1 STL中list,vector,map,set区别</h4>

<h5 id="vector">vector</h5>

<ul>
  <li>vector封装了数组，拥有<strong>一段连续的内存空间</strong>，并且<strong>起始地址不变</strong>。</li>
  <li>存取复杂度：能实现高效的随机<strong>存取</strong>，其时间复杂度为O(1)。</li>
  <li>增删复杂度：由于内存空间是连续的，因此<strong>插入</strong>和<strong>删除</strong>时，会造成内存块的拷贝，时间复杂度为O(n)。</li>
  <li>特别是当数组空间不足时，会重新申请一块内存空间（2倍）并进行拷贝。</li>
  <li>vector支持根据下标随机存取元素。其原因是“<strong>循秩访问</strong>”这种向量特有的元素访问方式。</li>
</ul>

<h5 id="list">list</h5>

<ul>
  <li>list 封装了链表，且是双向链表。因此<strong>内存空间是不连续的</strong>。</li>
  <li>每一个结点都维护一个信息块、一个前向指针和一个后向指针，因此支持前向/后向遍历。</li>
  <li>存取复杂度：只能通过指针访问数据，所以list的随机存取非常没有效率，时间复杂度为o(n)。原因是<strong>存储的对象是离散的，随机访问需要遍历整个链表</strong></li>
  <li>增删复杂度：在已经定位到要增删元素的位置的情况下，增删元素能在常数时间内完成，即O(1) 。可以<strong>不分配必须的内存大小方便的进行添加和删除</strong>操作。</li>
  <li>当要存储的是大型负责<strong>类对象</strong>时，list要优于vector。</li>
  <li>
    <p>list 容器不支持根据下标随机存取元素。<strong>不支持[ ]操作符和vector.at()</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_14.jpg" alt="" /></p>
  </li>
</ul>

<h5 id="map">map</h5>

<ul>
  <li>map的本质其实就是映射，键值（key-value）一一对应。</li>
  <li>map的实现是一颗<strong>红黑树</strong>，因此，map的内部键的数据都是排好序的，查找和删除、插入的效率都是n(logn)。</li>
  <li>multimap 允许一个键对应多个值；而map则是一个键对应一个值。</li>
</ul>

<h5 id="set">set</h5>

<ul>
  <li>所得元素的<strong>只有key没有value，value就是key</strong>。不允许键值的重复，即在set中<strong>每个元素的值都唯一</strong>。</li>
  <li>set的实现是一颗<strong>红黑树</strong>，因此，set的内部键的数据都是排好序的，查找和删除、插入的效率都是n(logn)。</li>
  <li><strong>set不能通过迭代器修改set元素值</strong>，其原因是set的值就是键。</li>
</ul>

<h4 id="32-虚函数">3.2 虚函数</h4>

<h5 id="虚函数使用条件">虚函数使用条件</h5>

<p>​	当基类指针指向一个子类对象，通过这个指针调用子类和基类<strong>同名成员函数</strong>的时候，基类声明为虚函数「子类不写也可以」就会调子类的这个函数，不声明就会调用基类的。关键字：<strong>virtual</strong></p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_15.jpg" alt="" /></p>

<h5 id="构造和析构可以是虚函数么">构造和析构可以是虚函数么</h5>

<p>​	<strong>构造不能为虚函数</strong>：如果构造函数是虚函数，那么就需要通过<strong>vtable（虚函数指针表）</strong> 来调用，但此时面对一块 raw memeory，到哪里去找 <strong>vtable</strong> 呢？毕竟，<strong>vtable</strong> 是在构造函数中才初始化的啊，而不是在其之前。因此构造函数不能为虚函数。</p>

<p>​	<strong>析构为虚函数</strong>：此时 vtable 已经初始化了；况且我们通常通过<strong>基类的指针来销毁对象</strong>，如果析构函数不为虚的话，就不能正确识别对象类型，从而不能正确销毁对象。</p>

<h5 id="虚函数可以是内联函数inline么">虚函数可以是内联函数(inline)么</h5>

<ul>
  <li>
    <p>内联函数：由于函数调用耗时长，因此<strong>在编译时将所调用的函数的代码直接嵌入到主调函数中</strong>，可以理解为<strong>内联函数体代码直接替换了调用函数这行代码</strong>。</p>
  </li>
  <li>虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。</li>
  <li>内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。</li>
</ul>

<h4 id="33-继承和多态">3.3 继承和多态</h4>

<p>C++有其三大特性：<strong>封装、继承和多态</strong>。</p>

<h5 id="继承">继承</h5>

<p>​	以让某个类型的对象，获得另一种类型对象属性的方法。实际上就是类与类之间可以共用代码，实现代码重用。可以理解为子类继承父类的方法。</p>

<p>​	例子：父类为Animal，其仅有2个成员函数，分别为bark()和eat()。子类为Dog，继承了父类的bark()和eat()，同时它还有自己的另一个方法run()。</p>

<h5 id="多态">多态</h5>

<p>​	多种形态，指一个类实例的相同方法在不同情况下有不同表现形式。</p>

<p>​	即子类可以重写父类的某个函数，从而为这个函数提供不同于父类的行为。<strong>一个父类的多个子类可以为同一个函数提供不同的实现</strong>，从而在父类这个公共的接口下，表现出多种行为。</p>

<p>​	例子：父类为Animal，其仅有2个成员函数，分别为bark()和eat()。子类为Dog，Cat，Snake，对于同一个方法bark()而言，不同的子类存在不同的喊叫方式，即为多态。</p>

<h5 id="区别">区别</h5>

<ul>
  <li>多态的实现要求必须是共有继承。</li>
  <li>继承关系中，并不要求基类方法一定是虚函数。而多态时，要求基类方法必须是虚函数。</li>
  <li>多态：子类重写父类的方法，使得子类具有不同的实现。且运行时，根据实际创建的对象动态决定使用哪个方法。</li>
</ul>

<h3 id="四-数据结构和算法">四. 数据结构和算法</h3>

<h4 id="41-排序算法">4.1 排序算法</h4>

<p>排序算法可以分为两大类：</p>

<ul>
  <li><strong>比较类排序</strong>：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序。这里比如冒泡、插入、快排、归并、堆排序等。</li>
  <li><strong>非比较类排序</strong>：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。 这里比如计数排序和位图排序。</li>
</ul>

<h5 id="算法复杂度">算法复杂度</h5>

<table>
  <thead>
    <tr>
      <th><strong>排序方法</strong></th>
      <th><strong>时间复杂度（平均）</strong></th>
      <th><strong>时间复杂度（最坏）</strong></th>
      <th><strong>时间复杂度（最好）</strong></th>
      <th><strong>空间复杂度</strong></th>
      <th><strong>稳定性</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>冒泡排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/fCuHGsq1VyabrY4.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/fCuHGsq1VyabrY4.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/SYbJGCZliqtu1R7.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/gHGzLTpifxBJ7oa.png" alt="" /></td>
      <td>稳定</td>
    </tr>
    <tr>
      <td><strong>插入排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/DLuPJ4IwE1Q9HNr.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/DLuPJ4IwE1Q9HNr.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/miW3p9T164cCOaR.png" alt="" /></td>
      <td>稳定</td>
    </tr>
    <tr>
      <td><strong>快速排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/fCuHGsq1VyabrY4.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td>不稳定</td>
    </tr>
    <tr>
      <td><strong>归并排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/5qMAQrFUsJfLTnb.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/5qMAQrFUsJfLTnb.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/5qMAQrFUsJfLTnb.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td>稳定</td>
    </tr>
    <tr>
      <td><strong>堆排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/qZTGoYNd89snwPD.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/gHGzLTpifxBJ7oa.png" alt="" /></td>
      <td>不稳定</td>
    </tr>
    <tr>
      <td><strong>计数排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/j4gCOS73LqwAXxv.png" alt="" /></td>
      <td>稳定</td>
    </tr>
    <tr>
      <td><strong>位图排序</strong></td>
      <td><img src="https://i.loli.net/2021/11/07/SYbJGCZliqtu1R7.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/SYbJGCZliqtu1R7.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/SYbJGCZliqtu1R7.png" alt="" /></td>
      <td><img src="https://i.loli.net/2021/11/07/gHGzLTpifxBJ7oa.png" alt="" /></td>
      <td>稳定</td>
    </tr>
  </tbody>
</table>

<h5 id="冒泡排序-bubble-sort">冒泡排序 Bubble sort</h5>

<p>​	它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。</p>

<p>算法步骤：</p>

<ul>
  <li>比较相邻的元素。如果第一个比第二个大，就交换它们两个；</li>
  <li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；</li>
  <li>针对所有的元素重复以上的步骤，除了最后一个；</li>
  <li>重复步骤1~3，直到排序完成。</li>
</ul>

<h5 id="插入排序-insertion-sort">插入排序 Insertion Sort</h5>

<p>​	它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p>

<p>算法步骤：</p>

<ul>
  <li>从第一个元素开始，该元素可以认为已经被排序；</li>
  <li>取出下一个元素，在已经排序的元素序列中从后向前扫描；</li>
  <li>如果该元素（已排序）大于新元素，将该元素移到下一位置；</li>
  <li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；</li>
  <li>将新元素插入到该位置后；</li>
  <li>重复步骤2~5。</li>
</ul>

<h5 id="快速排序-quick-sort">快速排序 Quick Sort</h5>

<p>​	通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。快速排序使用<strong>分治法</strong>来把一个串（list）分为两个子串（sub-lists）。</p>

<p>算法步骤：</p>

<ul>
  <li>从数列中挑出一个元素，称为 “基准”（pivot）；</li>
  <li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；</li>
  <li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</li>
</ul>

<h5 id="归并排序-merge-sort">归并排序 Merge Sort</h5>

<p>​	该算法是采用<strong>分治法</strong>（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。</p>

<p>算法步骤：</p>

<ul>
  <li>把长度为n的输入序列分成两个长度为n/2的子序列；</li>
  <li>对这两个子序列分别采用归并排序；</li>
  <li>将两个排序好的子序列合并成一个最终的排序序列。</li>
</ul>

<h5 id="堆排序-heap-sort">堆排序 Heap Sort</h5>

<p>​	利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点，大顶堆和小顶堆。</p>

<p>算法步骤：</p>

<ul>
  <li>将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；</li>
  <li>将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]；</li>
  <li>由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。</li>
</ul>

<h5 id="计数排序-counting-sort">计数排序 Counting Sort</h5>

<p>​	计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。</p>

<p>算法步骤：</p>

<ul>
  <li>找出待排序的数组中最大和最小的元素；</li>
  <li>统计数组中每个值为i的元素出现的次数，存入数组C的第i项；</li>
  <li>对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；</li>
  <li>反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。</li>
</ul>

<h5 id="位图排序-bitmap-sort">位图排序 Bitmap Sort</h5>

<p>​	位图排序是一种效率极高(复杂度可达O(n))并且很节省空间的一种排序方法，但是这种排序方法对输入的数据是有比较严格的要求(<strong>数据不能重复，大致知道数据的范围</strong>)。 位图排序即利用位图或者位向量来表示集合。</p>

<p><strong>参考的面试题</strong>：40亿个QQ号码，如果使用O(1)的时间复杂度去查找一个QQ号是否存在。</p>

<p>算法步骤：</p>

<ul>
  <li>根据待排序集合中最大的数，开辟一个位数组，用来表示待排序集合中的整数。</li>
  <li>待排序集合中的数字在位数组中的对应位置置1，其他的置0。</li>
  <li>将对应序号的整数放置到位对应的index上，并在每个对应的位上置位1.</li>
  <li>检验每一位，如果该位位1，输出对应的整数。</li>
</ul>

<h4 id="42-红黑树">4.2 红黑树</h4>

<h5 id="二叉查找树bst">二叉查找树(BST)</h5>

<p>特性：</p>

<ul>
  <li>
    <p><strong>左</strong>子树上所有结点的值均<strong>小于或等于</strong>它的根结点的值。</p>
  </li>
  <li>
    <p><strong>右</strong>子树上所有结点的值均<strong>大于或等于</strong>它的根结点的值。</p>
  </li>
  <li>
    <p>左、右子树也分别为二叉排序树。</p>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_16.jpg" alt="" /></p>

<p>根据二分查找的思想，查找的最大次数等同于树的高度。但是二叉查找树有其自身的缺陷：在多次出入新的节点后可能会出现不平衡现象，如下图。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_17.jpg" alt="" /></p>

<h5 id="红黑树rbt">红黑树（RBT）</h5>

<p>红黑树是一种<strong>自平衡</strong>的<strong>二叉查找树</strong>。其除了具有二查找树的特性外，还具有以下特性：</p>

<ul>
  <li>节点是红色或黑色。</li>
  <li>根节点是黑色。</li>
  <li>每个叶子节点都是黑色的空节点（NIL节点）。</li>
  <li>每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)</li>
  <li>从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。</li>
</ul>

<p>如下图插入一个14的新节点。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_18.jpg" alt="" /></p>

<p>红黑树实现自平衡的三种操作：</p>

<ul>
  <li>
    <p>左旋：<strong>逆时针</strong>旋转红黑树的两个节点，使得父节点被自己的右孩子取代，而自己成为自己的左孩子。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_19.jpg" alt="" /></p>
  </li>
  <li>
    <p>右旋：<strong>顺时针</strong>旋转红黑树的两个节点，使得父节点被自己的左孩子取代，而自己成为自己的右孩子。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_20.jpg" alt="" /></p>
  </li>
  <li>
    <p>变色</p>
  </li>
</ul>

<h4 id="43-回溯算法">4.3 回溯算法</h4>

<h5 id="递归实现-伪代码">递归实现-伪代码</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>算法 ReBack(k)
if k&gt;n:
	then &lt;x1,x2...xn&gt;是解
else:
	while S_k != 空集 do
		找到S_k中的最小值x_k
		S_k = S_k - {x_k}
		计算S_k+1
		ReBack(k+1)
</code></pre></div></div>

<h5 id="迭代实现-伪代码">迭代实现-伪代码</h5>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>迭代算法 Backtrack
输入：n
输出：所有的解

1. 对于i=1,2,...n 确定x_i # 确定初始值
2. k = 1
3. 计算S_k
4. while S_k != 空集 do # 满足约束分支搜索
		找到S_k中的最小值x_k
		S_k = S_k - {x_k}
		if k &lt; n then
			k = k+1
			计算S_k
		else
			&lt;x1,x2...xn&gt;是解
5. if k&gt;1 then k = k-1 ; goto4 # 回溯
</code></pre></div></div>

<h5 id="四后问题">四后问题</h5>

<blockquote>
  <p><strong>问题描述</strong>：在4 * 4 的方格棋盘中放置4个皇后，使得没有2个皇后在同一行、同一列、也不在45°的斜线上。问有多少种可能的布局？</p>
</blockquote>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_21.jpg" alt="" /></p>

<p><strong>解</strong>是4维向量&lt;x_1,x_2,x_3,x_4&gt;，解为：&lt;2,4,1,3&gt;，&lt;3,1,4,2&gt;</p>

<p>其<strong>搜索空间</strong>是一个<strong>4叉树</strong>，如下图。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_22.jpg" alt="" /></p>

<ul>
  <li>每个结点有4个儿子，分别代表1，2，3，4列位置。</li>
  <li>第 i 层选择解向量中第 i 个分量的值</li>
  <li>最深层的树叶是解。</li>
  <li>按深度优先次序便利树，找到所有的解。</li>
</ul>

<h5 id="0-1背包问题">0-1背包问题</h5>

<blockquote>
  <p><strong>问题描述</strong>：有n种物品，每种物品只有1个。第 i 种物品价值为v_i，重量位w_i，i = 1,2,…,n。问如何选择放入背包的物品，使得总重量不超过B，而价值达到最大？</p>
</blockquote>

<p><strong>解</strong>：n维 0-1 向量&lt;x_1,x_2,…x_n&gt;</p>

<p><strong>节点</strong>：&lt;x_1,x_2,…x_k&gt;</p>

<p><strong>搜索空间</strong>： 0-1 取值的<strong>二叉树</strong>，称为子集树，有2^n 片树叶。</p>

<p><strong>可行解</strong>：满足约束条件
\(\sum_{i=1}^{n} w_{i} x_{i} \leq B\)
<strong>最优解</strong>：可行解中价值达到最大的解</p>

<p>实例：V = {12,11,9,8}，W = {8,6,4,3},B = 13</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_23.jpg" alt="" /></p>

<h5 id="货郎问题">货郎问题</h5>

<blockquote>
  <p><strong>问题描述</strong>：有n个城市，已知任两个城市之间的距离，求一条每个城市恰好经过一次的回路，使得总长度最小。</p>
</blockquote>

<p>实例：City = {1,2,3,4},d(1,2) = 5,d(1,3) = 9,d(1,4) = 4,d(2,3) = 13,d(2,4) = 2,d(3,4) = 7。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_24.jpg" alt="" /></p>

<p><strong>解</strong>：&lt;1,2,4,3&gt; 长度 = 5 + 2 + 7 + 9 = 23</p>

<p><strong>搜索空间</strong>：<strong>排列树</strong>，每层有 (n-1)! 片树叶</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_25.jpg" alt="" /></p>]]></content><author><name>李小肥的YY</name></author><category term="面试" /><summary type="html"><![CDATA[记录算法面试中遇到的基础问题和过程记录]]></summary></entry><entry><title type="html">ZED2相机api使用心得</title><link href="http://localhost:4000/ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html" rel="alternate" type="text/html" title="ZED2相机api使用心得" /><published>2021-08-25T05:11:00+08:00</published><updated>2021-08-25T05:11:00+08:00</updated><id>http://localhost:4000/ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97</id><content type="html" xml:base="http://localhost:4000/ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html"><![CDATA[<h3 id="一-zed相机的选型">一. ZED相机的选型</h3>

<blockquote>
  <p>STEREOLABS（ZED相机厂家）的官网：https://www.stereolabs.com/zed/</p>
</blockquote>

<p>ZED双目相机有以下四种型号：</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_1.png" alt="" /></p>

<p><a href="https://www.stereolabs.com/zed-2i/">ZED 2i</a>：ZED相机最新款（ZED相机二代的进阶版，<strong>防尘防水</strong>）</p>

<p><a href="https://www.stereolabs.com/zed-2i/">ZED 2</a> ：ZED相机二代（相较于1代多了<strong>支持IMU</strong>）</p>

<p><a href="https://www.stereolabs.com/zed-mini/">ZED mini</a>：功能上和二代基本一致，<strong>尺寸更小</strong>，<strong>性能上要差</strong>，比如这里支持的景深在15m以内，而二代的景深最大支持20m。</p>

<p><a href="https://www.stereolabs.com/zed/">ZED</a>：ZED相机一代，支持2K视频，景深范围在(0.3m,25m)，<strong>无IMU</strong>,所以对于需要玩SLAM的这款就不推荐了。</p>

<h3 id="二-安装zed的sdk">二. 安装ZED的SDK</h3>

<h4 id="21-安装sdk">2.1 安装SDK</h4>

<blockquote>
  <p>ZED相机SDK官网：https://www.stereolabs.com/developers/release/</p>
</blockquote>

<p>我们可以看到是，所有的SDK基本都需要你<strong>安装cuda</strong>，因此我选择了cuda11.0进行安装，具体的cuda安装过程可参考我之前的一篇博客：<a href="https://www.lixiaofei2yy.website/windows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BAcuda10.1%E5%92%8Cpytorch1.6">Windows10环境下搭建CUDA10.1和pytorch1.6</a>。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_2.png" alt="" /></p>

<p>直接安装即可，将下载下来的exe双击运行<code class="language-plaintext highlighter-rouge">ZED_SDK_Windows10_cuda11.0_v3.5.2_4.exe</code>即可，如下图所示</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_3.png" alt="" /></p>

<p>一直往下走即可。</p>

<h4 id="22-安装python-api">2.2 安装python API</h4>

<p>安装完成之后，可以在 <code class="language-plaintext highlighter-rouge">C:\Program Files (x86)\ZED SDK\</code>下看到<code class="language-plaintext highlighter-rouge">get_python_api.py</code>，如下图</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_4.png" alt="" /></p>

<p>直接进行安装python的api：<code class="language-plaintext highlighter-rouge">python get_python_api.py</code></p>

<h3 id="三-python-api的使用">三. python API的使用</h3>

<ul>
  <li>
    <p>导入zed的python包</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyzed.sl</span> <span class="k">as</span> <span class="n">sl</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>查看zed相机版本，这里说下，如果检测到是ZED一代的化，是不支持拿IMU数据的。</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zed</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Camera</span><span class="p">()</span>
<span class="n">info</span> <span class="o">=</span> <span class="n">zed</span><span class="p">.</span><span class="nf">get_camera_information</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Camera Model: </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">info</span><span class="p">.</span><span class="n">camera_model</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>拿到相机的温度信息（本人亲测可用，讲真别用官方教程里的例子，得到的温度全是0，坑）
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">sensors_data</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">SensorsData</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">zed</span><span class="p">.</span><span class="nf">get_sensors_data</span><span class="p">(</span><span class="n">sensors_data</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">TIME_REFERENCE</span><span class="p">.</span><span class="n">CURRENT</span><span class="p">)</span> <span class="o">==</span> <span class="n">sl</span><span class="p">.</span><span class="n">ERROR_CODE</span><span class="p">.</span><span class="n">SUCCESS</span><span class="p">:</span>
      	<span class="c1"># 这里分别拿到左、右相机，imu，气压计4者的温度
</span>      	<span class="n">temperature_left</span> <span class="o">=</span> <span class="n">sensors_data</span><span class="p">.</span><span class="nf">get_temperature_data</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="n">sl</span><span class="p">.</span><span class="n">SENSOR_LOCATION</span><span class="p">.</span><span class="n">ONBOARD_LEFT</span><span class="p">)</span>
          <span class="n">temperature_right</span> <span class="o">=</span> <span class="n">sensors_data</span><span class="p">.</span><span class="nf">get_temperature_data</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="n">sl</span><span class="p">.</span><span class="n">SENSOR_LOCATION</span><span class="p">.</span><span class="n">ONBOARD_RIGHT</span><span class="p">)</span>
          <span class="n">temperature_imu</span> <span class="o">=</span> <span class="n">sensors_data</span><span class="p">.</span><span class="nf">get_temperature_data</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="n">sl</span><span class="p">.</span><span class="n">SENSOR_LOCATION</span><span class="p">.</span><span class="n">IMU</span><span class="p">)</span>
          <span class="n">temperature_barometer</span> <span class="o">=</span> <span class="n">sensors_data</span><span class="p">.</span><span class="nf">get_temperature_data</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="n">sl</span><span class="p">.</span><span class="n">SENSOR_LOCATION</span><span class="p">.</span><span class="n">BAROMETER</span><span class="p">)</span>
          <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Left: {:.2f}, Right: {:.2f}, IMU: {:.2f}, Barometer: {:.2f}</span><span class="se">\r\n</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">temperature_left</span><span class="p">,</span>
                                                                                         <span class="n">temperature_right</span><span class="p">,</span>
                                                                                         <span class="n">temperature_imu</span><span class="p">,</span>
                                                                                    <span class="n">temperature_barometer</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>拿到相机的惯导(IMU)信息，注意这里使用的是<strong>Y轴向上的右手定律</strong>，这里即Z轴方向是车头/飞机头的方向。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_5.png" alt="" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 初始化
</span><span class="n">zed</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Camera</span><span class="p">()</span>  <span class="c1"># Create a ZED camera object
</span><span class="n">input_type</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">InputType</span><span class="p">()</span>  <span class="c1"># Set configuration parameters
</span>  
<span class="n">init</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">InitParameters</span><span class="p">(</span><span class="n">input_t</span><span class="o">=</span><span class="n">input_type</span><span class="p">)</span>  <span class="c1"># 初始化
</span>          
        <span class="n">self</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">coordinate_system</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="n">COORDINATE_SYSTEM</span><span class="p">.</span><span class="n">RIGHT_HANDED_Y_UP</span>  <span class="c1"># 右手定律Y轴向上
</span>  
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">runtime_parameters</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">RuntimeParameters</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">zed</span><span class="p">.</span><span class="nf">grab</span><span class="p">(</span><span class="n">runtime_parameters</span><span class="p">)</span> <span class="o">==</span> <span class="n">sl</span><span class="p">.</span><span class="n">ERROR_CODE</span><span class="p">.</span><span class="n">SUCCESS</span><span class="p">:</span>
        <span class="n">zed_imu</span> <span class="o">=</span> <span class="n">zed_sensors</span><span class="p">.</span><span class="nf">get_imu_data</span><span class="p">()</span>
        <span class="n">zed_imu_pose</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Transform</span><span class="p">()</span>
                <span class="n">ox</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">zed_imu</span><span class="p">.</span><span class="nf">get_pose</span><span class="p">(</span><span class="n">zed_imu_pose</span><span class="p">).</span><span class="nf">get_orientation</span><span class="p">().</span><span class="nf">get</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
                <span class="n">oy</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">zed_imu</span><span class="p">.</span><span class="nf">get_pose</span><span class="p">(</span><span class="n">zed_imu_pose</span><span class="p">).</span><span class="nf">get_orientation</span><span class="p">().</span><span class="nf">get</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
                <span class="n">oz</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">zed_imu</span><span class="p">.</span><span class="nf">get_pose</span><span class="p">(</span><span class="n">zed_imu_pose</span><span class="p">).</span><span class="nf">get_orientation</span><span class="p">().</span><span class="nf">get</span><span class="p">()[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
                <span class="n">ow</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="n">zed_imu</span><span class="p">.</span><span class="nf">get_pose</span><span class="p">(</span><span class="n">zed_imu_pose</span><span class="p">).</span><span class="nf">get_orientation</span><span class="p">().</span><span class="nf">get</span><span class="p">()[</span><span class="mi">3</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">IMU Orientation: Ox: {0}, Oy: {1}, Oz {2}, Ow: {3}</span><span class="se">\n</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">ox</span><span class="p">,</span> <span class="n">oy</span><span class="p">,</span> <span class="n">oz</span><span class="p">,</span> <span class="n">ow</span><span class="p">))</span>
</code></pre></div>    </div>
    <p>这里拿到的数据是四元数，如果我们想转成欧拉角，这里推推荐使用scipy的转换函数<code class="language-plaintext highlighter-rouge">Rotation.from_quat</code>。</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.spatial.transform</span> <span class="kn">import</span> <span class="n">Rotation</span>
<span class="c1"># 将上面拿到的四元数转成欧拉角
</span><span class="n">rot</span> <span class="o">=</span> <span class="n">Rotation</span><span class="p">.</span><span class="nf">from_quat</span><span class="p">([</span><span class="n">ox</span><span class="p">,</span><span class="n">oy</span><span class="p">,</span><span class="n">oz</span><span class="p">,</span><span class="n">ow</span><span class="p">])</span>
<span class="n">eular_angle</span> <span class="o">=</span> <span class="n">rot</span><span class="p">.</span><span class="nf">as_euler</span><span class="p">(</span><span class="sh">'</span><span class="s">xyz</span><span class="sh">'</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">翻滚角：</span><span class="si">{</span><span class="n">eular_angle</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s">,俯仰角：</span><span class="si">{</span><span class="n">eular_angle</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">,方位角：eular_angle[1]</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>拿取当前时间（毫秒级）</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 当前时间戳(毫秒)
</span><span class="n">time_zed</span> <span class="o">=</span> <span class="n">zed_pose</span><span class="p">.</span><span class="n">timestamp</span><span class="p">.</span><span class="nf">get_milliseconds</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>拿到前景图</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 定义图像数据
</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">zed</span><span class="p">.</span><span class="nf">get_camera_information</span><span class="p">().</span><span class="n">camera_resolution</span>
<span class="n">image_zed</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Mat</span><span class="p">(</span><span class="n">image_size</span><span class="p">.</span><span class="n">width</span><span class="p">,</span> <span class="n">image_size</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">MAT_TYPE</span><span class="p">.</span><span class="n">U8_C4</span><span class="p">)</span>
  
<span class="k">while</span> <span class="bp">True</span><span class="err">：</span>
	<span class="c1"># 从zed相机中拿到前景图
</span>    <span class="n">zed</span><span class="p">.</span><span class="nf">grab</span><span class="p">()</span>
    <span class="c1"># 拿取图像
</span>    <span class="n">zed</span><span class="p">.</span><span class="nf">retrieve_image</span><span class="p">(</span><span class="n">image_zed</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">VIEW</span><span class="p">.</span><span class="n">LEFT</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">MEM</span><span class="p">.</span><span class="n">CPU</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
    <span class="c1"># 转成numpy
</span>    <span class="n">image_np</span> <span class="o">=</span> <span class="n">image_zed</span><span class="p">.</span><span class="nf">get_data</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>拿到景深图（当然也可以拿到3D点云数据）</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 这里需要在初始化中加入深度模式
</span><span class="n">init</span><span class="p">.</span><span class="n">depth_mode</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="n">DEPTH_MODE</span><span class="p">.</span><span class="n">ULTRA</span>  <span class="c1"># 深度模式  (默认-PERFORMANCE)
</span><span class="n">init</span><span class="p">.</span><span class="n">coordinate_units</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="n">UNIT</span><span class="p">.</span><span class="n">MILLIMETER</span>  <span class="c1"># 毫米级    (默认-MILLIMETER)
</span>  
<span class="c1"># 定义测量数据
</span><span class="n">depth_zed</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Mat</span><span class="p">(</span><span class="n">image_size</span><span class="p">.</span><span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">image_size</span><span class="p">.</span><span class="n">height</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># 16位进行保存
</span><span class="n">point_cloud_zed</span> <span class="o">=</span> <span class="n">sl</span><span class="p">.</span><span class="nc">Mat</span><span class="p">(</span><span class="n">image_size</span><span class="p">.</span><span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span><span class="n">image_size</span><span class="p">.</span><span class="n">height</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
  
<span class="k">while</span> <span class="bp">True</span><span class="err">：</span>
	<span class="c1"># 从zed相机中拿到景深图
</span>    <span class="n">zed</span><span class="p">.</span><span class="nf">grab</span><span class="p">()</span>
    <span class="c1"># 拿取景深图像
</span>    <span class="n">zed</span><span class="p">.</span><span class="nf">retrieve_measure</span><span class="p">(</span><span class="n">depth_zed</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">MEASURE</span><span class="p">.</span><span class="n">DEPTH</span><span class="p">,</span><span class="n">sl</span><span class="p">.</span><span class="n">MEM</span><span class="p">.</span><span class="n">CPU</span><span class="p">,</span><span class="n">image_size</span><span class="p">)</span>
    <span class="c1"># 拿取3D点云图像
</span>    <span class="n">zed</span><span class="p">.</span><span class="nf">retrieve_measure</span><span class="p">(</span><span class="n">point_cloud_zed</span><span class="p">,</span> <span class="n">sl</span><span class="p">.</span><span class="n">MEASURE</span><span class="p">.</span><span class="n">XYZRGBA</span><span class="p">)</span>
    <span class="c1"># 转成numpy
</span>    <span class="n">depth_np</span> <span class="o">=</span> <span class="n">depth_zed</span><span class="p">.</span><span class="nf">get_data</span><span class="p">()</span>
    <span class="n">point_cloud_value</span> <span class="o">=</span> <span class="n">point_cloud_zed</span><span class="p">.</span><span class="nf">get_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
</ul>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><summary type="html"><![CDATA[记录ZED双目相机的python API使用过程]]></summary></entry><entry><title type="html">Jetson Xavier NX 的使用记录</title><link href="http://localhost:4000/JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html" rel="alternate" type="text/html" title="Jetson Xavier NX 的使用记录" /><published>2021-08-25T05:11:00+08:00</published><updated>2021-08-25T05:11:00+08:00</updated><id>http://localhost:4000/JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95</id><content type="html" xml:base="http://localhost:4000/JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html"><![CDATA[<h3 id="一-远程桌面">一. 远程桌面</h3>

<blockquote>
  <p>在windows10远程上操作jetson Xavier，远程的前提：jetson xavier和Windows的PC在同一个局域网内（我这里是直接在windows10上开启热点）。</p>
</blockquote>

<ul>
  <li>安装xrdp：<code class="language-plaintext highlighter-rouge">sudo apt-get install xrdp vnc4server xbase-clients</code></li>
</ul>

<h4 id="11桌面共享没反应">1.1：桌面共享没反应</h4>

<blockquote>
  <p>桌面共享其实就是一个vnc-server（因此没有必要再在linux上安装vnc-server了），如果要远程，必须要先开启共享，允许其他人控制自己电脑。</p>
</blockquote>

<p>这里发现<strong>双击了桌面共享，没反应</strong>。</p>

<p><strong>解决方案</strong>：</p>

<ul>
  <li>安装dconf-editor：<code class="language-plaintext highlighter-rouge">sudo apt-get install dconf-editor</code></li>
  <li>运行dconf-editor，更改系统配置，org ==&gt; gnome ==&gt; desktop ==&gt; remote-access，关闭以下两个：<code class="language-plaintext highlighter-rouge">promotion-enabled</code>和<code class="language-plaintext highlighter-rouge">requre-encryption</code></li>
  <li>开启桌面共享：<code class="language-plaintext highlighter-rouge">/usr/lib/vino/vino-server</code></li>
</ul>

<h4 id="12-开启远程">1.2 开启远程</h4>

<ul>
  <li>在Windows10上安装vnc-client，官网地址：https://www.realvnc.com/en/connect/download/viewer/windows/</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_1.png" alt="" /></p>

<ul>
  <li>
    <p>输入linux的ip后，直接连接即可。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_2.png" alt="" /></p>
  </li>
</ul>

<h4 id="13-建立双击可执行文件desktop">1.3 建立双击可执行文件.desktop</h4>

<blockquote>
  <p>由于每次我开启远程桌面的时候，都需要在命令行输入相关指令，很麻烦，就想说有没有可以直接在像windows一样快捷方式</p>
</blockquote>

<ul>
  <li>
    <p>写一个shell脚本来开启桌面共享：<code class="language-plaintext highlighter-rouge">vim ~/vnc-server.sh</code></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>
/usr/lib/vino/vino-server
</code></pre></div>    </div>
  </li>
  <li>
    <p>在桌面上新建一个.desktop文件：<code class="language-plaintext highlighter-rouge">vim ~/Desktop/vnc-server.desktop</code></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Desktop Entry]
<span class="nv">Encoding</span><span class="o">=</span>UTF-8
<span class="nv">Type</span><span class="o">=</span>Application
<span class="nv">Categories</span><span class="o">=</span><span class="nb">true
</span><span class="nv">Version</span><span class="o">=</span>1.0
<span class="nv">Name</span><span class="o">=</span>vnc-server
<span class="nv">Exec</span><span class="o">=</span>sh /home/yy/vnc-server.sh <span class="c">#注意这里是绝对路径</span>
<span class="nv">Path</span><span class="o">=</span>/home/yy
<span class="nv">Terminal</span><span class="o">=</span><span class="nb">false</span> <span class="c"># 是否保留终端</span>
<span class="nv">StartupNotify</span><span class="o">=</span><span class="nb">true</span> <span class="c"># 开机自启动</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>给.desktop文件加上可执行权限：<code class="language-plaintext highlighter-rouge">sudo chmod +x ~/Desktop/vnc-server.desktop</code></p>
  </li>
</ul>

<h4 id="14-开机自动开启">1.4 开机自动开启</h4>

<ul>
  <li>创建开机自启动文件夹：<code class="language-plaintext highlighter-rouge">mkdir ~/.config/autostart</code></li>
  <li>复制.desktop文件到该文件夹下：<code class="language-plaintext highlighter-rouge">cp ~/Desktop/vnc-server.desktop ~/.config/autostart/</code></li>
  <li>给.desktop文件加上可执行权限：<code class="language-plaintext highlighter-rouge">sudo chmod +x ~/.config/autostart/vnc-server.desktop</code></li>
</ul>

<h3 id="二-配置cuda和cudnn">二. 配置cuda和cuDNN</h3>

<ul>
  <li>用JetPack刷机（本人选用的是Jetpack4.4.1），jetpack地址：https://developer.nvidia.com/embedded/jetpack-archive</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_3.png" alt="" /></p>

<ul>
  <li>安装完成后，我们可以查看jetpack的版本：<code class="language-plaintext highlighter-rouge">cat /etc/nv_tegra_release</code>，同时已经给我们安装好了CUDA 10.2 、cudnn 8.0 、opencv、python3.6。</li>
</ul>

<h4 id="21-设置cuda环境变量">2.1 设置cuda环境变量</h4>

<p>​	查询cuda版本：<code class="language-plaintext highlighter-rouge">nvcc -V</code>基本就能看到cuda信息了，但是这里却<strong>报错没有nvcc指令</strong>。解决方案：将cuda添加到环境变量中</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sudo vim /etc/profile </code>，这里说下其实在<code class="language-plaintext highlighter-rouge">/usr/local</code>下有2个cuda相关文件夹，分别是<code class="language-plaintext highlighter-rouge">cuda</code>和<code class="language-plaintext highlighter-rouge">cuda-10.2</code>，你会发现其实是一致的。</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-10.2/bin:<span class="nv">$PATH</span>
<span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda-10.2/lib64<span class="nv">$LD_LIBRARY_PATH</span>
<span class="nb">export </span><span class="nv">CUDA_HOME</span><span class="o">=</span>/usr/local/cuda-10.2
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">source /etc/profile</code>，再去命令行输入<code class="language-plaintext highlighter-rouge">nvcc -V</code>就可以看到cuda10.2的信息了</p>
  </li>
</ul>

<h4 id="22-设置cudnn">2.2 设置cuDNN</h4>

<p>安装好的cuDNN的头文件：<code class="language-plaintext highlighter-rouge">/usr/include/cudnn.h</code>
安装好的cuDNN的库文件：<code class="language-plaintext highlighter-rouge">/usr/lib/aarch64-linux-gnu/libcudnn*</code></p>

<p>(1) 而<strong>这些头文件和库文件都不在cuda目录下</strong>，因此要复制到cuda目录下：</p>

<ul>
  <li>复制头文件：<code class="language-plaintext highlighter-rouge">sudo cp /usr/include/cudnn.h /usr/local/cuda/include</code></li>
  <li>复制库文件：<code class="language-plaintext highlighter-rouge">sudo cp /usr/lib/aarch64-linux-gnu/libcudnn* /usr/local/cuda/lib64/</code></li>
</ul>

<p>(2) 修改文件权限：<code class="language-plaintext highlighter-rouge">sudo chmod 777 /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</code></p>

<p>(3) 重新软连接：</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">cd</span> /usr/local/cuda/lib64
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn.so.8.0.0 libcudnn.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_ops_train.so.8.0.0 libcudnn_ops_train.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_ops_infer.so.8.0.0 libcudnn_ops_infer.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_adv_infer.so.8.0.0 libcudnn_adv_infer.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_cnn_infer.so.8.0.0 libcudnn_cnn_infer.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_cnn_train.so.8.0.0 libcudnn_cnn_train.so.8
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_adv_train.so.8.0.0 libcudnn_adv_train.so.8

   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_ops_train.so.7.3.1 libcudnn_ops_train.so.7
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_ops_infer.so.7.3.1libcudnn_ops_infer.so.7
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_adv_infer.so.7.3.1 libcudnn_adv_infer.so.7
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_cnn_infer.so.7.3.1 libcudnn_cnn_infer.so.7
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_cnn_train.so.7.3.1 libcudnn_cnn_train.so.7
   <span class="nb">sudo ln</span> <span class="nt">-sf</span> libcudnn_adv_train.so.7.3.1 libcudnn_adv_train.so.7
</code></pre></div></div>

<p>(4) 编译与验证：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo ldconfig
sudo cp -r /usr/src/cudnn_samples_v8/ ~/
cd ~/cudnn_samples_v8/mnistCUDNN
sudo chmod 777 ~/cudnn_samples_v8
sudo make clean
sudo make
./mnistCUDNN # 验证cuDNN
</code></pre></div></div>

<p>(5) 查询cuDNN版本：<code class="language-plaintext highlighter-rouge">cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2</code></p>

<h3 id="三-配置torch和torchvision">三. 配置torch和torchvision</h3>

<h4 id="31-配置torch">3.1 配置torch</h4>

<blockquote>
  <p>这里安装torch的方式和普通的windows和linux下安装不一样，pytorch有专门的jetson版本</p>
</blockquote>

<p>Pytorch的jetson版本下载地址：https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-9-0-now-available/72048</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_4.png" alt="" /></p>

<ul>
  <li>
    <p>下载完成后直接使用pip进行安装：<code class="language-plaintext highlighter-rouge">sudo pip3 install numpy torch-1.9.0-cp36-cp36m-linux_aarch64.whl</code></p>
  </li>
  <li>
    <p>安装必须的依赖：<code class="language-plaintext highlighter-rouge">sudo apt-get install libopenblas-base libopenmpi-dev </code></p>
  </li>
</ul>

<h4 id="32-配置torchvision">3.2 配置torchvision</h4>

<p>由于安装的是1.9.0版本的pytorch，直接安装于其对应的torchvision(0.10.0)：<code class="language-plaintext highlighter-rouge">sudo pip3 install torchvision==0.10.0</code></p>

<h4 id="33-验证gpu可用">3.3 验证GPU可用</h4>

<ul>
  <li>
    <p>命令行打开python，导入torch包：<code class="language-plaintext highlighter-rouge">import torch</code></p>
  </li>
  <li>查看pytorch可调用的cuda版本：<code class="language-plaintext highlighter-rouge">torch.version.cuda</code></li>
  <li>查看cuda是否可用：<code class="language-plaintext highlighter-rouge">torch.cuda.is_available()</code></li>
</ul>

<h4 id="34-使用yolo遇到的问题">3.4 使用yolo遇到的问题</h4>

<p>问题：<code class="language-plaintext highlighter-rouge">RuntimeError: No such operator torchvision::nms</code></p>

<p>实验过程：在网上搜到的都是torch和torchvision的版本不对，要升级torchvision之类的，实验将torchvision升级到0.10.0，依旧不行。</p>

<p>解决方案：其实在使用yolo时的非极大值抑制的时候，可以将<code class="language-plaintext highlighter-rouge">utils.general.py</code>中nms相关代码替换</p>

<ul>
  <li>
    <p>原始代码：<code class="language-plaintext highlighter-rouge">i = torch.ops.torchvision.nms(boxes, scores, iou_thres) </code></p>
  </li>
  <li>
    <p>替换代码：</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torchvision</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">ops</span><span class="p">.</span><span class="nf">nms</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">iou_thres</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><summary type="html"><![CDATA[记录使用Jetson Xavier NX的使用体验中遇到的问题和记录]]></summary></entry><entry><title type="html">python的打包神器——Nuitka</title><link href="http://localhost:4000/python%E7%9A%84%E6%89%93%E5%8C%85%E7%A5%9E%E5%99%A8Nuitka.html" rel="alternate" type="text/html" title="python的打包神器——Nuitka" /><published>2021-08-10T23:11:00+08:00</published><updated>2021-08-10T23:11:00+08:00</updated><id>http://localhost:4000/python%E7%9A%84%E6%89%93%E5%8C%85%E7%A5%9E%E5%99%A8Nuitka</id><content type="html" xml:base="http://localhost:4000/python%E7%9A%84%E6%89%93%E5%8C%85%E7%A5%9E%E5%99%A8Nuitka.html"><![CDATA[<h3 id="一-pyinstaller和nuitka使用感受">一. pyinstaller和Nuitka使用感受</h3>

<h4 id="11-使用需求">1.1 使用需求</h4>

<blockquote>
  <p>这次也是由于项目需要，要将python的代码转成exe的程序，在找了许久后，发现了2个都能对python项目打包的工具——pyintaller和nuitka。</p>
</blockquote>

<p>这2个工具同时都能满足项目的需要：</p>

<ul>
  <li><strong>隐藏源码</strong>。这里的pyinstaller是通过设置key来对源码进行加密的；而nuitka则是将python源码转成C++（这里得到的是二进制的pyd文件，防止了反编译），然后再编译成可执行文件。</li>
  <li><strong>方便移植</strong>。用户使用方便，不用再安装什么python啊，第三方包之类的。</li>
</ul>

<h4 id="12-使用感受">1.2 使用感受</h4>

<p>2个工具使用后的最大的感受就是：</p>

<ul>
  <li>pyinstaller体验很差！
    <ul>
      <li>一个深度学习的项目最后转成的exe竟然有近3个G的大小（<strong>pyinstaller是将整个运行环境进行打包</strong>），对，你没听错，一个EXE有3个G！</li>
      <li>打包超级慢，启动超级慢。</li>
    </ul>
  </li>
  <li>nuitka真香！
    <ul>
      <li>同一个项目，生成的exe只有7M！</li>
      <li>打包超级快（1min以内），启动超级快。</li>
    </ul>
  </li>
</ul>

<h3 id="二-nuitka的安装及使用">二. Nuitka的安装及使用</h3>

<h4 id="21-nuitka的安装">2.1 nuitka的安装</h4>

<ul>
  <li>直接利用pip即可安装：<code class="language-plaintext highlighter-rouge">pip install Nuitka </code></li>
  <li>下载vs2019(MSVS)或者MinGW64，反正都是C++的编译器，随便下。</li>
</ul>

<h4 id="22-使用过程">2.2 使用过程</h4>

<p>对于第三方依赖包较多的项目（比如需要import torch,tensorflow,cv2,numpy,pandas,geopy等等）而言，这里最好打包的方式是<strong>只将属于自己的代码转成C++，不管这些大型的第三方包！</strong></p>

<p>以下是我demo的一个目录结构（这里使用了pytq5框架写的界面）：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">├─utils</span><span class="w"> </span><span class="err">//源码</span><span class="mi">1</span><span class="err">文件夹</span><span class="w">
</span><span class="err">├─src</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">源码</span><span class="mi">2</span><span class="err">文件夹</span><span class="w">
</span><span class="err">├─logo.ico</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">demo的图标</span><span class="w">
</span><span class="err">└─demo.py</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">main文件</span><span class="w">
</span></code></pre></div></div>

<p>使用以下命令（调试）直接生成exe文件：</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nuitka <span class="nt">--standalone</span> <span class="nt">--show-memory</span> <span class="nt">--show-progress</span> <span class="nt">--nofollow-imports</span> <span class="nt">--plugin-enable</span><span class="o">=</span>qt-plugins <span class="nt">--follow-import-to</span><span class="o">=</span>utils,src <span class="nt">--output-dir</span><span class="o">=</span>out <span class="nt">--windows-icon-from-ico</span><span class="o">=</span>./logo.ico demo.py
</code></pre></div></div>

<p>这里简单介绍下我上面的nuitka的命令：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--standalone</code>：方便移植到其他机器，不用再安装python</li>
  <li><code class="language-plaintext highlighter-rouge">--show-memory --show-progress</code>：展示整个安装的进度过程</li>
  <li><code class="language-plaintext highlighter-rouge">--nofollow-imports</code>：不编译代码中所有的import，比如keras，numpy之类的。</li>
  <li><code class="language-plaintext highlighter-rouge">--plugin-enable=qt-plugins</code>：我这里用到pyqt5来做界面的，这里nuitka有其对应的插件。</li>
  <li><code class="language-plaintext highlighter-rouge">--follow-import-to=utils,src</code>：需要编译成C++代码的指定的2个包含源码的文件夹，这里用<code class="language-plaintext highlighter-rouge">,</code>来进行分隔。</li>
  <li><code class="language-plaintext highlighter-rouge">--output-dir=out</code>：指定输出的结果路径为out。</li>
  <li><code class="language-plaintext highlighter-rouge">--windows-icon-from-ico=./logo.ico</code>：指定生成的exe的图标为logo.ico这个图标，这里推荐一个将图片转成ico格式文件的网站（比特虫）。</li>
  <li><code class="language-plaintext highlighter-rouge">--windows-disable-console</code>：运行exe取消弹框。这里没有放上去是因为我们还需要调试，可能哪里还有问题之类的。</li>
</ul>

<p>经过1min的编译之后，你就能在你的目录下看到：</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">├─utils</span><span class="w"> </span><span class="err">//源码</span><span class="mi">1</span><span class="err">文件夹</span><span class="w">
</span><span class="err">├─src</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">源码</span><span class="mi">2</span><span class="err">文件夹</span><span class="w">
</span><span class="err">├─out</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">生成的exe文件夹</span><span class="w">
    </span><span class="err">├─demo.build</span><span class="w"> 
    </span><span class="err">└─demo.dist</span><span class="w">
		</span><span class="err">└─demo.exe</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">生成的exe文件</span><span class="w">
</span><span class="err">├─logo.ico</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">demo的图标</span><span class="w">
</span><span class="err">└─demo.py</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">main文件</span><span class="w">
</span></code></pre></div></div>

<p>当然这里你会发现真正运行exe的时候，会报错：<code class="language-plaintext highlighter-rouge">no module named torch,cv2,tensorflow</code>等等这些没有转成C++的第三方包。</p>

<p>这里需要找到这些包（我的是在software\python3.7\Lib\site-packages下）复制（比如numpy,cv2这个文件夹）到<code class="language-plaintext highlighter-rouge">demo.dist</code>路径下。</p>

<p>至此，exe能完美运行啦！</p>]]></content><author><name>李小肥的YY</name></author><category term="代码" /><summary type="html"><![CDATA[对比pyinstaller和nuitka打包工具及nuitka的使用过程]]></summary></entry><entry><title type="html">Mask_RCNN在TF2下跑通自己的数据集</title><link href="http://localhost:4000/Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html" rel="alternate" type="text/html" title="Mask_RCNN在TF2下跑通自己的数据集" /><published>2021-07-26T20:11:00+08:00</published><updated>2021-07-26T20:11:00+08:00</updated><id>http://localhost:4000/Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86</id><content type="html" xml:base="http://localhost:4000/Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html"><![CDATA[<blockquote>
  <p>论文原文地址：https://arxiv.org/abs/1703.06870</p>

  <p>MaskRCNN官方的git地址：https://github.com/matterport/Mask_RCNN</p>
</blockquote>

<h3 id="一-构建数据集">一. 构建数据集</h3>

<p>这里参考官方推荐的气球语义分割的<a href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46">例子</a>，这里选用的是和他一致的打标工具 <a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA (VGG Image Annotator)</a>。个人感觉这个比<a href="https://github.com/wkentaro/labelme">labeme</a>好用太多。</p>

<ul>
  <li>直接在<a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA官网</a>下载即可，下载完成后如下图所示，直接用浏览器打开<code class="language-plaintext highlighter-rouge">via.html</code>即可开箱使用。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_1.png" alt="" /></p>

<ul>
  <li>选择<code class="language-plaintext highlighter-rouge">Add Files</code>添加图片后，选择<code class="language-plaintext highlighter-rouge">Attributes</code>设置打标的label，然后用多边形工具进行打标，如下图。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_2.png" alt="" /></p>

<ul>
  <li>输出json格式的打标结果</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_3.png" alt="" /></p>

<ul>
  <li>将图片和json结果保存在同一个目录下，构建自己的数据集时可参考我的目录结构。</li>
</ul>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">├─dataset</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">├─train</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">1</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">2</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">3</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">└─annotations.json</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">└─val</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">1</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">2</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">├─</span><span class="mi">3</span><span class="err">.jpg</span><span class="w">
</span><span class="err">│</span><span class="w">  </span><span class="err">│</span><span class="w">  </span><span class="err">└─annotations.json</span><span class="w">
</span></code></pre></div></div>

<h3 id="二-准备工作">二. 准备工作</h3>

<blockquote>
  <p>由于官方的代码只支持tensorflow的版本都是1.x的版本，对于tensorflow 2.x的版本官方代码中很多地方不能调用，这里需要大量修改。</p>
</blockquote>

<h4 id="21-环境搭建">2.1 环境搭建</h4>

<p>本人是Windows系统，安装的是11.0版本的cuda，以下是我安装的项目必须的python包。</p>

<ul>
  <li>scikit-image==0.16.2  这里说一句，如果安装的是更高版本的，最好降低成0.16的，不然可能后面训练的时候会报<code class="language-plaintext highlighter-rouge">Input image dtype is bool. Interpolation is not defined with bool data type</code>，这里<a href="https://stackoverflow.com/questions/62330374/input-image-dtype-is-bool-interpolation-is-not-defined-with-bool-data-type">参考</a>。</li>
  <li>tensorflow==2.2.0 就是因为tensorflow的1.x版本不支持cuda11.0，才折腾好久….</li>
  <li>keras==2.4.0</li>
  <li>numpy==2.1.0</li>
</ul>

<h4 id="22-源码的替换">2.2 源码的替换</h4>

<blockquote>
  <p>之前本人找到一个TF2.0版本的<a href="https://github.com/ahmedfgad/Mask-RCNN-TF2">Mask RCNN</a>，哎，但是发现没卵用！</p>
</blockquote>

<ul>
  <li>下载官方源码：<code class="language-plaintext highlighter-rouge">git clone https://github.com/matterport/Mask_RCNN.git</code></li>
  <li>替换官方的核心代码<code class="language-plaintext highlighter-rouge">mrcnn</code>下的所有代码。</li>
</ul>

<p>PS：由于这里改的官方代码中<code class="language-plaintext highlighter-rouge">mrcnn/model.py</code>,<code class="language-plaintext highlighter-rouge">mrcnn/config.py</code>,<code class="language-plaintext highlighter-rouge">mrcnn/utils.py</code>,<code class="language-plaintext highlighter-rouge">parallel_model.py</code>需要修改的文件太多，直接给出<a href="https://github.com/yy2lyx/MaskRCNN_TF2">git地址</a>，大家可以直接下在<code class="language-plaintext highlighter-rouge">mrcnn</code>这个文件夹及其下面的py文件对官方的<code class="language-plaintext highlighter-rouge">mrcnn</code>这个文件夹进行替换（不然太折腾人了）。</p>

<h4 id="23-训练代码修改">2.3 训练代码修改</h4>

<ul>
  <li>
    <p>这里训练的代码参考的是官方的<code class="language-plaintext highlighter-rouge">samples/ballon/ballon.py</code>这个文件，直接复制到主目录<code class="language-plaintext highlighter-rouge">Mask_RCNN</code>下，修改成自己想要的名字，比如<code class="language-plaintext highlighter-rouge">train.py</code>。</p>
  </li>
  <li>
    <p>修改根地址，这里由于从<code class="language-plaintext highlighter-rouge">samples/ballon/</code>目录到主目录下，因此修改<code class="language-plaintext highlighter-rouge">ROOT_DIR = '.'</code></p>
  </li>
  <li>
    <p>修改config类成自己的类，注意我这里是改成了动物类，然后一共是识别2个种类，然后最好这里的<code class="language-plaintext highlighter-rouge">NAME</code>和利用VIA构建数据集中的Attribute一致。</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AnimalConfig</span><span class="p">(</span><span class="n">Config</span><span class="p">):</span>
    <span class="c1"># Give the configuration a recognizable name
</span>    <span class="n">NAME</span> <span class="o">=</span> <span class="sh">"</span><span class="s">animal</span><span class="sh">"</span>
    
    <span class="c1"># Adjust down if you use a smaller GPU.
</span>    <span class="n">IMAGES_PER_GPU</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Number of classes (including background)
</span>    <span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span>  <span class="c1"># Background + balloon
</span>
    <span class="c1"># Number of training steps per epoch
</span>    <span class="n">STEPS_PER_EPOCH</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="c1"># Skip detections with &lt; 90% confidence
</span>    <span class="n">DETECTION_MIN_CONFIDENCE</span> <span class="o">=</span> <span class="mf">0.9</span>
</code></pre></div></div>

<ul>
  <li>修改Dataset类成自己的Dataset类，同时修改load函数</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AnimalDataset</span><span class="p">(</span><span class="n">utils</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">load_animal</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dataset_dir</span><span class="p">,</span> <span class="n">subset</span><span class="p">):</span>
        <span class="c1"># Add classes. We have only one class to add.
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">add_class</span><span class="p">(</span><span class="sh">"</span><span class="s">animal</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">pig</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">add_class</span><span class="p">(</span><span class="sh">"</span><span class="s">animal</span><span class="sh">"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="sh">"</span><span class="s">cow</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">..</span><span class="bp">...</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">add_image</span><span class="p">(</span>
                <span class="sh">"</span><span class="s">animal</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">image_id</span><span class="o">=</span><span class="n">a</span><span class="p">[</span><span class="sh">'</span><span class="s">filename</span><span class="sh">'</span><span class="p">],</span>
                <span class="n">path</span><span class="o">=</span><span class="n">image_path</span><span class="p">,</span>
                <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span>
                <span class="n">polygons</span><span class="o">=</span><span class="n">polygons</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>修改load_mask函数</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">load_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image_id</span><span class="p">):</span>
        <span class="n">image_info</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">image_info</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">image_info</span><span class="p">[</span><span class="sh">"</span><span class="s">source</span><span class="sh">"</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">animal</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="nf">super</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">__class__</span><span class="p">,</span> 	<span class="n">self</span><span class="p">).</span><span class="nf">load_mask</span><span class="p">(</span><span class="n">image_id</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>修改image_reference函数</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">image_reference</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">image_id</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Return the path of the image.</span><span class="sh">"""</span>
        <span class="n">info</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">image_info</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">info</span><span class="p">[</span><span class="sh">"</span><span class="s">source</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">animal</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">info</span><span class="p">[</span><span class="sh">"</span><span class="s">path</span><span class="sh">"</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nf">super</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">__class__</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">image_reference</span><span class="p">(</span><span class="n">image_id</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>修改训练函数</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Train the model.</span><span class="sh">"""</span>
    <span class="c1"># Training dataset.
</span>    <span class="n">dataset_train</span> <span class="o">=</span> <span class="nc">AnimalDataset</span><span class="p">()</span>
    <span class="n">dataset_train</span><span class="p">.</span><span class="nf">load_animal</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataset</span><span class="p">,</span> <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">dataset_train</span><span class="p">.</span><span class="nf">prepare</span><span class="p">()</span>

    <span class="c1"># Validation dataset
</span>    <span class="n">dataset_val</span> <span class="o">=</span> <span class="nc">AnimalDataset</span><span class="p">()</span>
    <span class="n">dataset_val</span><span class="p">.</span><span class="nf">load_animal</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">dataset</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">dataset_val</span><span class="p">.</span><span class="nf">prepare</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="三-训练">三. 训练</h3>

<p>直接在命令行中<code class="language-plaintext highlighter-rouge">python train.py train --dataset=./dataset --weights=coco</code>即可看到模型开始训练了。</p>

<p>这里注意2点：</p>

<ul>
  <li>用VIA打标好的数据集注意是放到Mask RCNN主目录下，所以这里的命令参数<code class="language-plaintext highlighter-rouge">--dataset=./dataset</code></li>
  <li>权重用的是coco形式，即<code class="language-plaintext highlighter-rouge">--weights=coco</code>，如果不是的话，你会遇到这类问题<code class="language-plaintext highlighter-rouge">mrcnn_bbox_fc/kernel:0' shape=(1024, 8) dtype=float32_ref&gt; has shape (1024, 8), but the saved weight has shape (1024, 324) </code>，具体可<a href="https://github.com/matterport/Mask_RCNN/issues/849">参考</a></li>
</ul>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><category term="深度学习" /><summary type="html"><![CDATA[讲述Mask RCNN在tensorflow2.x下如何跑通自己的数据集]]></summary></entry><entry><title type="html">ORB-SLAM3在windows下的编译使用</title><link href="http://localhost:4000/orb_slam3.html" rel="alternate" type="text/html" title="ORB-SLAM3在windows下的编译使用" /><published>2021-05-12T10:11:00+08:00</published><updated>2021-05-12T10:11:00+08:00</updated><id>http://localhost:4000/orb_slam3</id><content type="html" xml:base="http://localhost:4000/orb_slam3.html"><![CDATA[<h3 id="一-数据集">一. 数据集</h3>

<h4 id="11-数据集介绍">1.1 数据集介绍</h4>

<p><a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets">Euroc</a>：基于室内的MAV(Micro Aerial Vehicle，微型飞行器)，一共两个场景（Machine Hall + Vicon Room）,其中每个数据集包含2个下载连接：</p>

<ul>
  <li>ROS(Robot Operating System) bag：机器人操作库，适用于嵌入式，这里推荐一个很好的双目+IMU应用在jetson nano上的<a href="https://github.com/tau-adl/Position-Control-Using-ORBSLAM2-on-the-Jetson-Nano">git</a>。</li>
  <li>ASL Dataset Format：数据集结构，包含传感器文件和双目相机的图片。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/orb_1.jpg" alt="" /></p>

<h4 id="12-数据使用介绍">1.2 数据使用介绍</h4>

<p>可用的数据包含：</p>

<ul>
  <li>Visual-Inertial Sensor Unit（视觉惯性传感器单元）
    <ul>
      <li>Stereo Images（双目图片）</li>
      <li>IMU（惯导数据）</li>
    </ul>
  </li>
  <li>Ground-Truth位姿轨迹
    <ul>
      <li><strong>Vicon</strong> 6轴运动姿态捕捉系统</li>
      <li><strong>Leica MS50</strong> 3维姿态镭射追踪</li>
      <li><strong>Leica MS50</strong> 3维重构</li>
    </ul>
  </li>
</ul>

<h4 id="13-imu数据介绍">1.3 IMU数据介绍</h4>

<ul>
  <li>w_RS_S_x [rad s^-1] ：MAV在R坐标系下的x轴角速度信息，单位rad/s</li>
  <li>w_RS_S_y [rad s^-1] ：MAV在R坐标系下的y轴角速度信息，单位rad/s</li>
  <li>w_RS_S_z [rad s^-1] ：MAV在R坐标系下的z轴角速度信息，单位rad/s</li>
  <li>a_RS_S_x [m s^-2]：MAV在R坐标系下x轴的线加速度信息，单位m/s^2</li>
  <li>a_RS_S_y [m s^-2]：MAV在R坐标系下y轴的线加速度信息，单位m/s^2</li>
  <li>a_RS_S_z [m s^-2]：MAV在R坐标系下z轴的线加速度信息，单位m/s^2</li>
</ul>

<h3 id="二-第三方包编译">二. 第三方包编译</h3>

<blockquote>
  <p>ORB_SLAM3论文地址：https://arxiv.org/pdf/2007.11898.pdf</p>

  <p>使用<a href="https://github.com/UZ-SLAMLab/ORB_SLAM3">ORB_SLAM3官方git</a>，推荐使用的系统为<a href="https://www.linuxidc.com/Linux/2019-02/156914.htm">ubuntu 18.04</a>，本人用win 10下进行测试的，这里推荐一个在win 10下编译ORB_SLAM3的<a href="https://github.com/melhashash/orbslam3-windows">git</a>，目前在该仓库下编译运行没毛病！</p>
</blockquote>

<h4 id="21-前期依赖的第三方包">2.1 前期依赖的第三方包</h4>

<ul>
  <li>eigen：线性算术的C++模板库（属于g2o的依赖），这里直接用vcpkg安装<code class="language-plaintext highlighter-rouge">vcpkg install eigen</code></li>
  <li>boost：后面编译ORB_SLAM3库需要，这里也是直接用vcpkg安装<code class="language-plaintext highlighter-rouge">vcpkg install boost</code>。</li>
  <li>opencv3.4.11：编译DBoW2和ORB_SLAM3需要。直接上官网下载exe即可，当然也可以利用vcpkg进行安装。</li>
</ul>

<h4 id="22-dbow2">2.2 DBoW2</h4>

<p>用于SLAM回环检测，这里需要配置opencv环境。具体过程如下：</p>

<ul>
  <li>
    <p>给<code class="language-plaintext highlighter-rouge">Thirdparty/DBoW2/CMakeLists.txt</code>配置opencv3.4.11的路径</p>

    <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set</span><span class="p">(</span>OpenCV_DIR <span class="s2">"D:/software/opencv/opencv/build"</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>在<code class="language-plaintext highlighter-rouge">Thirdparty/DBoW2</code>路径下新建一个<code class="language-plaintext highlighter-rouge">build</code>文件夹，cmake生成<code class="language-plaintext highlighter-rouge">cmake ..</code></p>
  </li>
  <li>
    <p>看到<code class="language-plaintext highlighter-rouge">configuration done</code>的时候，用vs2019打开<code class="language-plaintext highlighter-rouge">build/DBoW2.sln</code></p>
  </li>
  <li>
    <p>将配置改成<code class="language-plaintext highlighter-rouge">release</code>，同时右键项目==&gt; 属性 ==&gt; 常规 ==&gt; 配置类型 ==&gt; <strong>静态库(.lib)</strong>；属性 ==&gt; 高级 ==&gt; 目标文件扩展名 ==&gt; <strong>.lib</strong>；C/C++ ==&gt; 代码生成 ==&gt; 运行库 ==&gt; <strong>多线程 (/MT)</strong></p>
  </li>
  <li>
    <p>右键项目 ==&gt; 生成，即可看到生成好的lib文件<code class="language-plaintext highlighter-rouge">Thirdparty/DBoW2/lib/Release/DBoW2.lib</code></p>
  </li>
</ul>

<h4 id="23-g2o">2.3 g2o</h4>

<p>用于图优化的框架。具体过程如下：</p>

<ul>
  <li>在<code class="language-plaintext highlighter-rouge">Thirdparty/g2o</code>路径下新建一个<code class="language-plaintext highlighter-rouge">build</code>文件夹，cmake生成<code class="language-plaintext highlighter-rouge">cmake ..</code></li>
  <li>看到<code class="language-plaintext highlighter-rouge">configuration done</code>的时候，用vs2019打开<code class="language-plaintext highlighter-rouge">build/g2o.sln</code></li>
  <li>将配置改成<code class="language-plaintext highlighter-rouge">release</code>，同时右键项目==&gt; 属性 ==&gt; 常规 ==&gt; 配置类型 ==&gt; <strong>静态库(.lib)</strong>；属性 ==&gt; 高级 ==&gt; 目标文件扩展名 ==&gt; <strong>.lib</strong>；C/C++ ==&gt; 代码生成 ==&gt; 运行库 ==&gt; <strong>多线程 (/MT)</strong>；C/C++ ==&gt; 预处理器 ==&gt;最上面加入<code class="language-plaintext highlighter-rouge">WINDOWS</code></li>
  <li>右键项目 ==&gt; 生成，即可看到生成好的lib文件<code class="language-plaintext highlighter-rouge">Thirdparty/g2o/build/Release/g2o.lib</code></li>
</ul>

<h4 id="24-pangolin">2.4 Pangolin</h4>

<p>用于3D视觉和3D导航的视觉图和用户之间的交互。这里其实和<strong>编译ORB_SLAM3没有关系</strong>，但是我们使用ORB_SLAM3库的时候应用的例子上是需要这个库的。具体过程如下：</p>

<ul>
  <li>
    <p>在<code class="language-plaintext highlighter-rouge">Thirdparty/g2o</code>路径下新建一个<code class="language-plaintext highlighter-rouge">build</code>文件夹，cmake生成<code class="language-plaintext highlighter-rouge">cmake ..</code></p>
  </li>
  <li>
    <p>看到<code class="language-plaintext highlighter-rouge">configuration done</code>的时候，用vs2019打开<code class="language-plaintext highlighter-rouge">build/Pangolin.sln</code></p>
  </li>
  <li>
    <p>将配置改成<code class="language-plaintext highlighter-rouge">release</code>，同时右键项目==&gt; 属性 ==&gt; 常规 ==&gt; 配置类型 ==&gt; <strong>静态库(.lib)</strong>；属性 ==&gt; 高级 ==&gt; 目标文件扩展名 ==&gt; <strong>.lib</strong>；C/C++ ==&gt; 代码生成 ==&gt; 运行库 ==&gt; <strong>多线程 (/MT)</strong></p>
  </li>
  <li>
    <p>这里是需要下载它依赖的其他库的，最好对git设置代理</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config <span class="nt">--global</span> http.proxy http://127.0.0.1:1080
git config <span class="nt">--global</span> https.proxy http://127.0.0.1:1080
</code></pre></div>    </div>
  </li>
  <li>
    <p>右键ALL_BUILD ==&gt; 生成，即可看到生成好的lib文件<code class="language-plaintext highlighter-rouge">ThirdParty/Pangolin/lib/Release/pangolin.lib</code></p>
  </li>
</ul>

<h3 id="三编译orb_slam3">三.编译ORB_SLAM3</h3>

<ul>
  <li>
    <p>给<code class="language-plaintext highlighter-rouge">orbslam3-windows/CMakeLists.txt</code>配置opencv3.4.11的路径</p>

    <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set</span><span class="p">(</span>OpenCV_DIR <span class="s2">"D:/software/opencv/opencv/build"</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>在<code class="language-plaintext highlighter-rouge">orbslam3-windows</code>的路径下新建一个<code class="language-plaintext highlighter-rouge">build</code>文件夹，cmake生成<code class="language-plaintext highlighter-rouge">cmake ..</code></p>
  </li>
  <li>
    <p>看到<code class="language-plaintext highlighter-rouge">configuration done</code>的时候，用vs2019打开<code class="language-plaintext highlighter-rouge">build/ORB_SLAM3.sln</code></p>
  </li>
  <li>
    <p>将配置改成<code class="language-plaintext highlighter-rouge">release</code>，同时右键项目==&gt; 属性 ==&gt; 常规 ==&gt; 配置类型 ==&gt; <strong>静态库(.lib)</strong>；属性 ==&gt; 高级 ==&gt; 目标文件扩展名 ==&gt; <strong>.lib</strong>；C/C++ ==&gt; 代码生成 ==&gt; 运行库 ==&gt; <strong>多线程 (/MT)</strong>；C/C++ ==&gt; 预处理器 ，添加以下预编译器定义</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WINDOWS
COMPILEDWITHC11
</code></pre></div>    </div>
  </li>
  <li>
    <p>右键项目 ==&gt; 生成，即可看到生成好的lib文件<code class="language-plaintext highlighter-rouge">ORB_SLAM3/build/Release/ORB-SLAM3.lib</code></p>
  </li>
</ul>

<h3 id="四-编译测试案例及展示">四. 编译测试案例及展示</h3>

<h4 id="41-编译stereo_inertial_euroc">4.1 编译stereo_inertial_euroc</h4>

<ul>
  <li>用vs2019打开<code class="language-plaintext highlighter-rouge">build/ORB_SLAM3.sln</code></li>
  <li>将配置改成<code class="language-plaintext highlighter-rouge">release</code>，同时右键项目stereo_inertial_tum_vi ==&gt; 属性 ==&gt; C/C++ ==&gt; 代码生成 ==&gt; 运行库 ==&gt; <strong>多线程 (/MT)</strong>；C/C++ ==&gt; 预处理器 ，添加以下预编译器定义<code class="language-plaintext highlighter-rouge">COMPILEDWITHC11</code>；链接器 ==&gt; 高级 ==&gt; 导入库，改为空；链接器 ==&gt; 输入 ==&gt; 去掉<code class="language-plaintext highlighter-rouge">..\Thirdparty\boost_1_67_0\lib64-msvc-14.1\libboost_serialization-vc141-mt-s-x64-1_67.lib</code>（由于这里是vcpkg安装的boost，因此该路径下根本没有这个lib）。</li>
  <li>右键项目 ==&gt; 生成，即可看到生成好的exe文件<code class="language-plaintext highlighter-rouge">ORB_SLAM3/Examples/Stereo-Inertial/Release/stereo_inertial_tum_vi.exe</code></li>
</ul>

<h4 id="42-使用展示案例stereo_inertial_euroc">4.2 使用展示案例stereo_inertial_euroc</h4>

<p>这个案例是双目 + 惯导的Euroc数据集的应用。</p>

<ul>
  <li>将下载好的数据集文件夹名字改成<code class="language-plaintext highlighter-rouge">MH01</code>(这里是由于本人下载是MH_01_easy.zip)</li>
  <li>
    <p>进入到生成好的exe文件夹下<code class="language-plaintext highlighter-rouge">cd orbslam3-windows\Examples\Stereo-Inertial\Release</code>，可以看到生成好的<code class="language-plaintext highlighter-rouge">stereo_inertial_euroc.exe</code></p>
  </li>
  <li>
    <p>开启程序：<code class="language-plaintext highlighter-rouge"> .\stereo_inertial_euroc.exe ..\..\..\Vocabulary\ORBvoc.txt ..\EuRoC.yaml ..\MH01\ ..\EuRoC_TimeStamps\MH01.txt dataset-MH01_stereoi</code></p>
  </li>
  <li>结果展示如下图所示：</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/orb_2.jpg" alt="" /></p>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><summary type="html"><![CDATA[讲述ORB-SLAM3在windows下的编译及其使用]]></summary></entry><entry><title type="html">目标检测(one stage)-从FPN到DSSD</title><link href="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_4.html" rel="alternate" type="text/html" title="目标检测(one stage)-从FPN到DSSD" /><published>2021-04-28T05:11:00+08:00</published><updated>2021-04-28T05:11:00+08:00</updated><id>http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_4</id><content type="html" xml:base="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_4.html"><![CDATA[<h3 id="一-fpn特征金字塔网络">一. FPN特征金字塔网络</h3>

<blockquote>
  <p>论文地址：https://arxiv.org/pdf/1612.03144.pdf</p>
</blockquote>

<p>这篇论文发布的时间是2017年4月19号，可以说在此之后，对于目标检测（小物体）而言，提升巨大，基本之后的模型比如DSSD，yolov3等都参考过该模型架构。</p>

<h4 id="11-解决的问题">1.1 解决的问题</h4>

<ul>
  <li>目标检测的基本挑战（问题）：识别多尺度变化的目标能力不足。这里解决了一下两个方面的难点：
    <ol>
      <li>相机距离目标远近不同导致拍摄的图片中目标尺寸不同而导致识别效率低下。</li>
      <li>小目标物体的识别较难。</li>
    </ol>
  </li>
</ul>

<h4 id="12-图像特征金字塔">1.2 图像特征金字塔</h4>

<p>特征金字塔是在不同大小尺寸的目标检测中的一个基础组件。</p>

<ul>
  <li>如下图所示，经过多次特征抽取后，越到高层的feature map所囊括的细节信息就越少，对于底层信息（比如小的目标）预测就越难。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_1.jpg" alt="" /></p>

<ul>
  <li>那么图像特征金字塔做了什么呢？既对同一张图片进行多次下采样，从而得到多张不同尺寸的图片，进而生成不同尺寸的feature map，从而使模型拥有对不同尺度大小的物体进行检测的能力。但是论文中也提出它的问题：<strong>消耗太大的内存和计算量</strong>。</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_2.jpg" alt="" /></p>

<ul>
  <li>
    <p>看到上面这张图的时候，你是不是觉得很熟悉？和某个网络的推理层很像？是的，就是SSD。SSD和YOLOv1最大的差别（之前的文章中有讲，有兴趣可以查看本人之前的文章）其实是推理层的不同，SSD用的就是多尺度的特征图综合来预测目标，从而达到对于小物体也能够检测的目的。</p>
  </li>
  <li>
    <p>如下图所示，是不是感觉和上面的图像特征金字塔很像？差别还是有的，SSD是对同一张图片进行卷积抽取其不同尺度的feature map进行分别做预测，而特征金字塔是对不同尺度的图片分别做特征抽取得到不同尺度的feature map在分别做预测。这里论文中也提到SSD的<strong>缺点</strong>：<strong>失去了高层语义信息重用的机会，导致低层语义信息不足</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_3.jpg" alt="" /></p>
  </li>
</ul>

<h4 id="13-特征金字塔网络fpn">1.3 特征金字塔网络（FPN）</h4>

<blockquote>
  <p>这里推荐一篇个人认为不错的git仓库：<a href="https://github.com/potterhsu/easy-fpn.pytorch">easy-fpn.pytorch</a>，是由pytorch复现的fpn网络。</p>
</blockquote>

<p>FPN的网络结构如下图所示：</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_4.jpg" alt="" /></p>

<p>我们可以看到，其实说白了FPN相较于SSD和特征金字塔厉害的地方：</p>

<ul>
  <li>强于SSD：重用了高层语义信息，每次预测都是结合了当前层和上一层的语义信息，使每一层不同尺度的特征图都具有较强的语义信息。</li>
  <li>强于特征金字塔：同样通过上下采样（这里不同的是采样的feature map），使模型拥有对不同尺度大小的物体进行检测的能力，却又构建了一个端到端的网络。</li>
</ul>

<p>下面是来源于我上面推荐的git仓库的FPN网络的细节架构图。方便我们很好的理解FPN中到底做了什么。如下图所示，从底层的feature map（1067 * 800）到高层的feature map(34 * 25)，每层feature map经过1 * 1的卷积之后和经过up sample之后的上层feature map做一个add操作，在进行推理。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_5.jpg" alt="" /></p>

<p>下面是细节复现的pytorch代码：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Bottom-up pathway
</span><span class="n">c1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">c1</span><span class="p">)</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span>
<span class="n">c4</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv4</span><span class="p">(</span><span class="n">c3</span><span class="p">)</span>
<span class="n">c5</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv5</span><span class="p">(</span><span class="n">c4</span><span class="p">)</span>

<span class="c1"># Top-down pathway and lateral connections
</span><span class="n">p5</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lateral_c5</span><span class="p">(</span><span class="n">c5</span><span class="p">)</span>
<span class="n">p4</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lateral_c4</span><span class="p">(</span><span class="n">c4</span><span class="p">)</span> <span class="o">+</span> <span class="n">F</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">p5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">c4</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">c4</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">nearest</span><span class="sh">'</span><span class="p">)</span>
<span class="n">p3</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lateral_c3</span><span class="p">(</span><span class="n">c3</span><span class="p">)</span> <span class="o">+</span> <span class="n">F</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">p4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">c3</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">c3</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">nearest</span><span class="sh">'</span><span class="p">)</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lateral_c2</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span> <span class="o">+</span> <span class="n">F</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">p3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">c2</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">c2</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">nearest</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Reduce the aliasing effect
</span><span class="n">p4</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dealiasing_p4</span><span class="p">(</span><span class="n">p4</span><span class="p">)</span>
<span class="n">p3</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dealiasing_p3</span><span class="p">(</span><span class="n">p3</span><span class="p">)</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dealiasing_p2</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>

<span class="n">p6</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">max_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">p5</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="二-dssd">二. DSSD</h3>

<blockquote>
  <p>论文地址：https://arxiv.org/abs/1701.06659.pdf</p>
</blockquote>

<p>这篇论文发布的时间是2017年1月23号。DSSD(Deconvolutional Single Shot Detector)，听名字就知道了，是SSD的升级版本，而且其实就是SSD + FPN的结合体，但是很奇怪，为啥你还在别人FPN后面发布呢？</p>

<h4 id="21-和ssd的差别">2.1 和SSD的差别</h4>

<p>下图是SSD和DSSD的网络架构示意图。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_6.jpg" alt="" /></p>

<p>SSD和DSSD在前面特征抽取层的backbone都是一样的，差别在于后面推理的过程：</p>

<ul>
  <li>SSD的推理过程经过多个卷积得到的不同尺寸的特征图来进行预测。</li>
  <li>DSSD的推理过程是FPN网络架构的复现：由底层特征结合经up sampling之后的上层特征，做一个结合的操作，论文中提到2中结合方式：
    <ul>
      <li>Eltw-sum：也叫broadcast add，将浅层和深层的特征图在对应的通道上做加法运算。</li>
      <li>Eltw-prod：也叫broadcast mul，将浅层和深层的特征图在对应的信道上做乘法运算。</li>
    </ul>
  </li>
</ul>

<h4 id="22-dssd在模型效果上的提升">2.2 DSSD在模型效果上的提升</h4>

<p>下图是SSD（左1和右1）和DSSD（左2和右2）的模型在同一张图片上的检测效果。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_7.jpg" alt="" /></p>

<p>可以明显的发现：</p>

<ul>
  <li>DSSD能检测到更多的目标。</li>
  <li>DSSD能检测到更小的目标。</li>
</ul>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><category term="深度学习" /><summary type="html"><![CDATA[讲述目标检测(one stage)-从FPN到DSSD]]></summary></entry><entry><title type="html">C++下消息队列（多消费者模式）的实现</title><link href="http://localhost:4000/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84C++%E5%AE%9E%E7%8E%B0.html" rel="alternate" type="text/html" title="C++下消息队列（多消费者模式）的实现" /><published>2021-04-24T07:21:00+08:00</published><updated>2021-04-24T07:21:00+08:00</updated><id>http://localhost:4000/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84C++%E5%AE%9E%E7%8E%B0</id><content type="html" xml:base="http://localhost:4000/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84C++%E5%AE%9E%E7%8E%B0.html"><![CDATA[<blockquote>
  <p>不允许用现成的消息队列比如rabbitmq等，非要造轮子！</p>
</blockquote>

<h3 id="一-生产者-消费者模式">一. 生产者-消费者模式</h3>

<ul>
  <li>生产者：这里由于是通过txt文件来进行交互，相当于txt文件的内容就是生产者，同时还需要实时监控txt文件，将其新消息放入队列。</li>
  <li>
    <p>消费者：从队列中取消息，并需要告诉队列该条消息已经被消费。</p>
  </li>
  <li>断点续传：需要考虑到程序崩溃之后，知道从哪开始消费。</li>
</ul>

<h4 id="11-多消费者多线程">1.1 多消费者——多线程</h4>

<p>这里如果如果是IO操作较多的话，推荐使用多线程来创建消费者。具体创建和消费的过程如下：</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/sumer_1.png" alt="" /></p>

<ul>
  <li>
    <p>我们可以看到其实这里的多消费者其实是串联的形式来进行消费，因此如果是CPU资源低，IO操作多的话，推荐这种形式。</p>
  </li>
  <li>
    <p>多线程之间的内存变量交互很友善，不像多进程（哎，难受啊）。</p>
  </li>
</ul>

<h4 id="12-多消费者多进程">1.2 多消费者——多进程</h4>

<ul>
  <li>考虑到这里是需要像CPU请求较多资源，甚至是需要使用GPU的资源和利用CUDA加速（深度学习模型占用资源较多），因此我这里使用的是多进程来构建消费者。具体创建和消费过程如下:</li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/sumer_2.png" alt="" /></p>

<h3 id="二-过程的实现">二. 过程的实现</h3>

<blockquote>
  <p>具体代码可以参考本人的<a href="https://github.com/yy2lyx/CplusDemos/tree/main/messageQueue">git</a></p>
</blockquote>

<ul>
  <li>
    <p>定时器：每隔一段时间扫描txt文件，并将文件中新加入的消息存放入队列中。</p>

    <pre><code class="language-C++">// timer扫描
int wait_sec = 1;
// 单独启动一个线程持续扫描文件（每5秒）
string path = "video.txt";
Timer timer1;
timer1.start(2000, std::bind(getVideoFromTxt, path, wait_sec, &amp;output));
</code></pre>
  </li>
  <li>
    <p>中间件：需要存放已经消费的消息，这样知道消费的具体位置，且支持程序崩溃/断掉之后，重启后知道在哪开始消费，同样用txt进行保存到本地。</p>
  </li>
  <li>
    <p>多消费者：使用多进程创建消费者，这里考虑到进程中间的共享内存不好交互，直接使用txt来交互数据（反正进程之间的内存交互其实也是通过一个共享文件映射来完成的）。这里直接使用调用命令行的方式来构建消费者。</p>

    <pre><code class="language-C++">void gen_multiProcess(int id, string input_txt,string output_txt) {
  
	STARTUPINFO si;
	si.cb = sizeof(si);
	PROCESS_INFORMATION pi;
	ZeroMemory(&amp;si, sizeof(si));
	ZeroMemory(&amp;pi, sizeof(pi));
	string cmdLine = "D:/vs_project/setTimer/x64/Debug/setTimer.exe " + input_txt + " " + output_txt;
	cout &lt;&lt; cmdLine &lt;&lt; endl;
	wstring str = StringToWString(cmdLine);
  
	BOOL bSuccess = CreateProcess(NULL,
		const_cast&lt;LPWSTR&gt;(str.c_str()),
		NULL, NULL, FALSE, 0, NULL, NULL, &amp;si, &amp;pi);
  
	if (bSuccess) {
		//handleOfProcess[id] = pi.hProcess;
		cout &lt;&lt; "Process-" &lt;&lt; id &lt;&lt; "completed!" &lt;&lt; endl;
	}
	else {
		cout &lt;&lt; "Error:" &lt;&lt; id &lt;&lt; endl;
	}
}
</code></pre>
  </li>
</ul>

<h3 id="三-收获">三. 收获</h3>

<p>其实手写消息队列，帮助自己更多的了解消息消费机制，以及多进程和多线程的使用，当然了也更了解了C++的标准库。所以推荐大家还是亲手动手手写一哈。哎，作为一个python调包侠突然写这种偏底层，有点难受好吧。</p>]]></content><author><name>李小肥的YY</name></author><category term="代码" /><summary type="html"><![CDATA[讲述在C++下实现的消息队列（多消费者模式）]]></summary></entry><entry><title type="html">目标检测(one stage)-YOLOv2</title><link href="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_3.html" rel="alternate" type="text/html" title="目标检测(one stage)-YOLOv2" /><published>2021-04-21T04:21:00+08:00</published><updated>2021-04-21T04:21:00+08:00</updated><id>http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_3</id><content type="html" xml:base="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_3.html"><![CDATA[<h3 id="一-与v1的不同之处">一. 与V1的不同之处</h3>

<p>YOLOv2相较于YOLOv1在VOC2007数据集上表现从63.4%提升到78.6%。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_1.jpg" alt="" /></p>

<p>YOLOv2与YOLOv1的不同之处一共体现在下面几个方面：</p>

<ul>
  <li>
    <p><strong>Batch Normalization</strong>（批归一化层）：在模型不过拟合的前提下，可以拿掉Dropout层；同时加速模型训练。在VOC2007数据集上效果<strong>mAP提升2.4%</strong>。</p>
  </li>
  <li>
    <p><strong>High Resolution Classifier</strong>（提高分辨率）:原本YOLOv1中模型训练的使用的是224 * 224分辨率的图像，现在resize成448 * 448的图片，最后经过10个epoch的微调。在VOC2007数据集上效果<strong>mAP提升3.7%</strong>。</p>
  </li>
  <li>
    <p><strong>Convolutional With Anchor Boxes</strong>（提高检测目标数量）：原本yolov1中将其中一个pool层拿掉后， feature map的大小由7 * 7 变成了13 * 13，然后每个1 * 1的grid里面增加了K个anchor boxes，因此从yolov1只能检测7 * 7 = 49个目标，增加到了13 * 13 * K个目标。在VOC2007数据集上效果<strong>虽然mAP下降了0.3%，但是在Recall上提升了7%</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_2.jpg" alt="" /></p>
  </li>
  <li>
    <p><strong>New Network</strong>（DarkNet-19）：提出了一个新的网络架构DarkNet-19（19个Conv 和 5个MaxPool），能够在YOLOv1的基础上减少33%的计算量。在VOC2007数据集上效果<strong>mAP提升0.4%</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_3.jpg" alt="" /></p>
  </li>
  <li>
    <p><strong>Dimension Clusters</strong>（尺度聚类）：如果Anchor boxes一开始就能和实际的物体的宽高比很接近，那么对于模型的收敛是否有帮助呢？YOLOv2这里就是使用了KMeans对所有的图片的宽高比（利用IOU计算之间的距离）进行聚类，结果是聚类个数K取5效果最好，从而每个grid中找到5个最好的预选框。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_4.jpg" alt="" /></p>
  </li>
  <li>
    <p><strong>Direct Location Prediction</strong>（绝对位置预测）：模型原本的anchor box在预测物体的x,y坐标时候会发生数值不稳定的现象（而R-CNN网络的boundingbox并非随机，而是由RPN网络生成），毕竟随机初始化的anchor box的位置，肯定需要花费大量时间才能学习到合适的位置。那么yolov2是如何完成？这里红色为anchor box，蓝色为模型的预测框，这里引入sigmoid函数来缩小到(0,1)之间，同时对计算后的结果进行归一化的处理，</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_5.jpg" alt="" /></p>

    <p>使用尺度聚类和直接位置预测两种方式后模型在VOC2007数据集上效果<strong>mAP提升4.8%</strong>。</p>
  </li>
  <li>
    <p><strong>Fine-Grained Features</strong>（颗粒度特征）：将feature map拆解成更小的feature map。借由前面DarkNet得到高解析度的特征拆解成小解析度的特征，因此来检测较小的物体。VOC2007数据集上效果<strong>mAP提升1%</strong>。</p>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_6.jpg" alt="" /></p>

<ul>
  <li>
    <p><strong>Muti-Scale Training</strong>（多尺度训练）：每10个batch去做一个resize的动作，从一开始的320 * 320到最终的608 * 608，最后得到的feature map从开始的10 * 10到19 * 19。VOC2007数据集上效果<strong>mAP提升1.2%</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_7.jpg" alt="" /></p>
  </li>
  <li>
    <p><strong>High Resolution Detector</strong>（输入大size的input）：通过输入图像尺寸更大，使得模型检测到更小物体。下图是从288到544尺寸之间mAP提升效果，当然fps会相应的减少。VOC2007数据集上效果<strong>mAP提升2%</strong>。</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_8.jpg" alt="" /></p>
  </li>
</ul>

<h3 id="二-其他模型的比较">二. 其他模型的比较</h3>

<p>下图是YOLOv2在COCO2015数据集上的表现。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_9.jpg" alt="" /></p>

<p>可以看到YOLOv2相较于SSD还有一些的差距的。</p>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><category term="深度学习" /><summary type="html"><![CDATA[目标检测（one stage）——YOLOv2]]></summary></entry><entry><title type="html">windows下安装python-pcl</title><link href="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL.html" rel="alternate" type="text/html" title="windows下安装python-pcl" /><published>2021-04-10T18:21:00+08:00</published><updated>2021-04-10T18:21:00+08:00</updated><id>http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL</id><content type="html" xml:base="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL.html"><![CDATA[<h3 id="一-准备工作">一. 准备工作</h3>

<ul>
  <li><strong>python 版本：3.7.9</strong>
    <ul>
      <li>cython</li>
      <li>numpy</li>
    </ul>
  </li>
  <li><strong>python-pcl:1.9.1</strong>
    <ul>
      <li><a href="https://github.com/strawlab/python-pcl">python-pcl源码</a>：后面需要进行编译</li>
      <li><a href="https://github.com/PointCloudLibrary/pcl/releases/">PCL1.9.1的All-In-One Installer</a> ：目前安装仅支持1.6到1.9的版本</li>
    </ul>
  </li>
  <li><strong>visual studio 2019</strong></li>
  <li><strong><a href="http://www.tarnyko.net/dl/gtk.htm">Windows Gtk</a></strong></li>
</ul>

<h3 id="二-安装">二. 安装</h3>

<ul>
  <li>
    <p>将下载好的ALL-In-One Installer进行安装，这里会要求你添加到环境变量（必须添加啊），并且会安装OpenNI这个工具。</p>
  </li>
  <li>
    <p>解压下载好的windows Gtk，将<code class="language-plaintext highlighter-rouge">bin</code>目录下所有文件复制到python-pcl源码目录下的<code class="language-plaintext highlighter-rouge">pkg-config</code>目录下。</p>
  </li>
  <li>
    <p>在<code class="language-plaintext highlighter-rouge">pkg-config</code>目录下，运行脚本<code class="language-plaintext highlighter-rouge">InstallWindowsGTKPlus.bat</code>，该脚本会下载必须的内容，下载完成后会多出这些文件夹，如下图所示</p>

    <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/pcl_1.png" alt="" /></p>
  </li>
  <li>
    <p>安装python的pcl包：</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">cd 你安装python-pcl源码目录</code></li>
      <li><code class="language-plaintext highlighter-rouge">python setup.py build_ext -i</code></li>
      <li><code class="language-plaintext highlighter-rouge">python setup.py install</code></li>
    </ul>
  </li>
</ul>

<h3 id="三-安装遇到的坑">三. 安装遇到的坑</h3>

<h4 id="31-坑一cannot-find-pcl">3.1 坑一：cannot find PCL</h4>

<ul>
  <li>问题：当你运行<code class="language-plaintext highlighter-rouge">python setup.py build_ext -i</code>的时候报出：<code class="language-plaintext highlighter-rouge">setup.py: error: cannot find PCL, tried 		pkg-config pcl_common-1.7 		pkg-config pcl_common-1.6 		pkg-config pcl_common</code></li>
  <li>解决方案：这里就是上面说的，别下除了1.6到1.9版本的pcl的All-In-One Installer啊。</li>
</ul>

<h4 id="32-坑二dll-load-failed">3.2 坑二：DLL load failed</h4>

<ul>
  <li>问题：全部安装完成之后，一切没有问题了，当你打开python，运行<code class="language-plaintext highlighter-rouge">import pcl</code>的时候报出：<code class="language-plaintext highlighter-rouge">DLL load failed</code>。</li>
  <li>解决方案：重启电脑！</li>
</ul>

<h3 id="四-python版本的使用">四. python版本的使用</h3>

<h4 id="41--点云数据的展示python">4.1  点云数据的展示（python）</h4>

<p>构建点云–Point_XYZRGBA格式(需要点云数据是N*4，分别表示x,y,z,RGB ,其中RGB 用一个整数表示颜色)，下面是python版本的点云数据展示</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pcl</span>
<span class="kn">import</span> <span class="n">pcl.pcl_visualization</span> <span class="k">as</span> <span class="n">viewer</span>  <span class="c1">#可视化库
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># cloud = pcl.load("cloud.pcd")
</span><span class="n">cloud_np</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">cloud.npy</span><span class="sh">"</span><span class="p">)</span>
<span class="n">cloud</span> <span class="o">=</span> <span class="n">pcl</span><span class="p">.</span><span class="nc">PointCloud_PointXYZRGBA</span><span class="p">(</span><span class="n">cloud_np</span><span class="p">)</span>
<span class="n">visual</span> <span class="o">=</span> <span class="n">pcl</span><span class="p">.</span><span class="n">pcl_visualization</span><span class="p">.</span><span class="nc">CloudViewing</span><span class="p">()</span>
<span class="n">visual</span><span class="p">.</span><span class="nc">ShowColorACloud</span><span class="p">(</span><span class="n">cloud</span><span class="p">)</span>

<span class="n">v</span> <span class="o">=</span> <span class="bp">True</span>
<span class="k">while</span> <span class="n">v</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span><span class="n">visual</span><span class="p">.</span><span class="nc">WasStopped</span><span class="p">())</span>
</code></pre></div></div>

<h4 id="42-命令行展示">4.2 命令行展示</h4>

<p>由于上面已经下载了PCL1.9.1了，可以直接在命令行中进行展示：<code class="language-plaintext highlighter-rouge">pcl_viewer_release H cloud.PCD</code>，下面的是来自Middlebury 2014数据集中经过立体匹配后的3D点云图。</p>

<p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/pcl_2.png" alt="" /></p>]]></content><author><name>李小肥的YY</name></author><category term="机器视觉" /><summary type="html"><![CDATA[介绍如何在win10下安装python版本的PCL点云库]]></summary></entry></feed>