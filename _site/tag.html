<!DOCTYPE html>
<html lang="en">
  




<head>
	<meta charset="utf-8">
	<title>Tag - 凡人炼丹传</title>
	<link rel="canonical" href="http://localhost:4000/tag.html">
	<meta name="description" content="欢迎各位看官光临本小站，希望共同学习进步哈！">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:4000"},
  "headline": "Tag",
  "abstract": "",
    "keywords": "",
    "wordcount": "74",
    "image": ["http://localhost:4000/assets/img"],
  "datePublished": "",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": ""},
  "publisher": {
    "@type":  "Organization",
    "logo": {
        "@type": "ImageObject",
        "encodingFormat": "image/png",
        "contentUrl": "http://localhost:4000/assets/img/branding/logo1.png",
        "url": "http://localhost:4000/assets/img/branding/logo1.png"},
    "name" : "凡人炼丹传"}
}
</script>
<!-- Open Graph data -->
<meta property="og:url" content="http://localhost:4000/tag.html"/>
<meta property="og:type" content="article"/>
<meta property="og:title" content="Tag"/>
<meta property="og:description" content=""/>
<meta property="og:image" content="http://localhost:4000/assets/img"/>
<meta property="og:image:alt" content="Tag"/>
<meta property="og:site_name" content="凡人炼丹传" />
<meta property="article:published_time" content="" />
<meta property="article:modified_time" content="" />
<meta property="article:tag" content="" />
<meta property="fb:admins" content="ar.maybach" />
<!-- Schema.org markup for Google -->
<meta itemprop="name" content="Tag">
<meta itemprop="description" content="">
<meta itemprop="image" content="http://localhost:4000/assets/img">
<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="">
<meta name="twitter:title" content="Tag">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="">
<meta data-rh="true" name="twitter:label1" content="Word count"/>
<meta data-rh="true" name="twitter:data1" content="74"/>
<meta name="twitter:image:src" content="http://localhost:4000/assets/img/">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#311e3e">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#311e3e">
	<!-- Google Fonts -->
	<link rel="preconnect" href="https://fonts.gstatic.com" />
	<style>
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 600;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 200;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3i94_wlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 700;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
	</style>
	<!-- <link href="https://fonts.googleapis.com/css?family=Lora:400,600|Source+Sans+Pro:200,400,700" rel="stylesheet"> -->
	<!-- Font Awesome -->
	<link rel="stylesheet" href="./assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="./assets/css/main.css">
	




<link rel="icon" href="./assets/img/favicon/favicon.ico" type="image/x-icon">
<link rel="apple-touch-icon" href="./assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="72x72" href="./assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="114x114" href="./assets/img/favicon/favicon.ico">
	
</head>

  <body>
    <div class="flex-container transparent">
  




<header class="main-header">
  <div class="wrapper">
    <div class="header-flex">
      <div class="menu-icon-container">
        <span class="menu-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
      </div>
      <nav class="main-nav">
        <span class="menu-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
        <ul>
          <li>
            <div class="theme-toggle night">
    <input class="night" type="checkbox" id="theme-switch">
    <label class="night" for="theme-switch">
        <div class="toggle night"></div>
        <div class="names night">             
        <p class="light night"><svg class="night" width="20" viewBox="0 0 25 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M12.5 2.49871C11.3401 2.50016 10.2282 2.96156 9.40801 3.78171C8.58785 4.60187 8.12645 5.71383 8.125 6.87371C8.125 7.03947 8.19085 7.19844 8.30806 7.31565C8.42527 7.43286 8.58424 7.49871 8.75 7.49871C8.91576 7.49871 9.07473 7.43286 9.19194 7.31565C9.30915 7.19844 9.375 7.03947 9.375 6.87371C9.37593 6.04519 9.70547 5.25088 10.2913 4.66503C10.8772 4.07918 11.6715 3.74964 12.5 3.74871C12.6658 3.74871 12.8247 3.68286 12.9419 3.56565C13.0592 3.44844 13.125 3.28947 13.125 3.12371C13.125 2.95795 13.0592 2.79898 12.9419 2.68177C12.8247 2.56456 12.6658 2.49871 12.5 2.49871V2.49871ZM12.5 -0.00129131C8.47891 -0.00129131 5.62031 3.26238 5.625 6.88269C5.62487 8.54403 6.22974 10.1486 7.32656 11.3964C8.32891 12.5378 9.29062 14.4007 9.375 14.9987L9.37734 17.9358C9.37744 18.0587 9.41402 18.1787 9.48242 18.2807L10.4395 19.7198C10.4964 19.8055 10.5737 19.8758 10.6644 19.9245C10.7551 19.9731 10.8564 19.9986 10.9594 19.9987H14.0395C14.1426 19.9988 14.2441 19.9734 14.3351 19.9247C14.426 19.8761 14.5034 19.8057 14.5605 19.7198L15.5176 18.28C15.5854 18.1776 15.6219 18.0578 15.6227 17.935L15.625 14.9987C15.7129 14.3846 16.6797 12.5303 17.6734 11.3964C18.5434 10.4028 19.1087 9.17963 19.3015 7.87318C19.4944 6.56673 19.3066 5.23238 18.7608 4.02985C18.215 2.82732 17.3342 1.80757 16.2238 1.09264C15.1135 0.377721 13.8206 -0.00207746 12.5 -0.00129131V-0.00129131ZM14.3727 17.7452L13.7047 18.7487H11.2937L10.6273 17.7452V17.4987H14.3738L14.3727 17.7452ZM14.375 16.2487H10.625L10.6227 14.9987H14.375V16.2487ZM16.7348 10.5725C16.1879 11.1956 15.316 12.4511 14.7594 13.7479H10.243C9.68516 12.4507 8.81328 11.1956 8.26641 10.5725C7.36971 9.5491 6.87599 8.2344 6.87734 6.87371C6.87031 3.8659 9.23594 1.24871 12.5 1.24871C15.602 1.24871 18.125 3.77176 18.125 6.87371C18.1249 8.23456 17.6305 9.54904 16.7336 10.5725H16.7348ZM3.75 6.87371C3.75 6.70795 3.68415 6.54898 3.56694 6.43177C3.44973 6.31456 3.29076 6.24871 3.125 6.24871H0.625C0.45924 6.24871 0.300269 6.31456 0.183058 6.43177C0.065848 6.54898 0 6.70795 0 6.87371C0 7.03947 0.065848 7.19844 0.183058 7.31565C0.300269 7.43286 0.45924 7.49871 0.625 7.49871H3.125C3.29076 7.49871 3.44973 7.43286 3.56694 7.31565C3.68415 7.19844 3.75 7.03947 3.75 6.87371ZM20.625 2.49871C20.7221 2.49849 20.8178 2.4759 20.9047 2.43269L23.4047 1.18269C23.5529 1.10852 23.6657 0.978483 23.718 0.821201C23.7704 0.66392 23.7582 0.492273 23.684 0.344021C23.6473 0.270614 23.5964 0.205161 23.5344 0.151397C23.4724 0.0976336 23.4004 0.0566132 23.3225 0.0306781C23.1652 -0.0217002 22.9936 -0.00945342 22.8453 0.0647243L20.3453 1.31472C20.2194 1.37771 20.1184 1.48136 20.0588 1.60889C19.9991 1.73643 19.9843 1.88037 20.0166 2.0174C20.049 2.15442 20.1267 2.2765 20.2371 2.36386C20.3475 2.45122 20.4842 2.49873 20.625 2.49871ZM24.375 6.24871H21.875C21.7092 6.24871 21.5503 6.31456 21.4331 6.43177C21.3158 6.54898 21.25 6.70795 21.25 6.87371C21.25 7.03947 21.3158 7.19844 21.4331 7.31565C21.5503 7.43286 21.7092 7.49871 21.875 7.49871H24.375C24.5408 7.49871 24.6997 7.43286 24.8169 7.31565C24.9342 7.19844 25 7.03947 25 6.87371C25 6.70795 24.9342 6.54898 24.8169 6.43177C24.6997 6.31456 24.5408 6.24871 24.375 6.24871ZM4.65469 1.31472L2.15469 0.0647243C2.08128 0.0279952 2.00136 0.00608435 1.91948 0.00024269C1.83761 -0.00559897 1.75539 0.004743 1.67751 0.0306781C1.52023 0.0830564 1.39019 0.195769 1.31602 0.344021C1.24184 0.492273 1.22959 0.66392 1.28197 0.821201C1.33435 0.978483 1.44706 1.10852 1.59531 1.18269L4.09531 2.43269C4.18223 2.4759 4.27794 2.49849 4.375 2.49871C4.5158 2.49873 4.65248 2.45122 4.7629 2.36386C4.87332 2.2765 4.951 2.15442 4.98337 2.0174C5.01574 1.88037 5.0009 1.73643 4.94124 1.60889C4.88158 1.48136 4.78061 1.37771 4.65469 1.31472ZM23.4047 12.5647L20.9047 11.3147C20.7564 11.2405 20.5847 11.2283 20.4274 11.2807C20.2701 11.3332 20.14 11.4459 20.0658 11.5942C19.9916 11.7425 19.9794 11.9142 20.0318 12.0715C20.0842 12.2289 20.197 12.3589 20.3453 12.4331L22.8453 13.6831C22.9936 13.7573 23.1653 13.7695 23.3226 13.7171C23.4799 13.6647 23.61 13.5519 23.6842 13.4036C23.7584 13.2553 23.7706 13.0836 23.7182 12.9263C23.6658 12.769 23.553 12.6389 23.4047 12.5647V12.5647ZM4.375 11.2487C4.27794 11.2489 4.18223 11.2715 4.09531 11.3147L1.59531 12.5647C1.44701 12.6389 1.33425 12.769 1.28183 12.9263C1.25588 13.0042 1.24552 13.0864 1.25135 13.1683C1.25719 13.2502 1.27909 13.3302 1.31582 13.4036C1.35255 13.477 1.40338 13.5425 1.46542 13.5963C1.52745 13.6501 1.59947 13.6911 1.67737 13.7171C1.83469 13.7695 2.00638 13.7573 2.15469 13.6831L4.65469 12.4331C4.78083 12.3702 4.88202 12.2666 4.94183 12.1389C5.00164 12.0113 5.01656 11.8672 4.98417 11.7301C4.95178 11.5929 4.87397 11.4707 4.76339 11.3833C4.65281 11.2959 4.51594 11.2485 4.375 11.2487V11.2487Z" /></svg></p>
        <p class="dark night"><svg class="night" width="20" viewBox="0 0 25 21" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M6.39614 3.72646C7.50591 1.56178 9.72622 0.00900831 12.4782 0.00114817C13.8006 -0.00388798 15.0965 0.375153 16.2101 1.09278C17.3237 1.8104 18.2079 2.83612 18.7564 4.04682C19.3049 5.25751 19.4945 6.60175 19.3024 7.91818C19.1103 9.23461 18.5447 10.4673 17.6735 11.4683C17.5227 11.6416 17.3516 11.859 17.1739 12.1069L9.47856 6.12184C9.65443 5.45016 10.046 4.85578 10.5924 4.43118C11.1387 4.00657 11.8093 3.77554 12.4997 3.77401C12.6654 3.77401 12.8244 3.70776 12.9416 3.58984C13.0588 3.47191 13.1247 3.31197 13.1247 3.1452C13.1247 2.97843 13.0588 2.81849 12.9416 2.70057C12.8244 2.58264 12.6654 2.51639 12.4997 2.51639C11.6212 2.5173 10.7634 2.78383 10.0374 3.28141C9.31146 3.77899 8.75092 4.48463 8.42856 5.30674L6.39614 3.72646ZM6.39614 10.0841C6.64968 10.5817 6.96225 11.0465 7.327 11.4683C7.97231 12.2091 8.98169 13.7568 9.36645 15.0624C9.36645 15.0726 9.36919 15.0828 9.37075 15.093H12.8372L6.39614 10.0841ZM9.37466 16.3502V17.8574C9.37584 18.1045 9.44934 18.3458 9.58599 18.5511L10.2536 19.5607C10.3675 19.7335 10.5221 19.8753 10.7037 19.9734C10.8852 20.0715 11.0881 20.1229 11.2942 20.1231H13.7047C13.9107 20.1231 14.1135 20.0718 14.2951 19.9739C14.4766 19.876 14.6313 19.7345 14.7454 19.5619L15.4129 18.5511C15.5492 18.3451 15.622 18.1033 15.6223 17.8558V17.2581L14.4528 16.3502H9.37466Z"/>
            <path class="night" d="M0.131556 1.2363L0.898352 0.243172C0.948738 0.177883 1.01142 0.123229 1.08282 0.0823368C1.15423 0.0414448 1.23294 0.0151171 1.31446 0.00486006C1.39598 -0.00539702 1.47872 0.000617709 1.55793 0.0225602C1.63714 0.0445026 1.71127 0.0819422 1.77609 0.132737L24.7585 18.0039C24.8894 18.1062 24.9745 18.2567 24.9952 18.4221C25.0158 18.5876 24.9703 18.7545 24.8687 18.8862L24.1015 19.8794C24.0511 19.9446 23.9884 19.9992 23.917 20.0401C23.8457 20.0809 23.767 20.1072 23.6855 20.1175C23.6041 20.1277 23.5214 20.1217 23.4422 20.0998C23.363 20.0779 23.2889 20.0405 23.2241 19.9898L0.241322 2.1186C0.110489 2.01624 0.0254259 1.86578 0.00484145 1.70032C-0.015743 1.53486 0.0298368 1.36795 0.131556 1.2363V1.2363Z"/>
            </svg></p>
        </div>
    </label>
</div>
          </li>
          <li>
            <a href="./">
              <div class="left">
                首页
              </div>  
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><g><rect x="83.534" y="40.929" width="3.997" height="20.071"/></g><path d="M16.466,41.931l33.548-25.123L92.81,48.877l2.396-3.198L50.015,11.814L4.794,45.679l2.396,3.199l5.279-3.954v42.763h75.062  V61h-3.997v22.69H64.598V54.068H35.402V83.69H16.466V41.931z M39.399,58.065h21.202V83.69H39.399V58.065z"/></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./archive.html">
              <div class="left">
                文章
              </div>
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="-3 3 64 64"><g><path d="M60.992,31.985c0-15.979-13-28.978-28.979-28.978c-15.994,0-29.006,12.999-29.006,28.978   c0,15.994,13.012,29.007,29.006,29.007v-2c-14.891,0-27.006-12.115-27.006-27.007c0-14.875,12.115-26.978,27.006-26.978   c14.876,0,26.979,12.103,26.979,26.978c0,8.945-4.479,17.329-11.804,22.338l0.874-10.062l-1.992-0.174l-1.135,13.071l13.042,1.136   l0.174-1.992l-9.183-0.799C56.443,50.079,60.992,41.321,60.992,31.985z"/><polygon points="33.014,12.682 31.014,12.682 31.014,32.398 39.811,41.224 41.227,39.812 33.014,31.572  "/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./tags.html">
              <div class="left">
                标签
              </div>
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><g><path d="M75.244,15.066c-2.59,0-5.027,1.012-6.857,2.843c-3.781,3.785-3.778,9.94,0.002,13.724    c1.831,1.833,4.266,2.843,6.857,2.843s5.026-1.01,6.861-2.843c3.781-3.785,3.781-9.943-0.002-13.724    C80.275,16.076,77.838,15.066,75.244,15.066z M78.766,28.252c-1.871,1.869-5.129,1.869-6.996,0c-1.929-1.931-1.931-5.069-0.002-7    c0.934-0.934,2.175-1.448,3.498-1.448c1.322,0,2.564,0.515,3.5,1.448C80.691,23.183,80.691,26.321,78.766,28.252z M94.632,41.027    l0.005-28.872c0-3.745-3.05-6.792-6.792-6.792L58.973,5.368l-1.237-0.004c-1.893,0-4.75,0-6.617,1.869L7.008,51.342    c-1.06,1.059-1.645,2.467-1.645,3.966s0.583,2.908,1.644,3.968l33.717,33.717c1.058,1.06,2.467,1.645,3.966,1.645    s2.908-0.585,3.968-1.645l44.106-44.111c1.893-1.886,1.88-4.604,1.869-7.227L94.632,41.027z M90.022,46.139L45.913,90.25    c-0.654,0.65-1.792,0.652-2.443,0L9.752,56.532c-0.328-0.327-0.507-0.762-0.507-1.225c0-0.462,0.18-0.894,0.507-1.221    L53.861,9.976c0.676-0.674,2.284-0.731,3.874-0.731l1.237,0.004l28.872-0.004c1.604,0,2.909,1.306,2.909,2.911l-0.005,28.872    l0.005,0.642C90.76,43.585,90.769,45.392,90.022,46.139z"/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./about.html">
              <div class="left">
                关于
              </div>
              <div class="right">
                <svg width='24px' aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 846.66 846.66"><g><path d="M351.26 453.22c-276.42,134.06 -224.86,336.22 -224.73,336.8 6.03,25.41 -32.58,34.56 -38.6,9.15 -0.15,-0.65 -55.78,-219.32 218.87,-367.66 -60.98,-39 -100.02,-106.82 -100.02,-182.56 0,-119.6 96.95,-216.55 216.55,-216.55 119.6,0 216.55,96.95 216.55,216.55 0,75.74 -39.04,143.56 -100.02,182.56 274.65,148.34 219.02,367.01 218.87,367.66 -6.02,25.41 -44.63,16.26 -38.6,-9.15 0.13,-0.58 51.69,-202.74 -224.73,-336.8 -22.55,7.96 -46.8,12.29 -72.07,12.29 -25.27,0 -49.52,-4.33 -72.07,-12.29zm72.07 -381.14c-97.68,0 -176.87,79.19 -176.87,176.87 0,97.69 79.19,176.87 176.87,176.87 97.68,0 176.87,-79.18 176.87,-176.87 0,-97.68 -79.19,-176.87 -176.87,-176.87z"/></g></svg>
              </div>
            </a>
          </li>
          <!-- <li>
            <a href="./feed.xml">
              <div class="left">
                Atom feed
              </div>
              <div class="right">
                <svg width='24px' aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M80 352c26.467 0 48 21.533 48 48s-21.533 48-48 48-48-21.533-48-48 21.533-48 48-48m0-32c-44.183 0-80 35.817-80 80s35.817 80 80 80 80-35.817 80-80-35.817-80-80-80zm367.996 147.615c-6.448-237.848-198.06-429.164-435.61-435.61C5.609 31.821 0 37.229 0 44.007v8.006c0 6.482 5.146 11.816 11.626 11.994 220.81 6.05 398.319 183.913 404.367 404.367.178 6.48 5.512 11.626 11.994 11.626h8.007c6.778 0 12.185-5.609 12.002-12.385zm-144.245-.05c-6.347-158.132-133.207-284.97-291.316-291.316C5.643 175.976 0 181.45 0 188.247v8.005c0 6.459 5.114 11.72 11.567 11.989 141.134 5.891 254.301 119.079 260.192 260.192.269 6.453 5.531 11.567 11.989 11.567h8.005c6.798 0 12.271-5.643 11.998-12.435z"></path></svg>
              </div>
            </a>
          </li> -->
        </ul>
      </nav>
      
      
      <div class="logo"><a href="./"><img class="logo" id="logo" src="./assets/img/branding/MVM-logo-full.svg" alt="凡人炼丹传"></a></div>
      <div class="search-icon-container">
        <span class="search-icon"><a><i class="fa fa-search" aria-hidden="true"></i></a></span>
      </div>
    </div>
  </div>
</header> <!-- End Header -->

  <div class="content wrapper">
    






	
	<div id="CV" class="hidden tag-master">
		<h1>CV</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html">Jetson Xavier NX 的使用记录</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-08-25T05:11:00+08:00">August 25, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-远程桌面">一. 远程桌面</h3> <blockquote> <p>在windows10远程上操作jetson Xavier，远程的前提：jetson xavier和Windows的PC在同一个局域网内（我这里是直接在windows10上开启热点）。</p> </blockquote> <ul> <li>安装xrdp：<code class="language-plaintext highlighter-rouge">sudo apt-get install xrdp vnc4server xbase-clients</code></li> </ul> <h4 id="11桌面共享没反应">1.1：桌面共享没反应</h4> <blockquote> <p>桌面共享其实就是一个vnc-server（因此没有必要再在linux上安装vnc-server了），如果要远程，必须要先开启共享，允许其他人控制自己电脑。</p> </blockquote> <p>这里发现<strong>双击了桌面共享，没反应</strong>。</p> <p><strong>解决方案</strong>：</p> <ul> <li>安装dconf-editor：<code class="language-plaintext highlighter-rouge">sudo apt-get install dconf-editor</code></li> <li>运行dconf-editor，更改系统配置，org ==&gt; gnome ==&gt; desktop ==&gt; remote-access，关闭以下两个：<code class="language-plaintext highlighter-rouge">promotion-enabled</code>和<code class="language-plaintext highlighter-rouge">requre-encryption</code></li> <li>开启桌面共享：<code class="language-plaintext highlighter-rouge">/usr/lib/vino/vino-server</code></li> </ul> <h4 id="12-开启远程">1.2 开启远程</h4>...<a class="read-more" href="./JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html">ZED2相机api使用心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-08-25T05:11:00+08:00">August 25, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-zed相机的选型">一. ZED相机的选型</h3> <blockquote> <p>STEREOLABS（ZED相机厂家）的官网：https://www.stereolabs.com/zed/</p> </blockquote> <p>ZED双目相机有以下四种型号：</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_1.png" alt="" /></p> <p><a href="https://www.stereolabs.com/zed-2i/">ZED 2i</a>：ZED相机最新款（ZED相机二代的进阶版，<strong>防尘防水</strong>）</p> <p><a href="https://www.stereolabs.com/zed-2i/">ZED 2</a> ：ZED相机二代（相较于1代多了<strong>支持IMU</strong>）</p> <p><a href="https://www.stereolabs.com/zed-mini/">ZED mini</a>：功能上和二代基本一致，<strong>尺寸更小</strong>，<strong>性能上要差</strong>，比如这里支持的景深在15m以内，而二代的景深最大支持20m。</p> <p><a href="https://www.stereolabs.com/zed/">ZED</a>：ZED相机一代，支持2K视频，景深范围在(0.3m,25m)，<strong>无IMU</strong>,所以对于需要玩SLAM的这款就不推荐了。</p> <h3 id="二-安装zed的sdk">二. 安装ZED的SDK</h3> <h4 id="21-安装sdk">2.1 安装SDK</h4> <blockquote> <p>ZED相机SDK官网：https://www.stereolabs.com/developers/release/</p> </blockquote> <p>我们可以看到是，所有的SDK基本都需要你<strong>安装cuda</strong>，因此我选择了cuda11.0进行安装，具体的cuda安装过程可参考我之前的一篇博客：<a href="https://www.lixiaofei2yy.website/windows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BAcuda10.1%E5%92%8Cpytorch1.6">Windows10环境下搭建CUDA10.1和pytorch1.6</a>。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_2.png" alt="" /></p> <p>直接安装即可，将下载下来的exe双击运行<code class="language-plaintext highlighter-rouge">ZED_SDK_Windows10_cuda11.0_v3.5.2_4.exe</code>即可，如下图所示</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_3.png" alt="" /></p> <p>一直往下走即可。</p> <h4 id="22-安装python-api">2.2 安装python API</h4>...<a class="read-more" href="./ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html">Mask_RCNN在TF2下跑通自己的数据集</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-07-26T20:11:00+08:00">July 26, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>论文原文地址：https://arxiv.org/abs/1703.06870</p> <p>MaskRCNN官方的git地址：https://github.com/matterport/Mask_RCNN</p> </blockquote> <h3 id="一-构建数据集">一. 构建数据集</h3> <p>这里参考官方推荐的气球语义分割的<a href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46">例子</a>，这里选用的是和他一致的打标工具 <a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA (VGG Image Annotator)</a>。个人感觉这个比<a href="https://github.com/wkentaro/labelme">labeme</a>好用太多。</p> <ul> <li>直接在<a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA官网</a>下载即可，下载完成后如下图所示，直接用浏览器打开<code class="language-plaintext highlighter-rouge">via.html</code>即可开箱使用。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_1.png" alt="" /></p> <ul> <li>选择<code class="language-plaintext highlighter-rouge">Add Files</code>添加图片后，选择<code class="language-plaintext highlighter-rouge">Attributes</code>设置打标的label，然后用多边形工具进行打标，如下图。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_2.png" alt="" /></p> <ul> <li>输出json格式的打标结果</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_3.png" alt="" /></p> <ul> <li>将图片和json结果保存在同一个目录下，构建自己的数据集时可参考我的目录结构。</li> </ul> <div class="language-json highlighter-rouge"><div...<a class="read-more" href="./Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./orb_slam3.html">ORB-SLAM3在windows下的编译使用</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-05-12T10:11:00+08:00">May 12, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-数据集">一. 数据集</h3> <h4 id="11-数据集介绍">1.1 数据集介绍</h4> <p><a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets">Euroc</a>：基于室内的MAV(Micro Aerial Vehicle，微型飞行器)，一共两个场景（Machine Hall + Vicon Room）,其中每个数据集包含2个下载连接：</p> <ul> <li>ROS(Robot Operating System) bag：机器人操作库，适用于嵌入式，这里推荐一个很好的双目+IMU应用在jetson nano上的<a href="https://github.com/tau-adl/Position-Control-Using-ORBSLAM2-on-the-Jetson-Nano">git</a>。</li> <li>ASL Dataset Format：数据集结构，包含传感器文件和双目相机的图片。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/orb_1.jpg" alt="" /></p> <h4 id="12-数据使用介绍">1.2 数据使用介绍</h4> <p>可用的数据包含：</p> <ul> <li>Visual-Inertial Sensor Unit（视觉惯性传感器单元） <ul> <li>Stereo Images（双目图片）</li> <li>IMU（惯导数据）</li> </ul> </li> <li>Ground-Truth位姿轨迹 <ul> <li><strong>Vicon</strong> 6轴运动姿态捕捉系统</li> <li><strong>Leica MS50</strong> 3维姿态镭射追踪</li>...<a class="read-more" href="./orb_slam3.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_4.html">目标检测(one stage)-从FPN到DSSD</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-04-28T05:11:00+08:00">April 28, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-fpn特征金字塔网络">一. FPN特征金字塔网络</h3> <blockquote> <p>论文地址：https://arxiv.org/pdf/1612.03144.pdf</p> </blockquote> <p>这篇论文发布的时间是2017年4月19号，可以说在此之后，对于目标检测（小物体）而言，提升巨大，基本之后的模型比如DSSD，yolov3等都参考过该模型架构。</p> <h4 id="11-解决的问题">1.1 解决的问题</h4> <ul> <li>目标检测的基本挑战（问题）：识别多尺度变化的目标能力不足。这里解决了一下两个方面的难点： <ol> <li>相机距离目标远近不同导致拍摄的图片中目标尺寸不同而导致识别效率低下。</li> <li>小目标物体的识别较难。</li> </ol> </li> </ul> <h4 id="12-图像特征金字塔">1.2 图像特征金字塔</h4> <p>特征金字塔是在不同大小尺寸的目标检测中的一个基础组件。</p> <ul> <li>如下图所示，经过多次特征抽取后，越到高层的feature map所囊括的细节信息就越少，对于底层信息（比如小的目标）预测就越难。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_1.jpg" alt="" /></p> <ul> <li>那么图像特征金字塔做了什么呢？既对同一张图片进行多次下采样，从而得到多张不同尺寸的图片，进而生成不同尺寸的feature map，从而使模型拥有对不同尺度大小的物体进行检测的能力。但是论文中也提出它的问题：<strong>消耗太大的内存和计算量</strong>。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_2.jpg" alt="" /></p> <ul> <li> <p>看到上面这张图的时候，你是不是觉得很熟悉？和某个网络的推理层很像？是的，就是SSD。SSD和YOLOv1最大的差别（之前的文章中有讲，有兴趣可以查看本人之前的文章）其实是推理层的不同，SSD用的就是多尺度的特征图综合来预测目标，从而达到对于小物体也能够检测的目的。</p> </li> <li> <p>如下图所示，是不是感觉和上面的图像特征金字塔很像？差别还是有的，SSD是对同一张图片进行卷积抽取其不同尺度的feature map进行分别做预测，而特征金字塔是对不同尺度的图片分别做特征抽取得到不同尺度的feature map在分别做预测。这里论文中也提到SSD的<strong>缺点</strong>：<strong>失去了高层语义信息重用的机会，导致低层语义信息不足</strong>。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_4_3.jpg" alt="" /></p>...<a class="read-more" href="./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_4.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_3.html">目标检测(one stage)-YOLOv2</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-04-21T04:21:00+08:00">April 21, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-与v1的不同之处">一. 与V1的不同之处</h3> <p>YOLOv2相较于YOLOv1在VOC2007数据集上表现从63.4%提升到78.6%。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_1.jpg" alt="" /></p> <p>YOLOv2与YOLOv1的不同之处一共体现在下面几个方面：</p> <ul> <li> <p><strong>Batch Normalization</strong>（批归一化层）：在模型不过拟合的前提下，可以拿掉Dropout层；同时加速模型训练。在VOC2007数据集上效果<strong>mAP提升2.4%</strong>。</p> </li> <li> <p><strong>High Resolution Classifier</strong>（提高分辨率）:原本YOLOv1中模型训练的使用的是224 * 224分辨率的图像，现在resize成448 * 448的图片，最后经过10个epoch的微调。在VOC2007数据集上效果<strong>mAP提升3.7%</strong>。</p> </li> <li> <p><strong>Convolutional With Anchor Boxes</strong>（提高检测目标数量）：原本yolov1中将其中一个pool层拿掉后， feature map的大小由7 * 7 变成了13 * 13，然后每个1 * 1的grid里面增加了K个anchor boxes，因此从yolov1只能检测7 * 7 = 49个目标，增加到了13 * 13 * K个目标。在VOC2007数据集上效果<strong>虽然mAP下降了0.3%，但是在Recall上提升了7%</strong>。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/mu_3_2.jpg" alt="" /></p>...<a class="read-more" href="./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_3.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="LLM" class="hidden tag-master">
		<h1>LLM</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul>...<a class="read-more" href="./raft.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused...<a class="read-more" href="./graphrag.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./langchain.html">LLM的应用开发框架——Langchain</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-07-04T08:00:00+08:00">July 4, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-langchain是什么">一. Langchain是什么</h3> <blockquote> <p>Langchain 官网文档：https://python.langchain.com/v0.2/docs/introduction/</p> </blockquote> <h4 id="llm崛起出现了哪些需求">LLM崛起出现了哪些需求？</h4> <ul> <li> <p>格式化输出：希望给的输出格式是json、csv、db格式</p> </li> <li> <p>输出很长的提示词文本：如何总结一本书的内容？</p> </li> <li> <p>多次API调用：两次调用api，前后两次需要结合的</p> </li> <li> <p>外部调用：比如需要进行web 搜索</p> </li> <li> <p>标准化开发</p> </li> <li> <p>快速切换模型：有多个大模型可用，支持代码不变，快速切换</p> </li> </ul> <h3 id="二-langchain支撑llm的应用">二. Langchain支撑LLM的应用</h3> <h4 id="21-支持多种llm">2.1 支持多种LLM</h4> <p>无论是国外的GPT4、LLaMa，还是国内的ChatGLM、Baichuan，都支持调用api和huggingface模型的使用，下面主要介绍HF模型的下载使用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">huggingface_hub</span> <span class="kn">import</span> <span class="n">snapshot_download</span> <span...<a class="read-more" href="./langchain.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8.html">大语言模型的应用及训练</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-07-18T23:00:00+08:00">July 18, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大语言模型llm">一. 大语言模型LLM</h3> <h4 id="11-llm的发展史">1.1 LLM的发展史</h4> <p>LLM(Large Language Model大语言模型)的发展起源应该是从Transformer开始，在chatGPT出现后热度达到顶峰。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/LLM%E5%8F%91%E5%B1%95%E5%8F%B2.png" alt="" /></p> <p>整个发展的过程可以概括为三个阶段：</p> <ul> <li> <p>第一阶段：真对某些领域数据单独微调，出现大量的预训练模型</p> </li> <li> <p>第二阶段：扩大模型参数及训练语料的规模，模型架构偏向于生成式模型，Prompt在微调阶段开始展现。</p> </li> <li> <p>第三阶段：模型参数和数据的规模急剧扩大，注重模型和人之间的交互。AI的安全性、可靠性更加收到关注。</p> </li> </ul> <h4 id="12-开源可用的中文llm">1.2 开源可用的中文LLM</h4> <p>目前公认较好的中文开源大语言模型如下：</p> <ul> <li> <p>Meta AI发布的Llama系列模型，目前已经到Llama2了，推荐一个中文的<a href="https://github.com/FlagAlpha/Llama2-Chinese">Llama2仓库</a></p> </li> <li> <p>清华大学的chatGLM系列模型，目前已经到chatGLM2了，推荐官方的<a href="https://github.com/THUDM/ChatGLM2-6B">chatGLM2仓库</a></p> </li> </ul> <h4 id="13-llm应用的nlp任务">1.3 LLM应用的NLP任务</h4> <p>现在LLM基本都是生成式模型，因此一般可应用的NLP任务：</p> <ul> <li> <p>翻译</p> </li> <li> <p>文本摘要</p>...<a class="read-more" href="./%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="NLP" class="hidden tag-master">
		<h1>NLP</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul>...<a class="read-more" href="./raft.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused...<a class="read-more" href="./graphrag.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html">知识图谱的小结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-12-25T08:00:00+08:00">December 25, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-定义">一. 定义</h3> <p>知识图谱是一种二元的图网络，用以描述客观世界中的实体信息及其相互关系规律的知识化体系。它的基本组成单元包括：</p> <ul> <li>实体-关系-实体</li> <li>实体-属性-属性值</li> </ul> <h3 id="二-知识图谱的构建">二. 知识图谱的构建</h3> <h4 id="21-知识建模">2.1 知识建模</h4> <p>对于构建知识图谱的时候，一般我们都是针对所在的特定领域进行建模，所以一般称为“本体建模”或者“领域建模”。</p> <p>这里构建本体模型一般分为3类技术：</p> <ul> <li>RDF：Resource Description Framework，即资源描述框架。采用“资源-属性-属性值”的“主谓宾”结构（或称三元组），提供一种框架容器，并通过XML定义了一套形式化的方法，为机器语义理解的结构基础。</li> <li>RDFS：RDFS是RDF的一个扩展，它提供了一些基本的类和属性，以及它们之间的关系。</li> <li>OWL：Web Ontology Language，Web本体语言，它是基于RDF和RDFS的一种更加丰富的知识表示语言。在OWL中，我们可以定义类、属性以及它们的约束和关系。此外，OWL还支持对知识的推理。</li> </ul> <h4 id="22-知识获取">2.2 知识获取</h4> <p>构建好需要的本体模型后，那么就需要把数据构建成对应的模型的输入了。我们知识的来源基本分为以下几类：</p> <ul> <li>私有数据 <ul> <li>企业的文档</li> <li>企业私有的用户数据</li> <li>企业私有的非结构化数据</li> </ul> </li> <li>公有数据 <ul> <li>新闻</li> <li>百科</li> <li>公有语料</li> </ul> </li> </ul> <p>那么对于一些上述这些数据拆分为两大类，来进行<strong>数据处理</strong>：</p> <ul> <li>非结构化数据：一般指的是无任何标识的文本，我们可以采用相关的NLP算法，比如实体识别和关系抽取（或者直接使用事件抽取，这里事件抽取可以参考我之前写的一篇博客）来构建实体关系的三元组。</li> <li>结构化数据：由于本身就是标准化的数据，我们只需要通过D2R服务器将数据库的内容转成RDF的形式。</li> </ul>...<a class="read-more" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./langchain.html">LLM的应用开发框架——Langchain</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-07-04T08:00:00+08:00">July 4, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-langchain是什么">一. Langchain是什么</h3> <blockquote> <p>Langchain 官网文档：https://python.langchain.com/v0.2/docs/introduction/</p> </blockquote> <h4 id="llm崛起出现了哪些需求">LLM崛起出现了哪些需求？</h4> <ul> <li> <p>格式化输出：希望给的输出格式是json、csv、db格式</p> </li> <li> <p>输出很长的提示词文本：如何总结一本书的内容？</p> </li> <li> <p>多次API调用：两次调用api，前后两次需要结合的</p> </li> <li> <p>外部调用：比如需要进行web 搜索</p> </li> <li> <p>标准化开发</p> </li> <li> <p>快速切换模型：有多个大模型可用，支持代码不变，快速切换</p> </li> </ul> <h3 id="二-langchain支撑llm的应用">二. Langchain支撑LLM的应用</h3> <h4 id="21-支持多种llm">2.1 支持多种LLM</h4> <p>无论是国外的GPT4、LLaMa，还是国内的ChatGLM、Baichuan，都支持调用api和huggingface模型的使用，下面主要介绍HF模型的下载使用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">huggingface_hub</span> <span class="kn">import</span> <span class="n">snapshot_download</span> <span...<a class="read-more" href="./langchain.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.html">分布式训练推理Accelerate</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-08-16T23:00:00+08:00">August 16, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>分布式训练的加速策略详情可见本人上篇文章《 <a href="https://www.lixiaofei2yy.website/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8">大语言模型的应用及训练</a>》，一般有三种，分别是数据并行，流水线式并行和张量并行，本文主推使用hugging face的accelerate库来进行模型分布式的训练和推理。</p> </blockquote> <h3 id="一-torch常用的分布式训练工具">一. torch常用的分布式训练工具</h3> <h4 id="11-dataparallel">1.1 DataParallel</h4> <p>DP(DataParallel)：实现数据并行方式的分布式训练，采用的是PS(worker-server)模式，<strong>不推荐</strong>。</p> <ul> <li>单进程多线程</li> <li>只能在单机上使用</li> <li>训练速度慢，且由于是<strong>PS模式（存在负载不均衡的问题）</strong>，随着worker的个数增多，训练速度越慢</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/dp111.png" alt="" /></p> <h4 id="12-distributeddataparallel">1.2 DistributedDataParallel</h4> <p>DDP(DistributedDataParallel)：实现数据并行方式的分布式训练，采用的是ring-all-reduce模式。它将<strong>模型复制到每个 GPU 上 ，同时复制了每个dataloader</strong>，并且当 <code class="language-plaintext highlighter-rouge">loss.backward()</code> 被调用进行反向传播的时候，所有这些模型副本的梯度将被同步地平均/下降 (reduce)。这确保每个设备在执行优化器步骤后具有相同的权重。</p> <ul> <li> <p>多进程</p> </li> <li> <p>支持多机多卡</p> </li> <li> <p>训练速度较DP快，ring-all-reduce模式下，所有worker只和自己相邻的两个worker进行通信</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/ddp.png" alt="" /></p> </li> </ul> <h4 id="13-amp">1.3 amp</h4>...<a class="read-more" href="./%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="代码" class="hidden tag-master">
		<h1>代码</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./taskflow.html">Taskflow 使用小结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-04-07T08:00:00+08:00">April 7, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-taskflow的优势和完整的工作流">一. TaskFlow的优势和完整的工作流</h3> <p>TaskFlow是OpenStack开源的Python库，他的优势：</p> <ul> <li>可伸缩</li> <li>简单创建任务级对象</li> <li>任务可插拔</li> <li>支持回滚容错机制</li> </ul> <p>api的文档参考：https://docs.openstack.org/taskflow/ocata/</p> <p>一个完整的taskflow包含了一下几个环节：</p> <ul> <li>创建task</li> <li>声明flow</li> <li>构建engine</li> </ul> <h4 id="11-构建task">1.1 构建task</h4> <p>构建task的方式是继承task类，然后修改其excute方法，这里可以指定任务的返回结果为res，注意还可以改写revert函数来重定义回滚的操作。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">task</span> <span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span> <span class="n">default_provides</span> <span class="o">=</span> <span class="sh">'</span><span class="s">res</span><span class="sh">'</span>...<a class="read-more" href="./taskflow.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html">pyspark使用总结-第二篇</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-07T08:00:00+08:00">November 7, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-常见的oom">一. 常见的OOM</h3> <h4 id="11-常用的解决方案">1.1 常用的解决方案</h4> <p>我们在使用spark的时候，经常在save数据的时候，都会遇到内存溢出的问题，这通常是由于数据量过大导致的。以下是一些可能的解决方案：</p> <ol> <li>增加分区数：如果数据集非常大，可以尝试增加分区数。可以使用<code class="language-plaintext highlighter-rouge">repartition()</code>或<code class="language-plaintext highlighter-rouge">coalesce()</code>函数来增加分区数。增加分区数可以将数据均匀地分布在更多的节点上，从而减少每个节点上的内存压力。</li> <li>压缩数据：如果数据集包含大量重复的值，可以考虑使用压缩算法来减少内存使用。Pyspark提供了多种压缩算法，如Snappy、Gzip等。可以使用<code class="language-plaintext highlighter-rouge">option("compression", "snappy")</code>来设置压缩算法。</li> <li>增加集群资源：可以考虑增加集群资源。可以增加集群的节点数或增加每个节点的内存。可以通过调整<code class="language-plaintext highlighter-rouge">spark.driver.memory</code>和<code class="language-plaintext highlighter-rouge">spark.executor.memory</code>参数来增加内存分配，特别对于driver而言，最好把内存设置大一些。</li> </ol> <h4 id="12-代码方面的优化">1.2 代码方面的优化</h4> <p>如果以上常用的解决方案依旧无法解决OOM的问题，那么我们可能需要考虑是否需要优化pyspark的代码了</p> <ul> <li>UDF过于复杂：尽可能将结果拆分不同的列，然后再用简单的udf来组合这些列进行计算。</li> <li>多用filter算子：提前将大量数据剔除</li> <li>多用select算子：只保留需要的列，减少内存的使用</li> <li>尽量少用collect、count算子：像这些action算子基本都会把executor的数据全部加载回driver上，导致driver的内存吃紧。</li> <li>当发现在某个udf环节只有一个节点在跑的时候，可以使用.cache()来分布式跑任务。</li> </ul> <h4 id="13-数据倾斜导致的oom和心跳时间超时">1.3 数据倾斜导致的OOM和心跳时间超时</h4> <p>通常我们会发现有些时候，数据本身并没有很大，但是要运行很长时间，而且最终还因为heart beat时间过长或则oom而失败。</p> <p><strong>发生</strong> 数据倾斜一般发生在：</p> <ul> <li>join两个df的时候</li> <li>groupby某一列，然后这一列（包含了a，b，c等元素）中，很不巧，a有非常多（1000），而b和c等元素仅有2个</li> </ul> <p><strong>验证</strong> 这时候我们可以直接通过yarn日志中的shuffer resize/records看到很多excutors中会发现极个别失败的excutor的size非常大（10w个），而其他的excutor的size可能只有10个。那么这个时候无疑是发生数据倾斜了。</p> <p><strong>解决</strong> 这里推荐使用<strong>加盐</strong>处理，比什么加excutor的内存和核数更加有效</p>...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html">配置python远程环境</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-12-28T08:00:00+08:00">December 28, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>由于工作基本基于python，所以本文主要记录配置远程linux的python环境</p> </blockquote> <h3 id="一-定义docker位置">一. 定义Docker位置</h3> <blockquote> <p>为什么要修改docker存储的位置？ 因为往往docker的缓存过大，导致最后打的镜像多了，最后占满空间了</p> </blockquote> <p>步骤：</p> <ul> <li>获取当前docker所在存储位置：<code class="language-plaintext highlighter-rouge">docker info | grep "Docker Root Dir"</code></li> <li>停止docker服务：<code class="language-plaintext highlighter-rouge">systemctl stop docker</code></li> <li>移动整个路径至新路径：<code class="language-plaintext highlighter-rouge">mv /var/lib/docker /data/docker</code></li> <li>创建软连接：<code class="language-plaintext highlighter-rouge">ln -s /data/docker /var/lib/docker</code></li> <li>重启docker服务：<code class="language-plaintext highlighter-rouge">systemctl start docker</code></li> <li>可以通过第一个命令查看现在的docker存储路径</li> </ul> <h3 id="二-安装python3或则conda">二. 安装python3或则conda</h3> <blockquote> <p>这里推荐安装conda，环境切换方便</p> </blockquote>...<a class="read-more" href="./%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html">pyspark使用心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-12-27T08:00:00+08:00">December 27, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-安装">一. 安装</h3> <blockquote> <p>要使用PySpark，本地要有Java开发环境。</p> </blockquote> <ul> <li> <p>Java 8 : <code class="language-plaintext highlighter-rouge">brew install --cask homebrew/cask-versions/adoptopenjdk8</code></p> </li> <li> <p>pyspark安装：<code class="language-plaintext highlighter-rouge">pip install pyspark</code></p> </li> </ul> <h3 id="二-和pandas之间的代码使用">二. 和pandas之间的代码使用</h3> <h4 id="21-读取csv">2.1 读取csv</h4> <blockquote> <p>spark在读取csv上优势就很明显了，能直接快速读取几个G的大文件</p> </blockquote> <p>pandas读取大的csv，只能将其拆分为多个chunk进行读取，假如我们直接读取csv，可能会直接报内存不够导致进程被干掉。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="n">df</span>...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./docker%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html">docker使用总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-01-10T08:00:00+08:00">January 10, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-定义">一. 定义</h3> <p>Docker的特点：</p> <ul> <li>是一个工具，能快速方便的创建、运行、部署软件。</li> <li>能将一个软件及其依赖打包成一个单独的库，方便移植。</li> <li>能解决不同application之间版本不兼容的问题（比如一个是python2环境，一个是python3环境）</li> <li>相较于虚拟机更为轻量，占用资源少，资源利用率高，运行速度快。</li> </ul> <p>Docker的应用：</p> <ul> <li>提供一次性的环境</li> <li>可组建微服务架构，大程序更方便扩容、稳定。</li> </ul> <h3 id="二-docker使用流程">二. docker使用流程</h3> <h4 id="21-docker的流程">2.1 docker的流程</h4> <p>整个docker的使用流程基本是：编写docker file ==&gt; 创建image(镜像) ==&gt; 实例化为container(容器) ==&gt; 跑container。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/docker_1.png" alt="" /></p> <h4 id="22-拉取使用的例子">2.2 拉取使用的例子</h4> <blockquote> <p>这里用的是doccano这个NLP文本标注工具作为例子，记录下docker在使用该镜像时遇到的问题和总结。</p> </blockquote> <p>使用过程常用的命令：</p> <ol> <li>拉取官方的一个doccano镜像：<code class="language-plaintext highlighter-rouge">docker pull doccano/doccano</code></li> <li>查看本地镜像列表：<code class="language-plaintext highlighter-rouge">docker image...<a class="read-more" href="./docker%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html">Selenium和webscraper爬虫</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-12-24T08:00:00+08:00">December 24, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-selenium爬虫">一. Selenium爬虫</h3> <h4 id="1-安装">1. 安装</h4> <blockquote> <p>Selenium 本身是一个自动化测试的工具，模拟人为在浏览器上进行操作，比如点击和下拉等等。</p> </blockquote> <p>安装的环境：</p> <ul> <li>python环境</li> <li>pip安装Selenium包：<code class="language-plaintext highlighter-rouge">pip install selenium</code></li> <li>chrome浏览器驱动：去<a href="https://chromedriver.chromium.org/downloads">官网</a>下载自己电脑已安装的浏览器所在的版本驱动</li> </ul> <p>我这边的chrome驱动装的是mac版本的，这里需要将其路径放到mac的环境变量中，下载后放到了<code class="language-plaintext highlighter-rouge">/usr/local/chromedriver</code>，</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim ~/.profile export PATH="$PATH:/usr/local/chromedriver" source ~/.profile </code></pre></div></div> <p>可以在控制台打<code class="language-plaintext highlighter-rouge">chromedriver</code>测试是否ok。</p> <h4 id="2-使用">2. 使用</h4> <blockquote> <p>这里的例子是的主要任务是：将给的头条url所在的公众号遍历其30条的文章标题和链接。</p> </blockquote> <p>所以我们需要拆解为2步：</p> <ul> <li>打开给定的url，并点击头条的公众号。</li> <li>另开一个页面，找到公众号下前30条文章的标题和链接（这里需要下拉才能看到后面的文章）。</li> </ul> <p>第一步：实例一个浏览器驱动，并找到公众号的XPath（这里推荐一个测试XPath的<strong>浏览器插件XPath...<a class="read-more" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="博客" class="hidden tag-master">
		<h1>博客</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./picgo%E4%B8%8B%E9%85%8D%E7%BD%AEgithub%E5%9B%BE%E5%BA%8A.html">picgo下配置github图床</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-01-20T19:11:00+08:00">January 20, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-必须的安装">一. 必须的安装</h3> <ul> <li>picgo：强大的能快速创建图片url的工具（支持多种图床），简直不要太好用。我们可以直接在官网下载相应版本的<a href="https://picgo.github.io/PicGo-Doc/zh/guide/#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85">picgo</a>，我这里选用的是windows版本的，当然也有mac版本的。</li> <li>git：这里推荐用scoop进行安装<code class="language-plaintext highlighter-rouge">scoop install git</code></li> </ul> <h3 id="二-搭建属于自己的github图床">二. 搭建属于自己的github图床</h3> <h4 id="21-新建一个共有仓库">2.1 新建一个共有仓库</h4> <p>首先，要搭建一个github图床，我们需要创建一个<strong>共有仓库</strong>（注意：如果是创建私有仓库根本无法显示图片出来）来存储上传的图片。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/new-rep.jpg" alt="" /></p> <h4 id="22-创建admin分支">2.2 创建admin分支</h4> <p>这里如果不会用git创建分支的同学可参考我上一篇文章<a href="https://www.lixiaofei2yy.website/git%E5%91%BD%E4%BB%A4">GIT命令学习</a>。</p> <p>这里注意最好选择帮你添加一个README.md文件。</p> <ul> <li>克隆刚创建的远程仓库：<code class="language-plaintext highlighter-rouge">git clone XX.git</code></li> <li>创建并切换到admin分支：<code class="language-plaintext highlighter-rouge">git checkout -b admin</code></li> <li>向远端仓库推送admin分支：<code class="language-plaintext highlighter-rouge">git push orgin admin</code></li> </ul> <p>这时，我们就可以在仓库中看到admin分支了，如下图。 <img...<a class="read-more" href="./picgo%E4%B8%8B%E9%85%8D%E7%BD%AEgithub%E5%9B%BE%E5%BA%8A.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Jasper2%E5%8D%9A%E5%AE%A2%E8%B7%9F%E6%96%B0.html">利用Jasper2主题和Netlify完善个人博客</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-11-27T04:21:00+08:00">November 27, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-更换jekyll主题">一. 更换Jekyll主题</h3> <ul> <li>之前用的是jekyll主题：<a href="https://github.com/artemsheludko/flexible-jekyll">Flexible-Jekyll</a>，如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jaster_1.jpg" alt="" /></p> <ul> <li>觉得有点过于单调和简单了，于是找到了命中注定：<a href="https://github.com/jekyller/jasper2">Jasper2</a>,如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jaster_2.jpg" alt="" /></p> <blockquote> <p>如果也想使用这个Jasper2主题的话，最好多读读其作者的readme哦！</p> </blockquote> <h4 id="11-在git仓库中推送生成好的html文件">1.1 在git仓库中推送生成好的html文件</h4> <p>​ 克隆Jasper2项目（master分支）到自己本地，然后利用jekyll开启本地预览模式：<code class="language-plaintext highlighter-rouge">bundle exec jekyll server</code>，这里你会发现在本地的上级目录下生成一个<code class="language-plaintext highlighter-rouge">jasper2-pages</code>文件夹。</p> <ul> <li>如果是和我一样是利用<code class="language-plaintext highlighter-rouge">username.github.io</code>建立的仓库，那么就直接在项目中新建一个<code class="language-plaintext highlighter-rouge">_site</code>文件夹，并将<code class="language-plaintext highlighter-rouge">jasper2-pages</code>内容复制到该目录下即可。</li> <li>如果是利用<code class="language-plaintext highlighter-rouge">github pages</code>来展示自己的项目的话，那就建立一个<code class="language-plaintext highlighter-rouge">gh-pages </code>分支，同时将<code class="language-plaintext...<a class="read-more" href="./Jasper2%E5%8D%9A%E5%AE%A2%E8%B7%9F%E6%96%B0.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Mac%E4%B8%8B%E5%88%A9%E7%94%A8jekyll%E5%92%8Cgithub-pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html">jekyll和github pages搭建个人博客</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-10-18T03:21:00+08:00">October 18, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-搭建环境">一. 搭建环境</h3> <h4 id="11-下载软件">1.1 下载软件</h4> <ul> <li><a href="https://www.jekyll.com.cn/">jekyll</a>：这个是将纯文本转化为静态网站和博客，使用gem安装下载：<code class="language-plaintext highlighter-rouge">gem install bundler jekyll</code>。</li> <li><a href="">github pages</a>：免费开源，并且可以自动生成域名，自己去构建一个属于自己的github账号和新建一个仓库（名字为：<code class="language-plaintext highlighter-rouge">XX.github.io</code>，这里<code class="language-plaintext highlighter-rouge">XX</code>就是你自己的账号名称）</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jek_1.jpg" alt="" /></p> <ul> <li>mac或者linux或者Windows平台。</li> </ul> <h4 id="12-选择一个适合自己的博客主题">1.2 选择一个适合自己的博客主题</h4> <blockquote> <p>jekyll主题：http://jekyllthemes.org/</p> <p>jekyll插件：http://www.jekyll-plugins.com/</p> </blockquote> <ul> <li>本人选择的jekyll主题：<a href="https://github.com/artemsheludko/flexible-jekyll">Flexible-Jekyll</a>，如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jek_2.jpg" alt="" /></p> <ul> <li>选择一个地方存放下载的主题（直接git下载）：<code class="language-plaintext highlighter-rouge">git clone https://github.com/artemsheludko/flexible-jekyll...<a class="read-more" href="./Mac%E4%B8%8B%E5%88%A9%E7%94%A8jekyll%E5%92%8Cgithub-pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="图算法" class="hidden tag-master">
		<h1>图算法</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.html">GCN在多标签分类中的应用</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-01-11T04:21:00+08:00">January 11, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一--torch的图神经网络库pyg">一. Torch的图神经网络库pyG</h3> <blockquote> <p>torch_geometric 官方文档：https://pytorch-geometric.readthedocs.io/en/latest/index.html</p> </blockquote> <h4 id="11-安装及使用">1.1 安装及使用</h4> <p>这里参考官网的安装过程。</p> <ol> <li> <p>确定自己安装的pytorch版本：<code class="language-plaintext highlighter-rouge">pip list</code>进行查看，例如本人的torch版本为<code class="language-plaintext highlighter-rouge">1.6.0+cu101</code>（这里的<code class="language-plaintext highlighter-rouge">cu101</code>是指cuda10.1）</p> </li> <li> <p>安装相关的第三方包，这里注意要匹配上面的torch版本，因此：<code class="language-plaintext highlighter-rouge">${TORCH} = 1.6.0</code>，<code class="language-plaintext highlighter-rouge">${CUDA} = cu101</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--no-index</span> torch-scatter <span class="nt">-f</span> https://pytorch-geometric.com/whl/torch-<span class="k">${</span><span class="nv">TORCH</span><span class="k">}</span>+<span class="k">${</span><span class="nv">CUDA</span><span...<a class="read-more" href="./GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Neo4j%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%9B%BE%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E7%BB%93%E5%90%88.html">Neo4j数据库与图数据挖掘算法结合</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-02-27T23:21:00+08:00">February 27, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-环境准备">一. 环境准备</h3> <ul> <li> <p>neo4j python包：<code class="language-plaintext highlighter-rouge">pip3 install neo4j</code> 和<code class="language-plaintext highlighter-rouge">pip3 install py2neo</code>（这里的py2neo 是python对Neo4j的驱动库,同时这里必须是py2neo版本必须是最新版4，不然会报连接数据库的错误，老版本不兼容的问题）</p> </li> <li> <p>Java8：这里由于neo4j 数据库是依赖于java8的。</p> </li> <li> <p><a href="[ftp://neo4j.55555.io/neo4j-chs/3.5.14/](ftp://neo4j.55555.io/neo4j-chs/3.5.14/)">Neo4j_3.5.14</a>：这里由于neo4j 在中国地区下载慢，并且neo4j3.X版本才支持java8，到4.0版本就是需要java11了。</p> </li> <li> <p><a href="[ftp://neo4j.55555.io/neo4j-desktop/1.2.4/](ftp://neo4j.55555.io/neo4j-desktop/1.2.4/)">Neo4j_Desktop</a>：neo4j的桌面端（可以远程数据库和连接本地数据库，同时包含很多额外的扩展）</p> </li> </ul> <h3 id="二-连接本地图数据库">二. 连接本地图数据库</h3> <blockquote> <p>py2neo V4 官方文档：https://py2neo.org/v4/index.html</p> </blockquote> <p>Neo4j 一共有3种连接方式：</p> <ul> <li>Bolt：bolt://localhost:11005</li> <li>HTTP：http://localhost:11006</li> <li>HTTPS：https://localhost:11007</li> </ul> <p>这里可以通过Neo4j Desktop来查看新建的图数据库（同时设置密码）</p> <h4...<a class="read-more" href="./Neo4j%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%9B%BE%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E7%BB%93%E5%90%88.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="机器学习" class="hidden tag-master">
		<h1>机器学习</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html">知识图谱的小结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-12-25T08:00:00+08:00">December 25, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-定义">一. 定义</h3> <p>知识图谱是一种二元的图网络，用以描述客观世界中的实体信息及其相互关系规律的知识化体系。它的基本组成单元包括：</p> <ul> <li>实体-关系-实体</li> <li>实体-属性-属性值</li> </ul> <h3 id="二-知识图谱的构建">二. 知识图谱的构建</h3> <h4 id="21-知识建模">2.1 知识建模</h4> <p>对于构建知识图谱的时候，一般我们都是针对所在的特定领域进行建模，所以一般称为“本体建模”或者“领域建模”。</p> <p>这里构建本体模型一般分为3类技术：</p> <ul> <li>RDF：Resource Description Framework，即资源描述框架。采用“资源-属性-属性值”的“主谓宾”结构（或称三元组），提供一种框架容器，并通过XML定义了一套形式化的方法，为机器语义理解的结构基础。</li> <li>RDFS：RDFS是RDF的一个扩展，它提供了一些基本的类和属性，以及它们之间的关系。</li> <li>OWL：Web Ontology Language，Web本体语言，它是基于RDF和RDFS的一种更加丰富的知识表示语言。在OWL中，我们可以定义类、属性以及它们的约束和关系。此外，OWL还支持对知识的推理。</li> </ul> <h4 id="22-知识获取">2.2 知识获取</h4> <p>构建好需要的本体模型后，那么就需要把数据构建成对应的模型的输入了。我们知识的来源基本分为以下几类：</p> <ul> <li>私有数据 <ul> <li>企业的文档</li> <li>企业私有的用户数据</li> <li>企业私有的非结构化数据</li> </ul> </li> <li>公有数据 <ul> <li>新闻</li> <li>百科</li> <li>公有语料</li> </ul> </li> </ul> <p>那么对于一些上述这些数据拆分为两大类，来进行<strong>数据处理</strong>：</p> <ul> <li>非结构化数据：一般指的是无任何标识的文本，我们可以采用相关的NLP算法，比如实体识别和关系抽取（或者直接使用事件抽取，这里事件抽取可以参考我之前写的一篇博客）来构建实体关系的三元组。</li> <li>结构化数据：由于本身就是标准化的数据，我们只需要通过D2R服务器将数据库的内容转成RDF的形式。</li> </ul>...<a class="read-more" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html">写专利心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-08T08:00:00+08:00">November 8, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h2 id="写专利心得">写专利心得</h2> <blockquote> <p>最近2个月一口气写了9篇专利，近些年加起来也写了近20篇AI算法类专利了，所以想写点自己对于写专利的一些心得体会。</p> </blockquote> <h3 id="一-专利相关知识">一. 专利相关知识</h3> <h4 id="11-专利是什么">1.1 专利是什么</h4> <p>专利是专利权的简称，主要分为发明、实用新型及工业设计三种类型：</p> <ul> <li> <p>发明：产品、方法及其改进的技术方案</p> </li> <li> <p>使用新型：产品的形状、结构或其结合的技术方案</p> </li> <li> <p>外观设计：产品外部形状、图案、色彩及其组合，如外包装。</p> </li> </ul> <h4 id="12-专利申请流程">1.2 专利申请流程</h4> <ul> <li> <p>想好idea，确保哪些可以写，哪些写不了</p> </li> <li> <p>利用专利检索的工具（比如google学术），查看别人是否写过</p> </li> <li> <p>写交底书（简写）</p> </li> <li> <p>第三方机构代理人撰写</p> </li> <li> <p>专利递交专利局</p> </li> <li> <p>官方受理、初审、公开、实审</p> </li> <li> <p>官方授权</p> </li> <li> <p>专利维持</p>...<a class="read-more" href="./%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html">pyspark使用总结-第二篇</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-07T08:00:00+08:00">November 7, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-常见的oom">一. 常见的OOM</h3> <h4 id="11-常用的解决方案">1.1 常用的解决方案</h4> <p>我们在使用spark的时候，经常在save数据的时候，都会遇到内存溢出的问题，这通常是由于数据量过大导致的。以下是一些可能的解决方案：</p> <ol> <li>增加分区数：如果数据集非常大，可以尝试增加分区数。可以使用<code class="language-plaintext highlighter-rouge">repartition()</code>或<code class="language-plaintext highlighter-rouge">coalesce()</code>函数来增加分区数。增加分区数可以将数据均匀地分布在更多的节点上，从而减少每个节点上的内存压力。</li> <li>压缩数据：如果数据集包含大量重复的值，可以考虑使用压缩算法来减少内存使用。Pyspark提供了多种压缩算法，如Snappy、Gzip等。可以使用<code class="language-plaintext highlighter-rouge">option("compression", "snappy")</code>来设置压缩算法。</li> <li>增加集群资源：可以考虑增加集群资源。可以增加集群的节点数或增加每个节点的内存。可以通过调整<code class="language-plaintext highlighter-rouge">spark.driver.memory</code>和<code class="language-plaintext highlighter-rouge">spark.executor.memory</code>参数来增加内存分配，特别对于driver而言，最好把内存设置大一些。</li> </ol> <h4 id="12-代码方面的优化">1.2 代码方面的优化</h4> <p>如果以上常用的解决方案依旧无法解决OOM的问题，那么我们可能需要考虑是否需要优化pyspark的代码了</p> <ul> <li>UDF过于复杂：尽可能将结果拆分不同的列，然后再用简单的udf来组合这些列进行计算。</li> <li>多用filter算子：提前将大量数据剔除</li> <li>多用select算子：只保留需要的列，减少内存的使用</li> <li>尽量少用collect、count算子：像这些action算子基本都会把executor的数据全部加载回driver上，导致driver的内存吃紧。</li> <li>当发现在某个udf环节只有一个节点在跑的时候，可以使用.cache()来分布式跑任务。</li> </ul> <h4 id="13-数据倾斜导致的oom和心跳时间超时">1.3 数据倾斜导致的OOM和心跳时间超时</h4> <p>通常我们会发现有些时候，数据本身并没有很大，但是要运行很长时间，而且最终还因为heart beat时间过长或则oom而失败。</p> <p><strong>发生</strong> 数据倾斜一般发生在：</p> <ul> <li>join两个df的时候</li> <li>groupby某一列，然后这一列（包含了a，b，c等元素）中，很不巧，a有非常多（1000），而b和c等元素仅有2个</li> </ul> <p><strong>验证</strong> 这时候我们可以直接通过yarn日志中的shuffer resize/records看到很多excutors中会发现极个别失败的excutor的size非常大（10w个），而其他的excutor的size可能只有10个。那么这个时候无疑是发生数据倾斜了。</p> <p><strong>解决</strong> 这里推荐使用<strong>加盐</strong>处理，比什么加excutor的内存和核数更加有效</p>...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html">pyspark使用心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-12-27T08:00:00+08:00">December 27, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-安装">一. 安装</h3> <blockquote> <p>要使用PySpark，本地要有Java开发环境。</p> </blockquote> <ul> <li> <p>Java 8 : <code class="language-plaintext highlighter-rouge">brew install --cask homebrew/cask-versions/adoptopenjdk8</code></p> </li> <li> <p>pyspark安装：<code class="language-plaintext highlighter-rouge">pip install pyspark</code></p> </li> </ul> <h3 id="二-和pandas之间的代码使用">二. 和pandas之间的代码使用</h3> <h4 id="21-读取csv">2.1 读取csv</h4> <blockquote> <p>spark在读取csv上优势就很明显了，能直接快速读取几个G的大文件</p> </blockquote> <p>pandas读取大的csv，只能将其拆分为多个chunk进行读取，假如我们直接读取csv，可能会直接报内存不够导致进程被干掉。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="n">df</span>...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%A7%A3.html">贝叶斯公式及模型的理解</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-02-10T16:10:00+08:00">February 10, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-贝叶斯公式">一. 贝叶斯公式</h3> <h4 id="11-实际的例子推导公式">1.1 实际的例子推导公式</h4> <p>这里我们用比较实际的例子来理解贝叶斯公式。</p> <p>现在我们有2个骰子，每个骰子有6个面。</p> <ul> <li>样本空间：$6\times6 = 36$</li> <li>事件A：其中一个骰子展示的是2</li> <li>事件B：两个骰子的总和是7</li> </ul> <p>如下图所示，将所有的样本空间展示出来，并圈出事件A、B两种情况的所有可能性。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/b_1.png" alt="" /></p> <p>那么，针对每个不同的事件所发生的概率如下：</p> <ul> <li> <p>事件A发生的概率： <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/b_2.png" alt="" /></p> </li> <li> <p>事件B发生的概率： <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/b_3.png" alt="" /></p> </li> <li> <p>事件A、B同时发生的概率： <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/b_4.png" alt="" /></p> </li> <li> <p>在A发生的条件下，B发生的概率： <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/b_5.png" alt="" /></p> </li>...<a class="read-more" href="./%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%90%86%E8%A7%A3.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html">深度学习算法面试总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-06-12T23:21:00+08:00">June 12, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>面试官会根据自己简历中提到的一些点进行提问，这里先自己对某些点进行深挖。</p> </blockquote> <h3 id="一数据处理">一.数据处理</h3> <p>海量数据：</p> <ul> <li>（1）数据量太大，无法短时间内处理完成</li> <li>（2）无法一次性将数据放入内存中。</li> </ul> <h4 id="11-缺失值处理">1.1 缺失值处理</h4> <ul> <li>填充固定值：选取某个固定值/默认值填充缺失值。</li> <li>填充均值：对每一列的缺失值，填充当列的均值。</li> <li>填充中位数：对每一列的缺失值，填充当列的中位数。</li> <li>填充众数：对每一列的缺失值，填充当列的众数。由于存在某列缺失值过多，众数为nan的情况，因此这里取的是每列删除掉nan值后的众数。</li> <li>填充上下条的数据：对每一条数据的缺失值，填充其上下条数据的值。</li> <li>填充插值得到的数据：用插值法拟合出缺失的数据，然后进行填充。插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。</li> </ul> <h3 id="二机器学习">二.机器学习</h3> <h4 id="21--svm和lr的区别与联系">2.1 SVM和LR的区别与联系？</h4> <p>SVM 和 LR 都是属于分类算法，不过 SVM 是通过划分超平面的方法来进行分类，而 LR 则是通过计算样本属于哪个类别的概率，从而达到分类效果</p> <h4 id="22--交叉熵函数系列问题与最大似然函数的关系和区别">2.2 交叉熵函数系列问题？与最大似然函数的关系和区别？</h4> <p>在二分类中，交叉熵函数和负最大似然函数的表达式是相同的，但是交叉熵函数是从信息论角度得到的，而最大似然函数则是从概率论角度得到的</p> <p>交叉熵涉及到2点：</p> <ul> <li>信息量：假设X是一个离散型随机变量，其取值集合为X，概率分布函数为p(x)=Pr(X=x),x∈X，我们定义事件X=x0的信息量为： I(x0)=−log(p(x0))，可以理解为，一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设： 事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219 事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014 可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。</li> <li>熵：假设小明的考试结果是一个0-1分布XA只有两个取值{0：不及格，1：及格}，在某次考试结果公布前，小明的考试结果有多大的不确定度呢？你肯定会说：十有八九不及格！因为根据先验知识，小明及格的概率仅有0.1,90%的可能都是不及格的。怎么来度量这个不确定度？求期望！不错，我们对所有可能结果带来的额外信息量求取均值（期望），其结果不就能够衡量出小明考试成绩的不确定度了吗。<strong>熵其实是信息量的期望值，它是一个随机变量的确定性的度量。熵越大，变量的取值越不确定，反之就越确定。</strong></li> <li>相对熵：称为<strong>KL散度</strong>，是两个随机分布间距离的度量。越小说明分布越一致。</li> <li>交叉熵：交叉熵与KL距离在行为上是等价的，都反映了分布p，q的相似程度。特别的，在logistic regression中， p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p)X∼B(1,p)...<a class="read-more" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="深度学习" class="hidden tag-master">
		<h1>深度学习</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul>...<a class="read-more" href="./raft.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused...<a class="read-more" href="./graphrag.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./langchain.html">LLM的应用开发框架——Langchain</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-07-04T08:00:00+08:00">July 4, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-langchain是什么">一. Langchain是什么</h3> <blockquote> <p>Langchain 官网文档：https://python.langchain.com/v0.2/docs/introduction/</p> </blockquote> <h4 id="llm崛起出现了哪些需求">LLM崛起出现了哪些需求？</h4> <ul> <li> <p>格式化输出：希望给的输出格式是json、csv、db格式</p> </li> <li> <p>输出很长的提示词文本：如何总结一本书的内容？</p> </li> <li> <p>多次API调用：两次调用api，前后两次需要结合的</p> </li> <li> <p>外部调用：比如需要进行web 搜索</p> </li> <li> <p>标准化开发</p> </li> <li> <p>快速切换模型：有多个大模型可用，支持代码不变，快速切换</p> </li> </ul> <h3 id="二-langchain支撑llm的应用">二. Langchain支撑LLM的应用</h3> <h4 id="21-支持多种llm">2.1 支持多种LLM</h4> <p>无论是国外的GPT4、LLaMa，还是国内的ChatGLM、Baichuan，都支持调用api和huggingface模型的使用，下面主要介绍HF模型的下载使用。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">huggingface_hub</span> <span class="kn">import</span> <span class="n">snapshot_download</span> <span...<a class="read-more" href="./langchain.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pytorch_lightning%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C.html">pytorch_lightning使用体验</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-01-18T08:00:00+08:00">January 18, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>如果是一些小模型想要快速实验，不想怎么写代码的，可以通过pytorch_lightning快速搭建模型，但是如果涉及到大模型，以及分布式训练预测，咱还是老老实实用pytorch吧。</p> </blockquote> <h3 id="一-使用体验">一. 使用体验</h3> <p>就像很多年前写过tensorflow之后看到keras后的欣喜，当我看到pytorch_lightning后瞬间就喜欢上了它！对于pytorch的重度使用者来说，每次都要写很多重复的训练预测代码，总感觉代码复用起来很麻烦，于是pytorch_lightning它来啦！</p> <p><strong>pytorch_lightning的优势：</strong></p> <ul> <li> <p>代码可读性、复用性高</p> </li> <li> <p>自由度和pytorch一样高，并没有像使用keras一样感觉封装过死的感觉。</p> </li> <li> <p>能像keras一样快速搭建模型，简化模型训练和预测的过程</p> </li> <li> <p>支持分布式训练</p> </li> </ul> <h3 id="二-安装和使用">二. 安装和使用</h3> <p>官网地址是：https://lightning.ai/</p> <p>pip进行安装：<code class="language-plaintext highlighter-rouge">pip show pytorch_lightning</code></p> <p>下面使用MNIST来展示如何使用pytorch_lightning来简化自己的代码</p> <h4 id="21-数据模块lightningdatamodule">2.1 数据模块LightningDataModule</h4> <p>通常情况下，我们需要做一些预处理，以及在定义完自己的dataset后，需要定义dataloader，这里可以直接继承LightningDataModule模块，直接重写其中的方法即可。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span> <span class="k">def</span> <span...<a class="read-more" href="./pytorch_lightning%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.html">分布式训练推理Accelerate</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-08-16T23:00:00+08:00">August 16, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>分布式训练的加速策略详情可见本人上篇文章《 <a href="https://www.lixiaofei2yy.website/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8">大语言模型的应用及训练</a>》，一般有三种，分别是数据并行，流水线式并行和张量并行，本文主推使用hugging face的accelerate库来进行模型分布式的训练和推理。</p> </blockquote> <h3 id="一-torch常用的分布式训练工具">一. torch常用的分布式训练工具</h3> <h4 id="11-dataparallel">1.1 DataParallel</h4> <p>DP(DataParallel)：实现数据并行方式的分布式训练，采用的是PS(worker-server)模式，<strong>不推荐</strong>。</p> <ul> <li>单进程多线程</li> <li>只能在单机上使用</li> <li>训练速度慢，且由于是<strong>PS模式（存在负载不均衡的问题）</strong>，随着worker的个数增多，训练速度越慢</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/dp111.png" alt="" /></p> <h4 id="12-distributeddataparallel">1.2 DistributedDataParallel</h4> <p>DDP(DistributedDataParallel)：实现数据并行方式的分布式训练，采用的是ring-all-reduce模式。它将<strong>模型复制到每个 GPU 上 ，同时复制了每个dataloader</strong>，并且当 <code class="language-plaintext highlighter-rouge">loss.backward()</code> 被调用进行反向传播的时候，所有这些模型副本的梯度将被同步地平均/下降 (reduce)。这确保每个设备在执行优化器步骤后具有相同的权重。</p> <ul> <li> <p>多进程</p> </li> <li> <p>支持多机多卡</p> </li> <li> <p>训练速度较DP快，ring-all-reduce模式下，所有worker只和自己相邻的两个worker进行通信</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/ddp.png" alt="" /></p> </li> </ul> <h4 id="13-amp">1.3 amp</h4>...<a class="read-more" href="./%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="爬虫" class="hidden tag-master">
		<h1>爬虫</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html">Selenium和webscraper爬虫</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-12-24T08:00:00+08:00">December 24, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-selenium爬虫">一. Selenium爬虫</h3> <h4 id="1-安装">1. 安装</h4> <blockquote> <p>Selenium 本身是一个自动化测试的工具，模拟人为在浏览器上进行操作，比如点击和下拉等等。</p> </blockquote> <p>安装的环境：</p> <ul> <li>python环境</li> <li>pip安装Selenium包：<code class="language-plaintext highlighter-rouge">pip install selenium</code></li> <li>chrome浏览器驱动：去<a href="https://chromedriver.chromium.org/downloads">官网</a>下载自己电脑已安装的浏览器所在的版本驱动</li> </ul> <p>我这边的chrome驱动装的是mac版本的，这里需要将其路径放到mac的环境变量中，下载后放到了<code class="language-plaintext highlighter-rouge">/usr/local/chromedriver</code>，</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim ~/.profile export PATH="$PATH:/usr/local/chromedriver" source ~/.profile </code></pre></div></div> <p>可以在控制台打<code class="language-plaintext highlighter-rouge">chromedriver</code>测试是否ok。</p> <h4 id="2-使用">2. 使用</h4> <blockquote> <p>这里的例子是的主要任务是：将给的头条url所在的公众号遍历其30条的文章标题和链接。</p> </blockquote> <p>所以我们需要拆解为2步：</p> <ul> <li>打开给定的url，并点击头条的公众号。</li> <li>另开一个页面，找到公众号下前30条文章的标题和链接（这里需要下拉才能看到后面的文章）。</li> </ul> <p>第一步：实例一个浏览器驱动，并找到公众号的XPath（这里推荐一个测试XPath的<strong>浏览器插件XPath...<a class="read-more" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="面试" class="hidden tag-master">
		<h1>面试</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html">面试基础总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-12-13T05:11:00+08:00">December 13, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        4 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-操作系统">一. 操作系统</h3> <h4 id="11-并行和并发">1.1 并行和并发</h4> <p><strong>并发</strong>：在操作系统中，某一时间段，几个程序在同一个CPU上运行，但在任意一个时间点上，只有一个程序在CPU上运行。</p> <p><strong>并行</strong>：当操作系统有多个CPU时，一个CPU处理A线程，另一个CPU处理B线程，<strong>两个线程互相不抢占CPU资源，可以同时进行</strong>，这种方式成为并行。</p> <p>知乎的例子：</p> <ul> <li>你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。</li> <li>你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。</li> <li>你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。</li> </ul> <h4 id="12-进程和线程">1.2 进程和线程</h4> <h5 id="121-进程">1.2.1 进程</h5> <p>​ <strong>进程是资源分配的基本单位，理解为一个程序</strong>。所以我们一般都要求进程池的进程数小于等于CPU的核心数。</p> <p>​ 如果问<strong>单核CPU能否运行多进程？</strong>答案又是肯定的。单核CPU也可以运行多进程，只不过不是同时的，而是极快地在<strong>进程间来回切换实现的多进程</strong>。进<strong>程拥有自己的地址空间，全局变量，文件描述符，各种硬件等等资源</strong>。</p> <h5 id="122-线程">1.2.2 线程</h5> <p>​ <strong>线程</strong>：线程是依赖于进程的。<strong>如果说进程和进程之间相当于程序与程序之间的关系，那么线程与线程之间就相当于程序内的任务和任务之间的关系。</strong></p> <p>​ 一个程序内包含了多种任务。加上了线程之后，线程能够共享进程的大部分资源，并参与CPU的调度。意味着它能够在<strong>进程间进行切换，实现并发</strong>。</p> <h5 id="123-为什么要用多进程适用条件">1.2.3 为什么要用多进程，适用条件</h5> <p>​ 总是在运行一个进程上的任务，就会出现一个现象。就是任务不一定总是在执行 ”计算型“ 的任务，会有很大可能是在执行网络调用，阻塞了，CPU 岂不就浪费了？</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_1.jpg" alt="" /></p> <p>因此，多进程适用于<strong>CPU密集型任务(各种循环处理、计算等等)</strong>。多线程适用于<strong>IO密集型任务(文件处理、网络爬虫等)</strong>。</p> <h5 id="124-多进程通信">1.2.4 多进程通信</h5> <p><strong>管道pipe</strong>：管道是一种<strong>半双工</strong>的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指<strong>父子进程关系</strong>。类似于python的<code class="language-plaintext highlighter-rouge">multiprocessing.Pipe()</code></p>...<a class="read-more" href="./%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html">深度学习算法面试总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-06-12T23:21:00+08:00">June 12, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>面试官会根据自己简历中提到的一些点进行提问，这里先自己对某些点进行深挖。</p> </blockquote> <h3 id="一数据处理">一.数据处理</h3> <p>海量数据：</p> <ul> <li>（1）数据量太大，无法短时间内处理完成</li> <li>（2）无法一次性将数据放入内存中。</li> </ul> <h4 id="11-缺失值处理">1.1 缺失值处理</h4> <ul> <li>填充固定值：选取某个固定值/默认值填充缺失值。</li> <li>填充均值：对每一列的缺失值，填充当列的均值。</li> <li>填充中位数：对每一列的缺失值，填充当列的中位数。</li> <li>填充众数：对每一列的缺失值，填充当列的众数。由于存在某列缺失值过多，众数为nan的情况，因此这里取的是每列删除掉nan值后的众数。</li> <li>填充上下条的数据：对每一条数据的缺失值，填充其上下条数据的值。</li> <li>填充插值得到的数据：用插值法拟合出缺失的数据，然后进行填充。插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。</li> </ul> <h3 id="二机器学习">二.机器学习</h3> <h4 id="21--svm和lr的区别与联系">2.1 SVM和LR的区别与联系？</h4> <p>SVM 和 LR 都是属于分类算法，不过 SVM 是通过划分超平面的方法来进行分类，而 LR 则是通过计算样本属于哪个类别的概率，从而达到分类效果</p> <h4 id="22--交叉熵函数系列问题与最大似然函数的关系和区别">2.2 交叉熵函数系列问题？与最大似然函数的关系和区别？</h4> <p>在二分类中，交叉熵函数和负最大似然函数的表达式是相同的，但是交叉熵函数是从信息论角度得到的，而最大似然函数则是从概率论角度得到的</p> <p>交叉熵涉及到2点：</p> <ul> <li>信息量：假设X是一个离散型随机变量，其取值集合为X，概率分布函数为p(x)=Pr(X=x),x∈X，我们定义事件X=x0的信息量为： I(x0)=−log(p(x0))，可以理解为，一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设： 事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219 事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014 可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。</li> <li>熵：假设小明的考试结果是一个0-1分布XA只有两个取值{0：不及格，1：及格}，在某次考试结果公布前，小明的考试结果有多大的不确定度呢？你肯定会说：十有八九不及格！因为根据先验知识，小明及格的概率仅有0.1,90%的可能都是不及格的。怎么来度量这个不确定度？求期望！不错，我们对所有可能结果带来的额外信息量求取均值（期望），其结果不就能够衡量出小明考试成绩的不确定度了吗。<strong>熵其实是信息量的期望值，它是一个随机变量的确定性的度量。熵越大，变量的取值越不确定，反之就越确定。</strong></li> <li>相对熵：称为<strong>KL散度</strong>，是两个随机分布间距离的度量。越小说明分布越一致。</li> <li>交叉熵：交叉熵与KL距离在行为上是等价的，都反映了分布p，q的相似程度。特别的，在logistic regression中， p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p)X∼B(1,p)...<a class="read-more" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html"> 阅读更多</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

<style>
.spinner {
  margin: 100px auto;
  width: 50px;
  height: 40px;
  text-align: center;
  font-size: 10px;
}

.spinner > div {
  background-color: var(--accent);
  height: 100%;
  width: 6px;
  display: inline-block;

  -webkit-animation: sk-stretchdelay 1.2s infinite ease-in-out;
  animation: sk-stretchdelay 1.2s infinite ease-in-out;
}

.spinner .rect2 {
  -webkit-animation-delay: -1.1s;
  animation-delay: -1.1s;
}

.spinner .rect3 {
  -webkit-animation-delay: -1.0s;
  animation-delay: -1.0s;
}

.spinner .rect4 {
  -webkit-animation-delay: -0.9s;
  animation-delay: -0.9s;
}

.spinner .rect5 {
  -webkit-animation-delay: -0.8s;
  animation-delay: -0.8s;
}

@-webkit-keyframes sk-stretchdelay {
  0%, 40%, 100% { -webkit-transform: scaleY(0.4) }
  20% { -webkit-transform: scaleY(1.0) }
}

@keyframes sk-stretchdelay {
  0%, 40%, 100% {
    transform: scaleY(0.4);
    -webkit-transform: scaleY(0.4);
  }  20% {
    transform: scaleY(1.0);
    -webkit-transform: scaleY(1.0);
  }
}
</style>
<div class="spinner">
  <div class="rect1"></div>
  <div class="rect2"></div>
  <div class="rect3"></div>
  <div class="rect4"></div>
  <div class="rect5"></div>
</div>




<div class="tag-cloud">
    
        <ul class="tags">
            
                
                <li><a href="./tag.html?tag=CV" class="tag">CV <span>(13)</span></a></li>
            
                
                <li><a href="./tag.html?tag=LLM" class="tag">LLM <span>(5)</span></a></li>
            
                
                <li><a href="./tag.html?tag=NLP" class="tag">NLP <span>(11)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E4%BB%A3%E7%A0%81" class="tag">代码 <span>(16)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E5%8D%9A%E5%AE%A2" class="tag">博客 <span>(3)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E5%9B%BE%E7%AE%97%E6%B3%95" class="tag">图算法 <span>(2)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" class="tag">机器学习 <span>(9)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="tag">深度学习 <span>(25)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E7%88%AC%E8%99%AB" class="tag">爬虫 <span>(1)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E9%9D%A2%E8%AF%95" class="tag">面试 <span>(2)</span></a></li>
            
    
        </ul>
</div>
  <div class="search-box">
  <div class="wrapper">
    <div class="search-grid">
      <form class="search-form">
        <div id="search-container">
          <input type="text" id="search-input" class="search" placeholder="Search">
        </div>
      </form>
      <ul id="results-container" class="results-search"></ul>
      <div class="icon-close-container">
        <span class="search-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
      </div>
    </div>
  </div>
</div>

  <div class="pagination clearfix">
  
  
</div>

  </div> <!-- End Wrapper -->
  




<footer class="main-footer">
    <div class="footer-wrapper">
        <div class="logo-symbol">
            <a class="logo-link" title="凡人炼丹传" href="./">
                <svg width="45px" height="45px" class="logo-symbol" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet" version="1.0" viewBox="0 0 649 649"><g fill="currentColor" stroke="none"><path d="M2938 6380 c-551 -53 -1031 -220 -1478 -514 -306 -201 -588 -470 -810 -771 -276 -374 -475 -850 -559 -1336 -64 -371 -53 -836 29 -1211 155 -712 552 -1347 1130 -1810 450 -360 1021 -589 1640 -659 58 -6 202 -12 320 -12 282 0 503 26 756 87 902 220 1680 841 2079 1661 303 622 402 1333 279 2005 -90 496 -313 984 -634 1390 -111 140 -378 404 -519 513 -456 352 -957 560 -1549 643 -126 17 -558 26 -684 14z m687 -220 c77 -11 189 -32 250 -46 127 -29 345 -94 345 -103 0 -4 -341 -188 -757 -409 l-757 -403 -41 22 c-22 13 -58 26 -79 29 l-40 5 -148 370 c-82 204 -150 377 -153 386 -10 29 325 119 570 153 169 24 174 24 430 21 183 -3 273 -8 380 -25z m-1292 -546 l157 -387 -24 -28 c-13 -16 -30 -44 -36 -64 -6 -19 -17 -35 -23 -35 -7 -1 -382 -54 -834 -119 -453 -64 -823 -115 -823 -111 0 3 43 62 95 132 269 358 584 630 980 844 90 49 321 153 341 154 6 0 81 -174 167 -386z m2026 347 l37 -20 129 -440 128 -440 -35 -39 c-20 -22 -37 -44 -39 -50 -3 -8 -290 13 -929 66 -775 65 -925 80 -928 92 -2 11 223 134 785 432 433 228 794 416 801 417 7 0 30 -8 51 -18z m204 -92 c420 -211 850 -600 1137 -1027 34 -51 60 -95 57 -98 -4 -4 -805 157 -859 172 -10 3 -18 12 -18 21 0 58 -78 133 -137 133 -18 0 -33 2 -33 5 0 3 -52 184 -116 403 -63 218 -117 405 -120 415 -3 9 -3 17 1 17 3 0 42 -19 88 -41z m-913 -894 c494 -41 904 -75 912 -75 7 -1 24 -23 36 -51 l24 -50 -169 -269 -168 -270 -44 0 c-24 0 -63 -9 -86 -21 l-42 -21 -679 402 c-373 222 -688 409 -699 416 -18 13 -18 14 -1 14 10 0 422 -34 916 -75z m-1175 18 l48 -48 -31 -225 c-18 -124 -60 -417 -94 -652 l-62 -428 -44 0 c-24 0 -51 -4 -61 -10 -16 -8 -146 87 -777 566 -418 317 -761 578 -763 580 -3 3 0 9 5 14 8 8 1633 247 1700 249 25 1 42 -9 79 -46z m915 -414 l690 -411 0 -38 0 -37 -147 -46 c-82 -26 -453 -148 -825 -271 l-676 -223 -22 30 -22 29 98 669 c82 557 101 669 114 669 8 0 31 9 50 19 19 11 38 20 43 20 4 1 318 -184 697 -410z m1959 175 c251 -53 457 -97 457 -98 9 -9 123 -247 153 -320 113 -272 189 -599 209 -901 l9 -130 -231 -273 c-224 -265 -232 -273 -264 -270 l-34 3 -418 1013 -419 1013 26 30 c15 16 33 29 41 29 8 0 220 -43 471 -96z m-593 2 c6 -5 804 -1949 802 -1952 -2 -2 -274 272 -605 609 l-600 612 13 32 c20 46 17 82 -9 128 l-23 41 170 271 171 272 40 -6 c22 -3 41 -6 41 -7z m-3341 -611 c402 -307 733 -561 737 -564 31 -26 -38 -31 -947 -65 -516 -19 -941 -33 -944 -30 -2 2 6 77 18 165 49 346 162 693 324 986 44 82 52 91 66 79 9 -7 345 -264 746 -571z m2710 -142 c17 -16 39 -32 48 -38 15 -9 13 -64 -23 -695 -22 -377 -40 -686 -40 -687 0 -2 -8 -3 -19 -3 -10 0 -30 -9 -45 -21 l-27 -21 -342 200 c-188 110 -542 317 -787 460 -245 144 -445 266 -445 273 0 8 312 116 820 285 451 150 822 272 824 273 2 1 18 -11 36 -26z m590 -425 c220 -222 500 -505 623 -629 l223 -225 -17 -31 -18 -30 -585 -82 c-322 -45 -602 -85 -621 -88 -31 -4 -37 -1 -53 27 -11 17 -34 39 -53 47 -19 9 -34 21 -34 27 -1 6 16 316 37 688 l37 678 26 9 c14 5 27 10 30 10 3 1 185 -180 405 -401z m-2587 -114 c-2 -9 -224 -178 -494 -375 l-492 -359 -38 16 c-26 11 -53 14 -84 10 -25 -3 -55 -7 -67 -8 -16 -2 -106 76 -362 316 -204 192 -341 327 -341 338 0 16 10 18 83 19 45 0 431 13 857 28 984 36 942 35 938 15z m59 -88 l22 -23 -104 -467 c-58 -256 -105 -468 -105 -470 0 -2 -14 -6 -32 -10 -17 -3 -47 -18 -65 -32 l-34 -26 -339 122 -338 122 -7 45 c-5 37 -3 47 12 58 10 7 229 169 488 359 258 190 472 346 475 346 3 0 15 -11 27 -24z m1013 -430 c421 -245 769 -452 775 -460 5 -8 7 -18 3 -21 -3 -4 -417 -41 -920 -84 l-913 -77 -16 26 c-9 15 -29 36 -45 47 l-28 21 104 465 105 465 43 7 c27 4 55 17 75 35 18 16 37 28 42 26 6 -2 354 -204 775 -450z m-2307 -276 c-7 -71 -4 -98 10 -126 l15 -30 -206 -248 -206 -248 -27 59 c-140 314 -228 733 -229 1086 l0 138 323 -303 c270 -254 322 -307 320 -328z m5277 366 c-17 -270 -58 -489 -135 -721 -38 -117 -134 -350 -140 -343 -1 2 -35 117 -75 256 l-72 253 26 25 c51 52 58 134 15 189 -21 26 -21 26 -2 48 11 12 102 120 203 240 100 120 184 216 186 214 2 -2 -1 -74 -6 -161z m-642 -487 l21 -41 -456 -782 c-251 -429 -461 -787 -467 -794 -9 -9 -19 -10 -42 -2 l-29 10 -174 676 -174 675 35 37 c20 20 40 51 45 67 l10 30 584 82 c321 44 594 82 605 82 16 1 27 -10 42 -40z m-4015 -145 c301 -109 327 -120 327 -142 0 -12 7 -39 15 -58 l15 -36 -411 -469 c-226 -259 -413 -468 -415 -466 -2 2 1 219 6 483 5 263 10 538 10 610 l0 132 29 12 c16 6 39 23 52 36 13 14 28 23 34 21 5 -2 157 -57 338 -123z m-517 -413 c-3 -262 -9 -527 -12 -589 -8 -134 -2 -135 -120 20 -93 121 -192 278 -272 428 l-61 115 215 257 c181 216 218 255 235 251 l22 -6 -7 -476z m4695 460 c3 -3 43 -133 88 -289 l82 -282 -62 -108 c-75 -130 -175 -278 -265 -392 -140 -176 -514 -528 -595 -558 -13 -5 -72 -13 -130 -17 l-105 -7 -16 40 -16 40 462 796 461 796 45 -6 c25 -4 48 -9 51 -13z m-1736 -69 c-6 -5 -361 -192 -790 -417 -429 -224 -806 -422 -838 -439 -52 -28 -59 -29 -70 -15 -17 22 -78 59 -99 59 -19 0 -16 -14 -68 300 -29 169 -38 246 -30 248 27 9 62 50 74 87 11 32 19 41 43 44 67 8 1683 139 1733 140 30 0 50 -3 45 -7z m90 -62 c10 -11 38 -26 62 -31 38 -10 44 -16 52 -48 90 -346 333 -1280 337 -1292 3 -11 -7 -23 -29 -36 -19 -11 -42 -38 -53 -60 l-19 -40 -1050 297 c-859 244 -1050 301 -1050 315 0 12 239 141 860 465 473 247 863 449 866 449 3 1 14 -8 24 -19z m-2076 -210 c13 0 21 -9 25 -27 10 -47 86 -497 86 -508 0 -5 -13 -19 -29 -29 -35 -24 -57 -59 -66 -108 -4 -22 -14 -39 -24 -42 -143 -41 -861 -236 -870 -236 -7 0 -11 5 -9 11 2 6 190 224 418 484 349 399 416 472 431 464 10 -5 27 -9 38 -9z m1376 -1065 c741 -208 1053 -300 1060 -312 6 -9 24 -32 41 -52 l31 -35 -30 -68 c-34 -77 -25 -71 -205 -139 -310 -116 -653 -180 -984 -183 -97 0 -178 1 -181 4 -89 106 -817 1053 -817 1063 0 18 9 27 23 21 7 -2 485 -137 1062 -299z m-1319 264 c31 -35 81 -51 134 -44 l46 6 380 -487 c208 -268 385 -496 392 -506 13 -17 10 -18 -45 -12 -640 65 -1267 346 -1732 776 l-61 57 42 12 c271 74 805 218 814 218 6 1 19 -9 30 -20z m2814 -563 c0 -5 -223 -138 -278 -165 -24 -13 -46 -20 -49 -18 -2 3 3 19 11 36 12 22 27 33 59 42 27 7 56 26 81 52 35 37 44 41 105 47 36 4 67 8 69 9 1 0 2 -1 2 -3z" transform="translate(0.000000,644.000000) scale(0.100000,-0.100000)"/></g></svg>
            </a>
        </div>
        <div class="copyright">
          <p>2026 &copy; 李小肥的YY</p>
        </div>
        <div class="footer-nav">
            <div>
                <a href="./archive.html">
                    文章
                </a>
            </div>
            <div>
                <a href="./tags.html">
                    标签
                </a>
            </div>
            <div>
                <a href="./about.html">
                    关于
                </a>
            </div>
        </div>
    </div>
</footer> <!-- End Footer -->

</div>

    <div class="top" title="Top">
      <svg aria-hidden="true" focusable="false" data-prefix="fal" data-icon="angle-up" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="svg-inline--fa fa-angle-up fa-w-8 fa-2x"><path fill="currentColor" d="M136.5 185.1l116 117.8c4.7 4.7 4.7 12.3 0 17l-7.1 7.1c-4.7 4.7-12.3 4.7-17 0L128 224.7 27.6 326.9c-4.7 4.7-12.3 4.7-17 0l-7.1-7.1c-4.7-4.7-4.7-12.3 0-17l116-117.8c4.7-4.6 12.3-4.6 17 .1z" class=""></path></svg>
    </div>
    




<!-- JS -->












<script>
(function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var logo = document.getElementById('logo');
    var nightModeOption = ('auto' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
    storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
    var data = storage.getItem('theme');
    try {
        data = JSON.parse(data ? data : '');
    } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
    }
    return data;
    }

    function handleThemeToggle(nightShift) {
    themeData.nightShift = nightShift;
    saveThemeData(themeData);
    html.dataset.theme = nightShift ? 'dark' : 'light';
    if (nightShift) {
        logo.setAttribute("src", "./assets/img/branding/MVM-logo-full-dark.svg");
    } else {
        logo.setAttribute("src", "./assets/img/branding/MVM-logo-full.svg");
    }
    // Toggle author image
    var authorImg = document.getElementById('author-img');
    var authorImgAbout = document.getElementById('author-img-about');
    
    if (nightShift) {
        if (authorImg) {
            authorImg.setAttribute("src", "./assets/img/yy_dark.png");
        }
        if (authorImgAbout) {
            authorImgAbout.setAttribute("src", "./assets/img/yy_dark.png");
        }
    } else {
        if (authorImg) {
            authorImg.setAttribute("src", "./assets/img/yy.jpg");
        }
        if (authorImgAbout) {
            authorImgAbout.setAttribute("src", "./assets/img/yy.jpg");
        }
    }
    
    setTimeout(function() {
        sw.checked = nightShift ? true : false;
    }, 50);
    }

    function autoThemeToggle() {
    // Next time point of theme toggle
    var now = new Date();
    var toggleAt = new Date();
    var hours = now.getHours();
    var nightShift = hours >= 19 || hours <=7;

    if (nightShift) {
        if (hours > 7) {
        toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
    } else {
        toggleAt.setHours(19);
    }

    toggleAt.setMinutes(0);
    toggleAt.setSeconds(0);
    toggleAt.setMilliseconds(0)

    var delay = toggleAt.getTime() - now.getTime();

    // auto toggle theme mode
    setTimeout(function() {
        handleThemeToggle(!nightShift);
    }, delay);

    return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
    };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
    handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
    var data = autoThemeToggle();

    // Toggle theme by local setting
    if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
    } else {
        handleThemeToggle(themeData.nightShift);
    }
    } else if (nightModeOption == 'manual') {
    handleThemeToggle(themeData.nightShift);
    } else {
    var nightShift = themeData.nightShift;
    if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
    }
    handleThemeToggle(nightShift);
    }
})();
</script>

<script src="./assets/js/jekyll-search.js"></script>
<script src="./assets/js/jquery-3.6.0.min.js"></script>







<script src="./assets/js/main.js"></script>
<script>
  SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('results-container'),
      json: './search.json',
      searchResultTemplate: '<li><a href="{url}" title="{description}">{title}</a><p>{description}</p></li>',
      noResultsText: 'No results found',
      fuzzy: false,
      exclude: ['Welcome']
    });
</script>


  <script src="./assets/js/infinite-jekyll.js"></script>



    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R8SZS2YBZK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R8SZS2YBZK');
</script>
  </body>
</html>
