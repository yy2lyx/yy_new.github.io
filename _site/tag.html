<!DOCTYPE html>
<html lang="en">
  




<head>
	<meta charset="utf-8">
	<title>Tag - 凡人炼丹传</title>
	<link rel="canonical" href="http://localhost:4000/tag.html">
	<meta name="description" content="欢迎各位看官光临本小站，希望共同学习进步哈！">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:4000"},
  "headline": "Tag",
  "abstract": "",
    "keywords": "",
    "wordcount": "75",
    "image": ["http://localhost:4000/assets/img"],
  "datePublished": "",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": ""},
  "publisher": {
    "@type":  "Organization",
    "logo": {
        "@type": "ImageObject",
        "encodingFormat": "image/png",
        "contentUrl": "http://localhost:4000/assets/img/branding/logo1.png",
        "url": "http://localhost:4000/assets/img/branding/logo1.png"},
    "name" : "凡人炼丹传"}
}
</script>
<!-- Open Graph data -->
<meta property="og:url" content="http://localhost:4000/tag.html"/>
<meta property="og:type" content="article"/>
<meta property="og:title" content="Tag"/>
<meta property="og:description" content=""/>
<meta property="og:image" content="http://localhost:4000/assets/img"/>
<meta property="og:image:alt" content="Tag"/>
<meta property="og:site_name" content="凡人炼丹传" />
<meta property="article:published_time" content="" />
<meta property="article:modified_time" content="" />
<meta property="article:tag" content="" />
<meta property="fb:admins" content="ar.maybach" />
<!-- Schema.org markup for Google -->
<meta itemprop="name" content="Tag">
<meta itemprop="description" content="">
<meta itemprop="image" content="http://localhost:4000/assets/img">
<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="">
<meta name="twitter:title" content="Tag">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="">
<meta data-rh="true" name="twitter:label1" content="Word count"/>
<meta data-rh="true" name="twitter:data1" content="75"/>
<meta name="twitter:image:src" content="http://localhost:4000/assets/img/">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#311e3e">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#311e3e">
	<!-- Google Fonts -->
	<link rel="preconnect" href="https://fonts.gstatic.com" />
	<style>
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 600;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 200;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3i94_wlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 700;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
	</style>
	<!-- <link href="https://fonts.googleapis.com/css?family=Lora:400,600|Source+Sans+Pro:200,400,700" rel="stylesheet"> -->
	<!-- Font Awesome -->
	<link rel="stylesheet" href="./assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="./assets/css/main.css">
	




<link rel="icon" href="./assets/img/favicon/favicon.ico" type="image/x-icon">
<link rel="apple-touch-icon" href="./assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="72x72" href="./assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="114x114" href="./assets/img/favicon/favicon.ico">
	
</head>

  <body>
    <div class="flex-container transparent">
  




<header class="main-header">
  <div class="wrapper">
    <div class="header-flex">
      <div class="menu-icon-container">
        <span class="menu-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
      </div>
      <nav class="main-nav">
        <span class="menu-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
        <ul>
          <li>
            <div class="theme-toggle night">
    <input class="night" type="checkbox" id="theme-switch">
    <label class="night" for="theme-switch">
        <div class="toggle night"></div>
        <div class="names night">             
        <p class="light night"><svg class="night" width="20" viewBox="0 0 25 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M12.5 2.49871C11.3401 2.50016 10.2282 2.96156 9.40801 3.78171C8.58785 4.60187 8.12645 5.71383 8.125 6.87371C8.125 7.03947 8.19085 7.19844 8.30806 7.31565C8.42527 7.43286 8.58424 7.49871 8.75 7.49871C8.91576 7.49871 9.07473 7.43286 9.19194 7.31565C9.30915 7.19844 9.375 7.03947 9.375 6.87371C9.37593 6.04519 9.70547 5.25088 10.2913 4.66503C10.8772 4.07918 11.6715 3.74964 12.5 3.74871C12.6658 3.74871 12.8247 3.68286 12.9419 3.56565C13.0592 3.44844 13.125 3.28947 13.125 3.12371C13.125 2.95795 13.0592 2.79898 12.9419 2.68177C12.8247 2.56456 12.6658 2.49871 12.5 2.49871V2.49871ZM12.5 -0.00129131C8.47891 -0.00129131 5.62031 3.26238 5.625 6.88269C5.62487 8.54403 6.22974 10.1486 7.32656 11.3964C8.32891 12.5378 9.29062 14.4007 9.375 14.9987L9.37734 17.9358C9.37744 18.0587 9.41402 18.1787 9.48242 18.2807L10.4395 19.7198C10.4964 19.8055 10.5737 19.8758 10.6644 19.9245C10.7551 19.9731 10.8564 19.9986 10.9594 19.9987H14.0395C14.1426 19.9988 14.2441 19.9734 14.3351 19.9247C14.426 19.8761 14.5034 19.8057 14.5605 19.7198L15.5176 18.28C15.5854 18.1776 15.6219 18.0578 15.6227 17.935L15.625 14.9987C15.7129 14.3846 16.6797 12.5303 17.6734 11.3964C18.5434 10.4028 19.1087 9.17963 19.3015 7.87318C19.4944 6.56673 19.3066 5.23238 18.7608 4.02985C18.215 2.82732 17.3342 1.80757 16.2238 1.09264C15.1135 0.377721 13.8206 -0.00207746 12.5 -0.00129131V-0.00129131ZM14.3727 17.7452L13.7047 18.7487H11.2937L10.6273 17.7452V17.4987H14.3738L14.3727 17.7452ZM14.375 16.2487H10.625L10.6227 14.9987H14.375V16.2487ZM16.7348 10.5725C16.1879 11.1956 15.316 12.4511 14.7594 13.7479H10.243C9.68516 12.4507 8.81328 11.1956 8.26641 10.5725C7.36971 9.5491 6.87599 8.2344 6.87734 6.87371C6.87031 3.8659 9.23594 1.24871 12.5 1.24871C15.602 1.24871 18.125 3.77176 18.125 6.87371C18.1249 8.23456 17.6305 9.54904 16.7336 10.5725H16.7348ZM3.75 6.87371C3.75 6.70795 3.68415 6.54898 3.56694 6.43177C3.44973 6.31456 3.29076 6.24871 3.125 6.24871H0.625C0.45924 6.24871 0.300269 6.31456 0.183058 6.43177C0.065848 6.54898 0 6.70795 0 6.87371C0 7.03947 0.065848 7.19844 0.183058 7.31565C0.300269 7.43286 0.45924 7.49871 0.625 7.49871H3.125C3.29076 7.49871 3.44973 7.43286 3.56694 7.31565C3.68415 7.19844 3.75 7.03947 3.75 6.87371ZM20.625 2.49871C20.7221 2.49849 20.8178 2.4759 20.9047 2.43269L23.4047 1.18269C23.5529 1.10852 23.6657 0.978483 23.718 0.821201C23.7704 0.66392 23.7582 0.492273 23.684 0.344021C23.6473 0.270614 23.5964 0.205161 23.5344 0.151397C23.4724 0.0976336 23.4004 0.0566132 23.3225 0.0306781C23.1652 -0.0217002 22.9936 -0.00945342 22.8453 0.0647243L20.3453 1.31472C20.2194 1.37771 20.1184 1.48136 20.0588 1.60889C19.9991 1.73643 19.9843 1.88037 20.0166 2.0174C20.049 2.15442 20.1267 2.2765 20.2371 2.36386C20.3475 2.45122 20.4842 2.49873 20.625 2.49871ZM24.375 6.24871H21.875C21.7092 6.24871 21.5503 6.31456 21.4331 6.43177C21.3158 6.54898 21.25 6.70795 21.25 6.87371C21.25 7.03947 21.3158 7.19844 21.4331 7.31565C21.5503 7.43286 21.7092 7.49871 21.875 7.49871H24.375C24.5408 7.49871 24.6997 7.43286 24.8169 7.31565C24.9342 7.19844 25 7.03947 25 6.87371C25 6.70795 24.9342 6.54898 24.8169 6.43177C24.6997 6.31456 24.5408 6.24871 24.375 6.24871ZM4.65469 1.31472L2.15469 0.0647243C2.08128 0.0279952 2.00136 0.00608435 1.91948 0.00024269C1.83761 -0.00559897 1.75539 0.004743 1.67751 0.0306781C1.52023 0.0830564 1.39019 0.195769 1.31602 0.344021C1.24184 0.492273 1.22959 0.66392 1.28197 0.821201C1.33435 0.978483 1.44706 1.10852 1.59531 1.18269L4.09531 2.43269C4.18223 2.4759 4.27794 2.49849 4.375 2.49871C4.5158 2.49873 4.65248 2.45122 4.7629 2.36386C4.87332 2.2765 4.951 2.15442 4.98337 2.0174C5.01574 1.88037 5.0009 1.73643 4.94124 1.60889C4.88158 1.48136 4.78061 1.37771 4.65469 1.31472ZM23.4047 12.5647L20.9047 11.3147C20.7564 11.2405 20.5847 11.2283 20.4274 11.2807C20.2701 11.3332 20.14 11.4459 20.0658 11.5942C19.9916 11.7425 19.9794 11.9142 20.0318 12.0715C20.0842 12.2289 20.197 12.3589 20.3453 12.4331L22.8453 13.6831C22.9936 13.7573 23.1653 13.7695 23.3226 13.7171C23.4799 13.6647 23.61 13.5519 23.6842 13.4036C23.7584 13.2553 23.7706 13.0836 23.7182 12.9263C23.6658 12.769 23.553 12.6389 23.4047 12.5647V12.5647ZM4.375 11.2487C4.27794 11.2489 4.18223 11.2715 4.09531 11.3147L1.59531 12.5647C1.44701 12.6389 1.33425 12.769 1.28183 12.9263C1.25588 13.0042 1.24552 13.0864 1.25135 13.1683C1.25719 13.2502 1.27909 13.3302 1.31582 13.4036C1.35255 13.477 1.40338 13.5425 1.46542 13.5963C1.52745 13.6501 1.59947 13.6911 1.67737 13.7171C1.83469 13.7695 2.00638 13.7573 2.15469 13.6831L4.65469 12.4331C4.78083 12.3702 4.88202 12.2666 4.94183 12.1389C5.00164 12.0113 5.01656 11.8672 4.98417 11.7301C4.95178 11.5929 4.87397 11.4707 4.76339 11.3833C4.65281 11.2959 4.51594 11.2485 4.375 11.2487V11.2487Z" /></svg></p>
        <p class="dark night"><svg class="night" width="20" viewBox="0 0 25 21" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M6.39614 3.72646C7.50591 1.56178 9.72622 0.00900831 12.4782 0.00114817C13.8006 -0.00388798 15.0965 0.375153 16.2101 1.09278C17.3237 1.8104 18.2079 2.83612 18.7564 4.04682C19.3049 5.25751 19.4945 6.60175 19.3024 7.91818C19.1103 9.23461 18.5447 10.4673 17.6735 11.4683C17.5227 11.6416 17.3516 11.859 17.1739 12.1069L9.47856 6.12184C9.65443 5.45016 10.046 4.85578 10.5924 4.43118C11.1387 4.00657 11.8093 3.77554 12.4997 3.77401C12.6654 3.77401 12.8244 3.70776 12.9416 3.58984C13.0588 3.47191 13.1247 3.31197 13.1247 3.1452C13.1247 2.97843 13.0588 2.81849 12.9416 2.70057C12.8244 2.58264 12.6654 2.51639 12.4997 2.51639C11.6212 2.5173 10.7634 2.78383 10.0374 3.28141C9.31146 3.77899 8.75092 4.48463 8.42856 5.30674L6.39614 3.72646ZM6.39614 10.0841C6.64968 10.5817 6.96225 11.0465 7.327 11.4683C7.97231 12.2091 8.98169 13.7568 9.36645 15.0624C9.36645 15.0726 9.36919 15.0828 9.37075 15.093H12.8372L6.39614 10.0841ZM9.37466 16.3502V17.8574C9.37584 18.1045 9.44934 18.3458 9.58599 18.5511L10.2536 19.5607C10.3675 19.7335 10.5221 19.8753 10.7037 19.9734C10.8852 20.0715 11.0881 20.1229 11.2942 20.1231H13.7047C13.9107 20.1231 14.1135 20.0718 14.2951 19.9739C14.4766 19.876 14.6313 19.7345 14.7454 19.5619L15.4129 18.5511C15.5492 18.3451 15.622 18.1033 15.6223 17.8558V17.2581L14.4528 16.3502H9.37466Z"/>
            <path class="night" d="M0.131556 1.2363L0.898352 0.243172C0.948738 0.177883 1.01142 0.123229 1.08282 0.0823368C1.15423 0.0414448 1.23294 0.0151171 1.31446 0.00486006C1.39598 -0.00539702 1.47872 0.000617709 1.55793 0.0225602C1.63714 0.0445026 1.71127 0.0819422 1.77609 0.132737L24.7585 18.0039C24.8894 18.1062 24.9745 18.2567 24.9952 18.4221C25.0158 18.5876 24.9703 18.7545 24.8687 18.8862L24.1015 19.8794C24.0511 19.9446 23.9884 19.9992 23.917 20.0401C23.8457 20.0809 23.767 20.1072 23.6855 20.1175C23.6041 20.1277 23.5214 20.1217 23.4422 20.0998C23.363 20.0779 23.2889 20.0405 23.2241 19.9898L0.241322 2.1186C0.110489 2.01624 0.0254259 1.86578 0.00484145 1.70032C-0.015743 1.53486 0.0298368 1.36795 0.131556 1.2363V1.2363Z"/>
            </svg></p>
        </div>
    </label>
</div>
          </li>
          <li>
            <a href="./">
              <div class="left">
                首页
              </div>  
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><g><rect x="83.534" y="40.929" width="3.997" height="20.071"/></g><path d="M16.466,41.931l33.548-25.123L92.81,48.877l2.396-3.198L50.015,11.814L4.794,45.679l2.396,3.199l5.279-3.954v42.763h75.062  V61h-3.997v22.69H64.598V54.068H35.402V83.69H16.466V41.931z M39.399,58.065h21.202V83.69H39.399V58.065z"/></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./archive.html">
              <div class="left">
                文章
              </div>
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="-3 3 64 64"><g><path d="M60.992,31.985c0-15.979-13-28.978-28.979-28.978c-15.994,0-29.006,12.999-29.006,28.978   c0,15.994,13.012,29.007,29.006,29.007v-2c-14.891,0-27.006-12.115-27.006-27.007c0-14.875,12.115-26.978,27.006-26.978   c14.876,0,26.979,12.103,26.979,26.978c0,8.945-4.479,17.329-11.804,22.338l0.874-10.062l-1.992-0.174l-1.135,13.071l13.042,1.136   l0.174-1.992l-9.183-0.799C56.443,50.079,60.992,41.321,60.992,31.985z"/><polygon points="33.014,12.682 31.014,12.682 31.014,32.398 39.811,41.224 41.227,39.812 33.014,31.572  "/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./tags.html">
              <div class="left">
                标签
              </div>
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><g><path d="M75.244,15.066c-2.59,0-5.027,1.012-6.857,2.843c-3.781,3.785-3.778,9.94,0.002,13.724    c1.831,1.833,4.266,2.843,6.857,2.843s5.026-1.01,6.861-2.843c3.781-3.785,3.781-9.943-0.002-13.724    C80.275,16.076,77.838,15.066,75.244,15.066z M78.766,28.252c-1.871,1.869-5.129,1.869-6.996,0c-1.929-1.931-1.931-5.069-0.002-7    c0.934-0.934,2.175-1.448,3.498-1.448c1.322,0,2.564,0.515,3.5,1.448C80.691,23.183,80.691,26.321,78.766,28.252z M94.632,41.027    l0.005-28.872c0-3.745-3.05-6.792-6.792-6.792L58.973,5.368l-1.237-0.004c-1.893,0-4.75,0-6.617,1.869L7.008,51.342    c-1.06,1.059-1.645,2.467-1.645,3.966s0.583,2.908,1.644,3.968l33.717,33.717c1.058,1.06,2.467,1.645,3.966,1.645    s2.908-0.585,3.968-1.645l44.106-44.111c1.893-1.886,1.88-4.604,1.869-7.227L94.632,41.027z M90.022,46.139L45.913,90.25    c-0.654,0.65-1.792,0.652-2.443,0L9.752,56.532c-0.328-0.327-0.507-0.762-0.507-1.225c0-0.462,0.18-0.894,0.507-1.221    L53.861,9.976c0.676-0.674,2.284-0.731,3.874-0.731l1.237,0.004l28.872-0.004c1.604,0,2.909,1.306,2.909,2.911l-0.005,28.872    l0.005,0.642C90.76,43.585,90.769,45.392,90.022,46.139z"/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="./about.html">
              <div class="left">
                关于
              </div>
              <div class="right">
                <svg width='24px' aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 846.66 846.66"><g><path d="M351.26 453.22c-276.42,134.06 -224.86,336.22 -224.73,336.8 6.03,25.41 -32.58,34.56 -38.6,9.15 -0.15,-0.65 -55.78,-219.32 218.87,-367.66 -60.98,-39 -100.02,-106.82 -100.02,-182.56 0,-119.6 96.95,-216.55 216.55,-216.55 119.6,0 216.55,96.95 216.55,216.55 0,75.74 -39.04,143.56 -100.02,182.56 274.65,148.34 219.02,367.01 218.87,367.66 -6.02,25.41 -44.63,16.26 -38.6,-9.15 0.13,-0.58 51.69,-202.74 -224.73,-336.8 -22.55,7.96 -46.8,12.29 -72.07,12.29 -25.27,0 -49.52,-4.33 -72.07,-12.29zm72.07 -381.14c-97.68,0 -176.87,79.19 -176.87,176.87 0,97.69 79.19,176.87 176.87,176.87 97.68,0 176.87,-79.18 176.87,-176.87 0,-97.68 -79.19,-176.87 -176.87,-176.87z"/></g></svg>
              </div>
            </a>
          </li>
          <!-- <li>
            <a href="./feed.xml">
              <div class="left">
                Atom feed
              </div>
              <div class="right">
                <svg width='24px' aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M80 352c26.467 0 48 21.533 48 48s-21.533 48-48 48-48-21.533-48-48 21.533-48 48-48m0-32c-44.183 0-80 35.817-80 80s35.817 80 80 80 80-35.817 80-80-35.817-80-80-80zm367.996 147.615c-6.448-237.848-198.06-429.164-435.61-435.61C5.609 31.821 0 37.229 0 44.007v8.006c0 6.482 5.146 11.816 11.626 11.994 220.81 6.05 398.319 183.913 404.367 404.367.178 6.48 5.512 11.626 11.994 11.626h8.007c6.778 0 12.185-5.609 12.002-12.385zm-144.245-.05c-6.347-158.132-133.207-284.97-291.316-291.316C5.643 175.976 0 181.45 0 188.247v8.005c0 6.459 5.114 11.72 11.567 11.989 141.134 5.891 254.301 119.079 260.192 260.192.269 6.453 5.531 11.567 11.989 11.567h8.005c6.798 0 12.271-5.643 11.998-12.435z"></path></svg>
              </div>
            </a>
          </li> -->
        </ul>
      </nav>
      
      
      <div class="logo"><a href="./"><img class="logo" id="logo" src="./assets/img/branding/MVM-logo-full.svg" alt="凡人炼丹传"></a></div>
      <div class="search-icon-container">
        <span class="search-icon"><a><i class="fa fa-search" aria-hidden="true"></i></a></span>
      </div>
    </div>
  </div>
</header> <!-- End Header -->

  <div class="content wrapper">
    






	
	<div id="CV" class="hidden tag-master">
		<h1>CV</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html">Jetson Xavier NX 的使用记录</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-08-25T05:11:00+08:00">August 25, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-远程桌面">一. 远程桌面</h3> <blockquote> <p>在windows10远程上操作jetson Xavier，远程的前提：jetson xavier和Windows的PC在同一个局域网内（我这里是直接在windows10上开启热点）。</p> </blockquote> <ul> <li>安装xrdp：<code class="language-plaintext highlighter-rouge">sudo apt-get install xrdp vnc4server xbase-clients</code></li> </ul> <h4 id="11桌面共享没反应">1.1：桌面共享没反应</h4> <blockquote> <p>桌面共享其实就是一个vnc-server（因此没有必要再在linux上安装vnc-server了），如果要远程，必须要先开启共享，允许其他人控制自己电脑。</p> </blockquote> <p>这里发现<strong>双击了桌面共享，没反应</strong>。</p> <p><strong>解决方案</strong>：</p> <ul> <li>安装dconf-editor：<code class="language-plaintext highlighter-rouge">sudo apt-get install dconf-editor</code></li> <li>运行dconf-editor，更改系统配置，org ==&gt; gnome ==&gt; desktop ==&gt; remote-access，关闭以下两个：<code class="language-plaintext highlighter-rouge">promotion-enabled</code>和<code class="language-plaintext highlighter-rouge">requre-encryption</code></li> <li>开启桌面共享：<code class="language-plaintext highlighter-rouge">/usr/lib/vino/vino-server</code></li> </ul> <h4 id="12-开启远程">1.2 开启远程</h4> <ul> <li>在Windows10上安装vnc-client，官网地址：https://www.realvnc.com/en/connect/download/viewer/windows/</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_1.png" alt="" /></p> <ul> <li> <p>输入linux的ip后，直接连接即可。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jet_2.png" alt="" /></p> </li> </ul> <h4 id="13-建立双击可执行文件desktop">1.3 建立双击可执行文件.desktop</h4> <blockquote> <p>由于每次我开启远程桌面的时候，都需要在命令行输入相关指令，很麻烦，就想说有没有可以直接在像windows一样快捷方式</p> </blockquote> <ul> <li> <p>写一个shell脚本来开启桌面共享：<code class="language-plaintext highlighter-rouge">vim ~/vnc-server.sh</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span> /usr/lib/vino/vino-server </code></pre></div> </div> </li> <li> <p>在桌面上新建一个.desktop文件：<code class="language-plaintext highlighter-rouge">vim ~/Desktop/vnc-server.desktop</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Desktop Entry]...<a class="read-more" href="./JetsonXavierNX%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html">ZED2相机api使用心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-08-25T05:11:00+08:00">August 25, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-zed相机的选型">一. ZED相机的选型</h3> <blockquote> <p>STEREOLABS（ZED相机厂家）的官网：https://www.stereolabs.com/zed/</p> </blockquote> <p>ZED双目相机有以下四种型号：</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_1.png" alt="" /></p> <p><a href="https://www.stereolabs.com/zed-2i/">ZED 2i</a>：ZED相机最新款（ZED相机二代的进阶版，<strong>防尘防水</strong>）</p> <p><a href="https://www.stereolabs.com/zed-2i/">ZED 2</a> ：ZED相机二代（相较于1代多了<strong>支持IMU</strong>）</p> <p><a href="https://www.stereolabs.com/zed-mini/">ZED mini</a>：功能上和二代基本一致，<strong>尺寸更小</strong>，<strong>性能上要差</strong>，比如这里支持的景深在15m以内，而二代的景深最大支持20m。</p> <p><a href="https://www.stereolabs.com/zed/">ZED</a>：ZED相机一代，支持2K视频，景深范围在(0.3m,25m)，<strong>无IMU</strong>,所以对于需要玩SLAM的这款就不推荐了。</p> <h3 id="二-安装zed的sdk">二. 安装ZED的SDK</h3> <h4 id="21-安装sdk">2.1 安装SDK</h4> <blockquote> <p>ZED相机SDK官网：https://www.stereolabs.com/developers/release/</p> </blockquote> <p>我们可以看到是，所有的SDK基本都需要你<strong>安装cuda</strong>，因此我选择了cuda11.0进行安装，具体的cuda安装过程可参考我之前的一篇博客：<a href="https://www.lixiaofei2yy.website/windows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BAcuda10.1%E5%92%8Cpytorch1.6">Windows10环境下搭建CUDA10.1和pytorch1.6</a>。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_2.png" alt="" /></p> <p>直接安装即可，将下载下来的exe双击运行<code class="language-plaintext highlighter-rouge">ZED_SDK_Windows10_cuda11.0_v3.5.2_4.exe</code>即可，如下图所示</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_3.png" alt="" /></p> <p>一直往下走即可。</p> <h4 id="22-安装python-api">2.2 安装python API</h4> <p>安装完成之后，可以在 <code class="language-plaintext highlighter-rouge">C:\Program Files (x86)\ZED SDK\</code>下看到<code class="language-plaintext highlighter-rouge">get_python_api.py</code>，如下图</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/zed_4.png" alt="" /></p> <p>直接进行安装python的api：<code class="language-plaintext highlighter-rouge">python get_python_api.py</code></p> <h3 id="三-python-api的使用">三. python API的使用</h3> <ul> <li> <p>导入zed的python包</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyzed.sl</span> <span class="k">as</span> <span class="n">sl</span> </code></pre></div> </div> </li> <li> <p>查看zed相机版本，这里说下，如果检测到是ZED一代的化，是不支持拿IMU数据的。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zed</span> <span class="o">=</span> <span...<a class="read-more" href="./ZED2%E7%9B%B8%E6%9C%BAapi%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html">Mask_RCNN在TF2下跑通自己的数据集</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-07-26T20:11:00+08:00">July 26, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>论文原文地址：https://arxiv.org/abs/1703.06870</p> <p>MaskRCNN官方的git地址：https://github.com/matterport/Mask_RCNN</p> </blockquote> <h3 id="一-构建数据集">一. 构建数据集</h3> <p>这里参考官方推荐的气球语义分割的<a href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46">例子</a>，这里选用的是和他一致的打标工具 <a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA (VGG Image Annotator)</a>。个人感觉这个比<a href="https://github.com/wkentaro/labelme">labeme</a>好用太多。</p> <ul> <li>直接在<a href="https://www.robots.ox.ac.uk/~vgg/software/via/">VIA官网</a>下载即可，下载完成后如下图所示，直接用浏览器打开<code class="language-plaintext highlighter-rouge">via.html</code>即可开箱使用。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_1.png" alt="" /></p> <ul> <li>选择<code class="language-plaintext highlighter-rouge">Add Files</code>添加图片后，选择<code class="language-plaintext highlighter-rouge">Attributes</code>设置打标的label，然后用多边形工具进行打标，如下图。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_2.png" alt="" /></p> <ul> <li>输出json格式的打标结果</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rcnn_3.png" alt="" /></p> <ul> <li>将图片和json结果保存在同一个目录下，构建自己的数据集时可参考我的目录结构。</li> </ul> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">├─dataset</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">├─train</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">├─</span><span class="mi">1</span><span class="err">.jpg</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">├─</span><span class="mi">2</span><span class="err">.jpg</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">├─</span><span class="mi">3</span><span class="err">.jpg</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span...<a class="read-more" href="./Mask_RCNN%E5%9C%A8TF2%E4%B8%8B%E8%B7%91%E9%80%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="LLM" class="hidden tag-master">
		<h1>LLM</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul> <li>训练的内容分为2块： <ul> <li>找到核心依据：QA对 + 标准答案的文档 + 多个误导的文档 + 思维链</li> <li>正确的例子：QA对 + 标准答案的文档 + 思维链</li> </ul> </li> <li>训练的核心：通过思维链来解释找到的答案，从而基于上下文信息，思考其答案，并链接到相关文档。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft_train.png" alt="raft_train" /></p> <h3 id="二-基于unsloth和lamma_index来实现faft">二. 基于unsloth和lamma_index来实现FAFT</h3> <h4 id="21-基于ollama和lamma_index来构建数据集">2.1 基于ollama和lamma_index来构建数据集</h4> <p>RAFT的数据集的特点是：</p> <ul> <li>QA对</li> <li>正确文档</li> <li>错误文档</li> <li>思维链</li> </ul> <p>所以我们需要一个能够提供思维链的大模型，帮助我们生成上述这些内容。</p> <ul> <li>模型：Qwen3-32B，选择这个千问模型是因为中文很友好+支持思维链+阿里的预训练的数据很顶</li> <li>调用框架：ollama，调用比如openai需要花钱，这个本地部署，调用不花钱！</li> </ul> <h4 id="22-安装相关依赖">2.2 安装相关依赖</h4> <p>这里需要使用以下几个深度学习相关的框架：</p> <ul> <li>lamma_index: 和langchain感觉很像，只是这个更加偏重于增强大型语言模型 (LLM) 处理广泛和异构数据集的能力。当然也能帮助我们构建raft数据集咯。</li> <li>unsloth:...<a class="read-more" href="./raft.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a></p> </blockquote> <p>GraphRAG比RAG优势在哪：</p> <ul> <li>RAG过于局限：RAG仅能检索到与query相速度最高的文本片段，无法从全局出发来看整个本地文本。</li> <li>GraphRAG通过构建实体关系图谱实现了信息间的连接，能从全局出发，能更完整地理解和检索复杂的关联信息，从而生成更准确和全局性的结果。</li> </ul> <h4 id="14-graphrag的流程">1.4 GraphRAG的流程</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/graphrag.png" alt="LangChain" /> 如上图所示，就是GraphRAG的处理流程图，其实总结起来就两个部分： 第一部分：构建知识图谱</p> <ul> <li>将本地文本进行分段</li> <li>对每个段落进行摘要提取：这里完全依赖于<strong>大模型的提取能力</strong></li> <li>实体和关系的提取：这里完全依赖于<strong>大模型的提取能力</strong>，实体和关系抽取可以参考本人之前写的《事件抽取实战》这篇文章</li> <li>构建知识图谱，写入数据库</li> </ul> <p>第二部分：利用构建的知识图谱回答问题</p> <ul> <li>社区检测：实际就是一种图聚类的方法，这里的“社区”，我们可以将其理解为一类具有相同特性的节点的集合。</li> <li>社区总结：给每个社区创建类似报告的摘要。利于理解整体的结构和语义。</li> <li>生成全局答案：给定用户查询，基于上一步生成的社区摘要可用于在多阶段过程中生成最终答案。</li> </ul> <h3 id="二-graphrag的轻量版本nano-graphrag">二. GraphRAG的轻量版本——nano-GraphRAG</h3> <p>对于GraphRAG而言，其封装的太死，代码量又很大，对于定制化的任务而言，不太好下手，因此推荐一个轻量化的版本——nano-GraphRAG。</p> <blockquote> <p>代码：https://github.com/gusye1234/nano-graphrag</p> </blockquote> <p>相较于GraphRAG的优势：</p> <ul> <li>代码量少：包含了tests + prompt也才只有1100行代码！</li> <li>更容易阅读</li> <li>给的例子太好用了，直接上手没有难度。</li> </ul> <h4 id="21-安装">2.1 安装</h4> <p>这里推荐不用官方推荐的pip install 来安装。因为这样会对于代码和prompt不好调整。 直接clone项目即可，然后安装其依赖<code...<a class="read-more" href="./graphrag.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1 依赖的安装</h4> <blockquote> <p>这里爬了不少坑，因此记录下</p> </blockquote> <ol> <li>直接pip安装：<code class="language-plaintext highlighter-rouge">pip install unsloth</code>, 这里会默认安装最新的torch版本，而非适配于自身系统cuda版本的torch（用<code class="language-plaintext highlighter-rouge">nvcc -V</code>可查看cuda版本）</li> <li>重新安装torch，本人这里cuda是12.1的：<code class="language-plaintext highlighter-rouge">pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121</code></li> <li>重新安装对应cuda版本的xformers：<code class="language-plaintext highlighter-rouge">pip install -U xformers --index-url https://download.pytorch.org/whl/cu121</code></li> <li>如果需要微调Qwen3，那么对于transformers有版本要求：<code class="language-plaintext highlighter-rouge">pip install transformers==4.51.0 --no-deps</code></li> <li>改了transformers之后，那么也需要对应的trl版本更改：<code class="language-plaintext highlighter-rouge">pip install trl==0.17.0 --no-deps</code></li> <li>安装vllm:<code class="language-plaintext highlighter-rouge">pip install vllm==0.7 --no-deps</code></li> <li>这里会遇到unsloth和vllm版本不匹配的问题：<code...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="NLP" class="hidden tag-master">
		<h1>NLP</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul> <li>训练的内容分为2块： <ul> <li>找到核心依据：QA对 + 标准答案的文档 + 多个误导的文档 + 思维链</li> <li>正确的例子：QA对 + 标准答案的文档 + 思维链</li> </ul> </li> <li>训练的核心：通过思维链来解释找到的答案，从而基于上下文信息，思考其答案，并链接到相关文档。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft_train.png" alt="raft_train" /></p> <h3 id="二-基于unsloth和lamma_index来实现faft">二. 基于unsloth和lamma_index来实现FAFT</h3> <h4 id="21-基于ollama和lamma_index来构建数据集">2.1 基于ollama和lamma_index来构建数据集</h4> <p>RAFT的数据集的特点是：</p> <ul> <li>QA对</li> <li>正确文档</li> <li>错误文档</li> <li>思维链</li> </ul> <p>所以我们需要一个能够提供思维链的大模型，帮助我们生成上述这些内容。</p> <ul> <li>模型：Qwen3-32B，选择这个千问模型是因为中文很友好+支持思维链+阿里的预训练的数据很顶</li> <li>调用框架：ollama，调用比如openai需要花钱，这个本地部署，调用不花钱！</li> </ul> <h4 id="22-安装相关依赖">2.2 安装相关依赖</h4> <p>这里需要使用以下几个深度学习相关的框架：</p> <ul> <li>lamma_index: 和langchain感觉很像，只是这个更加偏重于增强大型语言模型 (LLM) 处理广泛和异构数据集的能力。当然也能帮助我们构建raft数据集咯。</li> <li>unsloth:...<a class="read-more" href="./raft.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a></p> </blockquote> <p>GraphRAG比RAG优势在哪：</p> <ul> <li>RAG过于局限：RAG仅能检索到与query相速度最高的文本片段，无法从全局出发来看整个本地文本。</li> <li>GraphRAG通过构建实体关系图谱实现了信息间的连接，能从全局出发，能更完整地理解和检索复杂的关联信息，从而生成更准确和全局性的结果。</li> </ul> <h4 id="14-graphrag的流程">1.4 GraphRAG的流程</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/graphrag.png" alt="LangChain" /> 如上图所示，就是GraphRAG的处理流程图，其实总结起来就两个部分： 第一部分：构建知识图谱</p> <ul> <li>将本地文本进行分段</li> <li>对每个段落进行摘要提取：这里完全依赖于<strong>大模型的提取能力</strong></li> <li>实体和关系的提取：这里完全依赖于<strong>大模型的提取能力</strong>，实体和关系抽取可以参考本人之前写的《事件抽取实战》这篇文章</li> <li>构建知识图谱，写入数据库</li> </ul> <p>第二部分：利用构建的知识图谱回答问题</p> <ul> <li>社区检测：实际就是一种图聚类的方法，这里的“社区”，我们可以将其理解为一类具有相同特性的节点的集合。</li> <li>社区总结：给每个社区创建类似报告的摘要。利于理解整体的结构和语义。</li> <li>生成全局答案：给定用户查询，基于上一步生成的社区摘要可用于在多阶段过程中生成最终答案。</li> </ul> <h3 id="二-graphrag的轻量版本nano-graphrag">二. GraphRAG的轻量版本——nano-GraphRAG</h3> <p>对于GraphRAG而言，其封装的太死，代码量又很大，对于定制化的任务而言，不太好下手，因此推荐一个轻量化的版本——nano-GraphRAG。</p> <blockquote> <p>代码：https://github.com/gusye1234/nano-graphrag</p> </blockquote> <p>相较于GraphRAG的优势：</p> <ul> <li>代码量少：包含了tests + prompt也才只有1100行代码！</li> <li>更容易阅读</li> <li>给的例子太好用了，直接上手没有难度。</li> </ul> <h4 id="21-安装">2.1 安装</h4> <p>这里推荐不用官方推荐的pip install 来安装。因为这样会对于代码和prompt不好调整。 直接clone项目即可，然后安装其依赖<code...<a class="read-more" href="./graphrag.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1 依赖的安装</h4> <blockquote> <p>这里爬了不少坑，因此记录下</p> </blockquote> <ol> <li>直接pip安装：<code class="language-plaintext highlighter-rouge">pip install unsloth</code>, 这里会默认安装最新的torch版本，而非适配于自身系统cuda版本的torch（用<code class="language-plaintext highlighter-rouge">nvcc -V</code>可查看cuda版本）</li> <li>重新安装torch，本人这里cuda是12.1的：<code class="language-plaintext highlighter-rouge">pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121</code></li> <li>重新安装对应cuda版本的xformers：<code class="language-plaintext highlighter-rouge">pip install -U xformers --index-url https://download.pytorch.org/whl/cu121</code></li> <li>如果需要微调Qwen3，那么对于transformers有版本要求：<code class="language-plaintext highlighter-rouge">pip install transformers==4.51.0 --no-deps</code></li> <li>改了transformers之后，那么也需要对应的trl版本更改：<code class="language-plaintext highlighter-rouge">pip install trl==0.17.0 --no-deps</code></li> <li>安装vllm:<code class="language-plaintext highlighter-rouge">pip install vllm==0.7 --no-deps</code></li> <li>这里会遇到unsloth和vllm版本不匹配的问题：<code...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="代码" class="hidden tag-master">
		<h1>代码</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./taskflow.html">Taskflow 使用小结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-04-07T08:00:00+08:00">April 7, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-taskflow的优势和完整的工作流">一. TaskFlow的优势和完整的工作流</h3> <p>TaskFlow是OpenStack开源的Python库，他的优势：</p> <ul> <li>可伸缩</li> <li>简单创建任务级对象</li> <li>任务可插拔</li> <li>支持回滚容错机制</li> </ul> <p>api的文档参考：https://docs.openstack.org/taskflow/ocata/</p> <p>一个完整的taskflow包含了一下几个环节：</p> <ul> <li>创建task</li> <li>声明flow</li> <li>构建engine</li> </ul> <h4 id="11-构建task">1.1 构建task</h4> <p>构建task的方式是继承task类，然后修改其excute方法，这里可以指定任务的返回结果为res，注意还可以改写revert函数来重定义回滚的操作。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">taskflow</span> <span class="kn">import</span> <span class="n">task</span> <span class="k">class</span> <span class="nc">TaskA</span><span class="p">(</span><span class="n">task</span><span class="p">.</span><span class="n">Task</span><span class="p">):</span> <span class="n">default_provides</span> <span class="o">=</span> <span class="sh">'</span><span class="s">res</span><span class="sh">'</span> <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span> <span class="n">res</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">a</span> <span class="k">return</span> <span class="n">res</span> <span class="k">def</span> <span class="nf">revert</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">a执行失败。。。</span><span class="sh">"</span><span class="p">)</span> </code></pre></div></div> <h4 id="12-构建flow">1.2 构建flow</h4> <p>在构建完task之后，则是需要定义flow，一般的线性flow的定义如下：</p> <div class="language-python...<a class="read-more" href="./taskflow.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html">pyspark使用总结-第二篇</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-07T08:00:00+08:00">November 7, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-常见的oom">一. 常见的OOM</h3> <h4 id="11-常用的解决方案">1.1 常用的解决方案</h4> <p>我们在使用spark的时候，经常在save数据的时候，都会遇到内存溢出的问题，这通常是由于数据量过大导致的。以下是一些可能的解决方案：</p> <ol> <li>增加分区数：如果数据集非常大，可以尝试增加分区数。可以使用<code class="language-plaintext highlighter-rouge">repartition()</code>或<code class="language-plaintext highlighter-rouge">coalesce()</code>函数来增加分区数。增加分区数可以将数据均匀地分布在更多的节点上，从而减少每个节点上的内存压力。</li> <li>压缩数据：如果数据集包含大量重复的值，可以考虑使用压缩算法来减少内存使用。Pyspark提供了多种压缩算法，如Snappy、Gzip等。可以使用<code class="language-plaintext highlighter-rouge">option("compression", "snappy")</code>来设置压缩算法。</li> <li>增加集群资源：可以考虑增加集群资源。可以增加集群的节点数或增加每个节点的内存。可以通过调整<code class="language-plaintext highlighter-rouge">spark.driver.memory</code>和<code class="language-plaintext highlighter-rouge">spark.executor.memory</code>参数来增加内存分配，特别对于driver而言，最好把内存设置大一些。</li> </ol> <h4 id="12-代码方面的优化">1.2 代码方面的优化</h4> <p>如果以上常用的解决方案依旧无法解决OOM的问题，那么我们可能需要考虑是否需要优化pyspark的代码了</p> <ul> <li>UDF过于复杂：尽可能将结果拆分不同的列，然后再用简单的udf来组合这些列进行计算。</li> <li>多用filter算子：提前将大量数据剔除</li> <li>多用select算子：只保留需要的列，减少内存的使用</li> <li>尽量少用collect、count算子：像这些action算子基本都会把executor的数据全部加载回driver上，导致driver的内存吃紧。</li> <li>当发现在某个udf环节只有一个节点在跑的时候，可以使用.cache()来分布式跑任务。</li> </ul> <h4 id="13-数据倾斜导致的oom和心跳时间超时">1.3 数据倾斜导致的OOM和心跳时间超时</h4> <p>通常我们会发现有些时候，数据本身并没有很大，但是要运行很长时间，而且最终还因为heart beat时间过长或则oom而失败。</p> <p><strong>发生</strong> 数据倾斜一般发生在：</p> <ul> <li>join两个df的时候</li> <li>groupby某一列，然后这一列（包含了a，b，c等元素）中，很不巧，a有非常多（1000），而b和c等元素仅有2个</li> </ul> <p><strong>验证</strong> 这时候我们可以直接通过yarn日志中的shuffer resize/records看到很多excutors中会发现极个别失败的excutor的size非常大（10w个），而其他的excutor的size可能只有10个。那么这个时候无疑是发生数据倾斜了。</p> <p><strong>解决</strong> 这里推荐使用<strong>加盐</strong>处理，比什么加excutor的内存和核数更加有效</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">salted_a</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">lit</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html">配置python远程环境</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2023-12-28T08:00:00+08:00">December 28, 2023</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>由于工作基本基于python，所以本文主要记录配置远程linux的python环境</p> </blockquote> <h3 id="一-定义docker位置">一. 定义Docker位置</h3> <blockquote> <p>为什么要修改docker存储的位置？ 因为往往docker的缓存过大，导致最后打的镜像多了，最后占满空间了</p> </blockquote> <p>步骤：</p> <ul> <li>获取当前docker所在存储位置：<code class="language-plaintext highlighter-rouge">docker info | grep "Docker Root Dir"</code></li> <li>停止docker服务：<code class="language-plaintext highlighter-rouge">systemctl stop docker</code></li> <li>移动整个路径至新路径：<code class="language-plaintext highlighter-rouge">mv /var/lib/docker /data/docker</code></li> <li>创建软连接：<code class="language-plaintext highlighter-rouge">ln -s /data/docker /var/lib/docker</code></li> <li>重启docker服务：<code class="language-plaintext highlighter-rouge">systemctl start docker</code></li> <li>可以通过第一个命令查看现在的docker存储路径</li> </ul> <h3 id="二-安装python3或则conda">二. 安装python3或则conda</h3> <blockquote> <p>这里推荐安装conda，环境切换方便</p> </blockquote> <h4 id="21-python3的安装">2.1 python3的安装</h4> <h5 id="211-前期准备">2.1.1 前期准备</h5> <blockquote> <p>注意这里需要将openssl升级到1.0.2，因为不然pip3 安装包的时候会出现无法访问http请求。</p> </blockquote> <p>步骤：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#安装openssl 1.0.2r版本</span> <span class="nb">cd</span> /home/install wget http://www.openssl.org/source/openssl-1.0.2r.tar.gz <span class="c">#下载openssl包</span> <span class="nb">tar</span> <span class="nt">-zxvf</span> openssl-1.0.2r.tar.gz <span class="c">#解压</span> <span class="nb">cd </span>openssl-1.0.2r <span class="c">#进入文件夹</span> ./config shared zlib <span class="c">#配置</span> make <span class="o">&amp;&amp;</span> make <span class="nb">install</span> <span class="c">#解析和安装</span>...<a class="read-more" href="./%E9%85%8D%E7%BD%AEpython%E8%BF%9C%E7%A8%8B%E7%8E%AF%E5%A2%83.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="博客" class="hidden tag-master">
		<h1>博客</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./picgo%E4%B8%8B%E9%85%8D%E7%BD%AEgithub%E5%9B%BE%E5%BA%8A.html">picgo下配置github图床</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-01-20T19:11:00+08:00">January 20, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-必须的安装">一. 必须的安装</h3>
<ul>
  <li>picgo：强大的能快速创建图片url的工具（支持多种图床），简直不要太好用。我们可以直接在官网下载相应版本的<a href="https://picgo.github.io/PicGo-Doc/zh/guide/#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85">picgo</a>，我这里选用的是windows版本的，当然也有mac版本的。</li>
  <li>git：这里推荐用scoop进行安装<code class="language-plaintext highlighter-rouge">scoop install git</code></li>
</ul>

<h3 id="二-搭建属于自己的github图床">二. 搭建属于自己的github图床</h3>
<h4 id="21-新建一个共有仓库">2.1 新建一个共有仓库</h4>

<p>首先，要搭建一个github图床，我们需要创建一个<strong>共有仓库</strong>（注意：如果是创建私有仓库根本无法显示图片出来）来存储上传的图片。
<img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/new-rep.jpg" alt="" /></p>

<h4 id="22-创建admin分支">2.2 创建admin分支</h4>
<p>这里如果不会用git创建分支的同学可参考我上一篇文章<a href="https://www.lixiaofei2yy.website/git%E5%91%BD%E4%BB%A4">GIT命令学习</a>。</p>

<p>这里注意最好选择帮你添加一个README.md文件。</p>
<ul>
  <li>克隆刚创建的远程仓库：<code class="language-plaintext highlighter-rouge">git clone XX.git</code></li>
  <li>创建并切换到admin分支：<code class="language-plaintext highlighter-rouge">git checkout -b admin</code></li>
  <li>向远端仓库推送admin分支：<code class="language-plaintext highlighter-rouge">git push orgin admin</code></li>
</ul>

<p>这时，我们就可以在仓库中看到admin分支了，如下图。
<img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/admin.jpg" alt="" /></p>

<h4 id="23-设置token">2.3 设置token</h4>
<p>这里我们还需要设置token，直接点击该<a href="https://github.com/settings/tokens">链接</a>即可。注意，这里需要将repo选择。如下图所示。
<img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/token.jpg" alt="" />
然后点击generate token就完成了。</p>

<h3 id="三-在picgo下配置github图床">三. 在picgo下配置github图床</h3>
<p>记住上面刚刚配置好的token和仓库名字及分支名admin，按照下图进行配置即可。
<img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/picgo.jpg" alt="" /></p>

<p>至此，我们就可以愉快的上传图片咯！</p>

<a class="read-more" href="./picgo%E4%B8%8B%E9%85%8D%E7%BD%AEgithub%E5%9B%BE%E5%BA%8A.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Jasper2%E5%8D%9A%E5%AE%A2%E8%B7%9F%E6%96%B0.html">利用Jasper2主题和Netlify完善个人博客</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-11-27T04:21:00+08:00">November 27, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-更换jekyll主题">一. 更换Jekyll主题</h3> <ul> <li>之前用的是jekyll主题：<a href="https://github.com/artemsheludko/flexible-jekyll">Flexible-Jekyll</a>，如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jaster_1.jpg" alt="" /></p> <ul> <li>觉得有点过于单调和简单了，于是找到了命中注定：<a href="https://github.com/jekyller/jasper2">Jasper2</a>,如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jaster_2.jpg" alt="" /></p> <blockquote> <p>如果也想使用这个Jasper2主题的话，最好多读读其作者的readme哦！</p> </blockquote> <h4 id="11-在git仓库中推送生成好的html文件">1.1 在git仓库中推送生成好的html文件</h4> <p>​ 克隆Jasper2项目（master分支）到自己本地，然后利用jekyll开启本地预览模式：<code class="language-plaintext highlighter-rouge">bundle exec jekyll server</code>，这里你会发现在本地的上级目录下生成一个<code class="language-plaintext highlighter-rouge">jasper2-pages</code>文件夹。</p> <ul> <li>如果是和我一样是利用<code class="language-plaintext highlighter-rouge">username.github.io</code>建立的仓库，那么就直接在项目中新建一个<code class="language-plaintext highlighter-rouge">_site</code>文件夹，并将<code class="language-plaintext highlighter-rouge">jasper2-pages</code>内容复制到该目录下即可。</li> <li>如果是利用<code class="language-plaintext highlighter-rouge">github pages</code>来展示自己的项目的话，那就建立一个<code class="language-plaintext highlighter-rouge">gh-pages </code>分支，同时将<code class="language-plaintext highlighter-rouge">jasper2-pages</code>内容复制到该目录下即可。</li> </ul> <p>注意：每次跟新仓库代码后，都需要重新生成一次，并替换掉<code class="language-plaintext highlighter-rouge">_site</code>文件夹内容！</p> <h4 id="12-内容替换">1.2 内容替换</h4> <ul> <li><code class="language-plaintext highlighter-rouge">_config.yml</code>：用来修改主页上的一些个人信息</li> <li><code class="language-plaintext highlighter-rouge">about/index.md</code>：修改关于的个人说明</li> <li><code class="language-plaintext highlighter-rouge">_post</code>：将其中的文章替换掉自己文章</li> </ul> <h4 id="13-前端页面的修改">1.3 前端页面的修改</h4> <blockquote> <p>ps:本人也是个前端新手，也是根据李小肥的指导才知道怎么修改前端的，给你们撒狗粮，哈哈哈！</p> </blockquote> <p>这里就不讲修改细节部分了，主要讲述如何快速找到想要修改的代码，毕竟授人以鱼不如授人以渔嘛！</p> <ul> <li>进入到jasper2的<a href="https://jekyller.github.io/jasper2/">展示主页</a>，右键页面中的facebook图标点击<code class="language-plaintext highlighter-rouge">检查</code>,就可以看到以下界面：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jaster_3.jpg" alt="" /></p> <ul> <li>在这个check界面上可以看到有个<code class="language-plaintext highlighter-rouge">social-link social-link-fb</code>类，那么如果我们想要修改这些内容，可以直接在项目代码中全文搜索，就可以在<code class="language-plaintext highlighter-rouge">author.html</code>中找到咯，但是这和我们想修改图标或者是内容不符啊，那么就往这个类的上面继续找<code class="language-plaintext highlighter-rouge">site-nav-right</code>,这里就指向了我们想要修改的图标。</li> <li>如果还想修改css文件呢，可以看到上图中<code class="language-plaintext highlighter-rouge">Styles</code>下面中就是，还可以直接在这里修改，就可以同时在网页中预览哦！如何找这个css文件呢，旁边的<code class="language-plaintext highlighter-rouge">screen.css:279</code>就是，而且连行号都给你了！</li>...<a class="read-more" href="./Jasper2%E5%8D%9A%E5%AE%A2%E8%B7%9F%E6%96%B0.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Mac%E4%B8%8B%E5%88%A9%E7%94%A8jekyll%E5%92%8Cgithub-pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html">jekyll和github pages搭建个人博客</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-10-18T03:21:00+08:00">October 18, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-搭建环境">一. 搭建环境</h3> <h4 id="11-下载软件">1.1 下载软件</h4> <ul> <li><a href="https://www.jekyll.com.cn/">jekyll</a>：这个是将纯文本转化为静态网站和博客，使用gem安装下载：<code class="language-plaintext highlighter-rouge">gem install bundler jekyll</code>。</li> <li><a href="">github pages</a>：免费开源，并且可以自动生成域名，自己去构建一个属于自己的github账号和新建一个仓库（名字为：<code class="language-plaintext highlighter-rouge">XX.github.io</code>，这里<code class="language-plaintext highlighter-rouge">XX</code>就是你自己的账号名称）</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jek_1.jpg" alt="" /></p> <ul> <li>mac或者linux或者Windows平台。</li> </ul> <h4 id="12-选择一个适合自己的博客主题">1.2 选择一个适合自己的博客主题</h4> <blockquote> <p>jekyll主题：http://jekyllthemes.org/</p> <p>jekyll插件：http://www.jekyll-plugins.com/</p> </blockquote> <ul> <li>本人选择的jekyll主题：<a href="https://github.com/artemsheludko/flexible-jekyll">Flexible-Jekyll</a>，如下图所示：</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jek_2.jpg" alt="" /></p> <ul> <li>选择一个地方存放下载的主题（直接git下载）：<code class="language-plaintext highlighter-rouge">git clone https://github.com/artemsheludko/flexible-jekyll </code></li> <li>这里直接在本地利用jekyll生成一个网页进行测试和调试：<code class="language-plaintext highlighter-rouge">bundle exec jekyll server</code>或者是<code class="language-plaintext highlighter-rouge">bundle exec jekyll s</code>，这里会生成一个本地的博客地址：<code class="language-plaintext highlighter-rouge">http://127.0.0.1:4000/</code>，可以直接查看</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/jek_3.jpg" alt="" /></p> <h4 id="13-将主题放入自己的仓库中">1.3 将主题放入自己的仓库中</h4> <ul> <li>git下载创建好的xx.github.io该仓库到自己本地：<code class="language-plaintext highlighter-rouge">git clone https://github.com/xx/xx.github.io.git</code></li> <li>将之前下载的主题放到自己创建的github.io这个仓库中</li> <li>git上传修改的地方： <ul> <li>git添加修改的地方：<code class="language-plaintext highlighter-rouge">git add .</code></li> <li>git提交：<code class="language-plaintext highlighter-rouge">git commit -m "修改"</code></li> <li>git推送：<code class="language-plaintext highlighter-rouge">git push</code></li> </ul> </li> <li>这里可以直接在网页上打开<code class="language-plaintext...<a class="read-more" href="./Mac%E4%B8%8B%E5%88%A9%E7%94%A8jekyll%E5%92%8Cgithub-pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="图算法" class="hidden tag-master">
		<h1>图算法</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.html">GCN在多标签分类中的应用</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-01-11T04:21:00+08:00">January 11, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一--torch的图神经网络库pyg">一. Torch的图神经网络库pyG</h3> <blockquote> <p>torch_geometric 官方文档：https://pytorch-geometric.readthedocs.io/en/latest/index.html</p> </blockquote> <h4 id="11-安装及使用">1.1 安装及使用</h4> <p>这里参考官网的安装过程。</p> <ol> <li> <p>确定自己安装的pytorch版本：<code class="language-plaintext highlighter-rouge">pip list</code>进行查看，例如本人的torch版本为<code class="language-plaintext highlighter-rouge">1.6.0+cu101</code>（这里的<code class="language-plaintext highlighter-rouge">cu101</code>是指cuda10.1）</p> </li> <li> <p>安装相关的第三方包，这里注意要匹配上面的torch版本，因此：<code class="language-plaintext highlighter-rouge">${TORCH} = 1.6.0</code>，<code class="language-plaintext highlighter-rouge">${CUDA} = cu101</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">--no-index</span> torch-scatter <span class="nt">-f</span> https://pytorch-geometric.com/whl/torch-<span class="k">${</span><span class="nv">TORCH</span><span class="k">}</span>+<span class="k">${</span><span class="nv">CUDA</span><span class="k">}</span>.html pip <span class="nb">install</span> <span class="nt">--no-index</span> torch-sparse <span class="nt">-f</span> https://pytorch-geometric.com/whl/torch-<span class="k">${</span><span class="nv">TORCH</span><span class="k">}</span>+<span class="k">${</span><span class="nv">CUDA</span><span class="k">}</span>.html pip <span class="nb">install</span> <span class="nt">--no-index</span> torch-cluster <span class="nt">-f</span> https://pytorch-geometric.com/whl/torch-<span class="k">${</span><span class="nv">TORCH</span><span class="k">}</span>+<span class="k">${</span><span class="nv">CUDA</span><span class="k">}</span>.html pip <span class="nb">install</span> <span class="nt">--no-index</span> torch-spline-conv <span class="nt">-f</span> https://pytorch-geometric.com/whl/torch-<span class="k">${</span><span class="nv">TORCH</span><span class="k">}</span>+<span class="k">${</span><span class="nv">CUDA</span><span class="k">}</span>.html pip <span class="nb">install </span>torch-geometric...<a class="read-more" href="./GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./Neo4j%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%9B%BE%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E7%BB%93%E5%90%88.html">Neo4j数据库与图数据挖掘算法结合</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-02-27T23:21:00+08:00">February 27, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-环境准备">一. 环境准备</h3> <ul> <li> <p>neo4j python包：<code class="language-plaintext highlighter-rouge">pip3 install neo4j</code> 和<code class="language-plaintext highlighter-rouge">pip3 install py2neo</code>（这里的py2neo 是python对Neo4j的驱动库,同时这里必须是py2neo版本必须是最新版4，不然会报连接数据库的错误，老版本不兼容的问题）</p> </li> <li> <p>Java8：这里由于neo4j 数据库是依赖于java8的。</p> </li> <li> <p><a href="[ftp://neo4j.55555.io/neo4j-chs/3.5.14/](ftp://neo4j.55555.io/neo4j-chs/3.5.14/)">Neo4j_3.5.14</a>：这里由于neo4j 在中国地区下载慢，并且neo4j3.X版本才支持java8，到4.0版本就是需要java11了。</p> </li> <li> <p><a href="[ftp://neo4j.55555.io/neo4j-desktop/1.2.4/](ftp://neo4j.55555.io/neo4j-desktop/1.2.4/)">Neo4j_Desktop</a>：neo4j的桌面端（可以远程数据库和连接本地数据库，同时包含很多额外的扩展）</p> </li> </ul> <h3 id="二-连接本地图数据库">二. 连接本地图数据库</h3> <blockquote> <p>py2neo V4 官方文档：https://py2neo.org/v4/index.html</p> </blockquote> <p>Neo4j 一共有3种连接方式：</p> <ul> <li>Bolt：bolt://localhost:11005</li> <li>HTTP：http://localhost:11006</li> <li>HTTPS：https://localhost:11007</li> </ul> <p>这里可以通过Neo4j Desktop来查看新建的图数据库（同时设置密码）</p> <h4 id="21-neo4j数据库语法cypher">2.1 Neo4j数据库语法Cypher</h4> <ul> <li>创建 <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>create (:Movie {title:"ABC",released:2016}) return p; </code></pre></div> </div> </li> <li>查询</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>match (p: Person) return p; 查询Person类型的所有数据 match (p: Person {name:"sun"}) return p; 查询名字等于sun的人 match( p1: Person {name:"sun"} )-[rel:friend]-&gt;(p2) return p2.name , p2.age 查询sun的朋友的名字和年龄 match (old) ... create (new) create (old)-[rel:dr]-&gt;(new)...<a class="read-more" href="./Neo4j%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%9B%BE%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95%E7%BB%93%E5%90%88.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="机器学习" class="hidden tag-master">
		<h1>机器学习</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html">知识图谱的小结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-12-25T08:00:00+08:00">December 25, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-定义">一. 定义</h3> <p>知识图谱是一种二元的图网络，用以描述客观世界中的实体信息及其相互关系规律的知识化体系。它的基本组成单元包括：</p> <ul> <li>实体-关系-实体</li> <li>实体-属性-属性值</li> </ul> <h3 id="二-知识图谱的构建">二. 知识图谱的构建</h3> <h4 id="21-知识建模">2.1 知识建模</h4> <p>对于构建知识图谱的时候，一般我们都是针对所在的特定领域进行建模，所以一般称为“本体建模”或者“领域建模”。</p> <p>这里构建本体模型一般分为3类技术：</p> <ul> <li>RDF：Resource Description Framework，即资源描述框架。采用“资源-属性-属性值”的“主谓宾”结构（或称三元组），提供一种框架容器，并通过XML定义了一套形式化的方法，为机器语义理解的结构基础。</li> <li>RDFS：RDFS是RDF的一个扩展，它提供了一些基本的类和属性，以及它们之间的关系。</li> <li>OWL：Web Ontology Language，Web本体语言，它是基于RDF和RDFS的一种更加丰富的知识表示语言。在OWL中，我们可以定义类、属性以及它们的约束和关系。此外，OWL还支持对知识的推理。</li> </ul> <h4 id="22-知识获取">2.2 知识获取</h4> <p>构建好需要的本体模型后，那么就需要把数据构建成对应的模型的输入了。我们知识的来源基本分为以下几类：</p> <ul> <li>私有数据 <ul> <li>企业的文档</li> <li>企业私有的用户数据</li> <li>企业私有的非结构化数据</li> </ul> </li> <li>公有数据 <ul> <li>新闻</li> <li>百科</li> <li>公有语料</li> </ul> </li> </ul> <p>那么对于一些上述这些数据拆分为两大类，来进行<strong>数据处理</strong>：</p> <ul> <li>非结构化数据：一般指的是无任何标识的文本，我们可以采用相关的NLP算法，比如实体识别和关系抽取（或者直接使用事件抽取，这里事件抽取可以参考我之前写的一篇博客）来构建实体关系的三元组。</li> <li>结构化数据：由于本身就是标准化的数据，我们只需要通过D2R服务器将数据库的内容转成RDF的形式。</li> </ul> <h4 id="23-知识融合">2.3 知识融合</h4> <blockquote> <p>知识融合是将不同来源的知识整合到一起的过程，用以解决知识的冲突和重复。</p> </blockquote> <p>以下是基于知识融合步骤：</p> <ol> <li>实体识别和链接：首先需要识别出不同数据源的相同实体，并将其链接。比如这里的“Tesla”和“特斯拉”应该识别并链接为同一实体。</li> <li>重复实体的合并：可以基于文本相似度来将不同数据源的重复实体进行合并</li> <li>关系融合：识别并合并描述相同实体之间的关系。</li> </ol> <h4 id="24-知识存储">2.4 知识存储</h4> <p>一般来说，会将知识利用图的形式进行存储，因此，我们需要将抽取的实体关系构建成图的形式：</p> <ul> <li>图的节点：实体</li> <li>图的边：关系</li> </ul> <p>图的存储一般使用的是Neo4j图数据库，据说其图的搜索的性能比mysql快1000倍！</p> <h4 id="25-知识计算">2.5 知识计算</h4> <blockquote> <p>知识计算是基于已构建的知识图谱进行能力输出的过程，它以图谱质量提升、潜在关系挖掘与补全、知识统计与知识推理作为主要研究内容。</p> </blockquote> <p>基于图论的相关挖掘算法：</p> <ul> <li>图匹配</li> <li>图查询</li> <li>频繁子图</li> <li>图聚类</li> </ul> <p>知识推理是指从知识库中已有的实体关系数据出发，进行计算机推理，建立实体间的新关联，从而拓展和丰富知识网络。以下是基于知识推理的计算方法：</p> <ul> <li>JENA：最常见的OWL推理工具是Jena，Jena2支持基于规则的简单推理，它的推理机制支持将推理器（inference reasoners）导入Jena，创建模型时将推理器与模型关联以实现推理。</li> <li>JESS：使用规则引擎进行推理，同 大多数专家系统工具一样，Jess的核心也是由事实库、规则库、推理机三大部分组成，并采用产生式规则作为基本的知识表达模式。</li> <li>ProLog：Prolog作为一种声明式逻辑编程语言，非常适合用于实现专家系统中的知识表示和推理。专家系统通过模拟人类专家的知识和决策过程来解决特定领域的复杂问题。在专家系统中，知识通常以事实（facts）和规则（rules）的形式表示，而Prolog的逻辑声明特性使得它成为实现专家系统的理想选择。</li> <li>DataLog:是一种基于逻辑的编程语言。它是一阶谓词逻辑中Horn子句逻辑的一种受限形式，只允许变量或常量作为谓词的自变元，不允许函数作为谓词的自变元。Datalog的语句由事实和规则组成，同Prolog一样，它可以实现对知识库的演绎推理，即可以从已知事实中根据跟着推理得到新的事实。</li> </ul> <h3 id="三-知识图谱的应用">三. 知识图谱的应用</h3> <h4 id="31-安防领域">3.1 安防领域</h4> <p>对于传销组织而言，其实其特征信息是潜藏在通话网络中，我们可以利用构建通话网络的图谱，利用子图识别和匹配的挖掘手段找到十分特殊的传销子图。</p>...<a class="read-more" href="./%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B0%8F%E7%BB%93.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html">写专利心得</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-08T08:00:00+08:00">November 8, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h2 id="写专利心得">写专利心得</h2> <blockquote> <p>最近2个月一口气写了9篇专利，近些年加起来也写了近20篇AI算法类专利了，所以想写点自己对于写专利的一些心得体会。</p> </blockquote> <h3 id="一-专利相关知识">一. 专利相关知识</h3> <h4 id="11-专利是什么">1.1 专利是什么</h4> <p>专利是专利权的简称，主要分为发明、实用新型及工业设计三种类型：</p> <ul> <li> <p>发明：产品、方法及其改进的技术方案</p> </li> <li> <p>使用新型：产品的形状、结构或其结合的技术方案</p> </li> <li> <p>外观设计：产品外部形状、图案、色彩及其组合，如外包装。</p> </li> </ul> <h4 id="12-专利申请流程">1.2 专利申请流程</h4> <ul> <li> <p>想好idea，确保哪些可以写，哪些写不了</p> </li> <li> <p>利用专利检索的工具（比如google学术），查看别人是否写过</p> </li> <li> <p>写交底书（简写）</p> </li> <li> <p>第三方机构代理人撰写</p> </li> <li> <p>专利递交专利局</p> </li> <li> <p>官方受理、初审、公开、实审</p> </li> <li> <p>官方授权</p> </li> <li> <p>专利维持</p> </li> </ul> <h4 id="13-写专利好处">1.3 写专利好处</h4> <ul> <li> <p>拓展和发散思维</p> </li> <li> <p>锻炼文笔</p> </li> <li> <p>了解当前行业已有的技术</p> </li> </ul> <p>其实说了这么多，还是因为写专利可以<strong>赚钱</strong>啦！</p> <h3 id="二-专利挖掘-算法类">二. 专利挖掘-算法类</h3> <p>对于算法工程师而言，其实写发明类专利还是很简单的。个人感觉就和写小论文差不太多，甚至于比写小论文还简单，因为写专利其实可以不需要数据支持，只需要把自己的解决方案写出来就好了！</p> <h4 id="21-创新点">2.1 创新点</h4> <ul> <li> <p>专利审查时判断创造性的逻辑，是用你的方案和现有的技术比对，看有哪些区别点，然后判断在现有技术的基础上，做出这些区别点的改变得到你的方案是否是容易想到的，有没有一些难度。</p> </li> <li> <p>如果都是一些常规的方案，并且应用到我们这里也没什么难度的话，创造性高度就比较低，如果并不是简单的能运用到我们的方案，需要做一些相应的技术难点的解决的话，创新性就比较好。</p> </li> </ul> <h4 id="22-可写的几类算法专利">2.2 可写的几类算法专利</h4> <ul> <li> <p>改进发明：这里最好详尽描述下现有技术，当前改进的技术</p> <ul> <li> <p>改进的数据处理</p> </li> <li> <p>改进的数据挖掘</p> </li> <li> <p>改进的数据标注</p> </li> <li> <p>改进的模型结构</p>...<a class="read-more" href="./%E5%86%99%E4%B8%93%E5%88%A9%E5%BF%83%E5%BE%97.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html">pyspark使用总结-第二篇</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2024-11-07T08:00:00+08:00">November 7, 2024</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-常见的oom">一. 常见的OOM</h3> <h4 id="11-常用的解决方案">1.1 常用的解决方案</h4> <p>我们在使用spark的时候，经常在save数据的时候，都会遇到内存溢出的问题，这通常是由于数据量过大导致的。以下是一些可能的解决方案：</p> <ol> <li>增加分区数：如果数据集非常大，可以尝试增加分区数。可以使用<code class="language-plaintext highlighter-rouge">repartition()</code>或<code class="language-plaintext highlighter-rouge">coalesce()</code>函数来增加分区数。增加分区数可以将数据均匀地分布在更多的节点上，从而减少每个节点上的内存压力。</li> <li>压缩数据：如果数据集包含大量重复的值，可以考虑使用压缩算法来减少内存使用。Pyspark提供了多种压缩算法，如Snappy、Gzip等。可以使用<code class="language-plaintext highlighter-rouge">option("compression", "snappy")</code>来设置压缩算法。</li> <li>增加集群资源：可以考虑增加集群资源。可以增加集群的节点数或增加每个节点的内存。可以通过调整<code class="language-plaintext highlighter-rouge">spark.driver.memory</code>和<code class="language-plaintext highlighter-rouge">spark.executor.memory</code>参数来增加内存分配，特别对于driver而言，最好把内存设置大一些。</li> </ol> <h4 id="12-代码方面的优化">1.2 代码方面的优化</h4> <p>如果以上常用的解决方案依旧无法解决OOM的问题，那么我们可能需要考虑是否需要优化pyspark的代码了</p> <ul> <li>UDF过于复杂：尽可能将结果拆分不同的列，然后再用简单的udf来组合这些列进行计算。</li> <li>多用filter算子：提前将大量数据剔除</li> <li>多用select算子：只保留需要的列，减少内存的使用</li> <li>尽量少用collect、count算子：像这些action算子基本都会把executor的数据全部加载回driver上，导致driver的内存吃紧。</li> <li>当发现在某个udf环节只有一个节点在跑的时候，可以使用.cache()来分布式跑任务。</li> </ul> <h4 id="13-数据倾斜导致的oom和心跳时间超时">1.3 数据倾斜导致的OOM和心跳时间超时</h4> <p>通常我们会发现有些时候，数据本身并没有很大，但是要运行很长时间，而且最终还因为heart beat时间过长或则oom而失败。</p> <p><strong>发生</strong> 数据倾斜一般发生在：</p> <ul> <li>join两个df的时候</li> <li>groupby某一列，然后这一列（包含了a，b，c等元素）中，很不巧，a有非常多（1000），而b和c等元素仅有2个</li> </ul> <p><strong>验证</strong> 这时候我们可以直接通过yarn日志中的shuffer resize/records看到很多excutors中会发现极个别失败的excutor的size非常大（10w个），而其他的excutor的size可能只有10个。那么这个时候无疑是发生数据倾斜了。</p> <p><strong>解决</strong> 这里推荐使用<strong>加盐</strong>处理，比什么加excutor的内存和核数更加有效</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">df1</span> <span class="o">=</span> <span class="n">df1</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">salted_a</span><span class="sh">"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">lit</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span...<a class="read-more" href="./pyspark%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="深度学习" class="hidden tag-master">
		<h1>深度学习</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./raft.html">大模型基于检索增强的微调-RAFT</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-11-27T08:00:00+08:00">November 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-raft简单介绍">一. RAFT简单介绍</h3> <blockquote> <p>论文：<a href="https://arxiv.org/abs/2403.10131">《RAFT: Adapting Language Model to Domain Specific RAG》</a></p> <h4 id="11-raft的优势">1.1 RAFT的优势</h4> <p>RAFT其实是基于RAG（检索增强）的SFT（有监督微调），那么他和这两者的差异是什么呢？</p> </blockquote> <ol> <li>RAG：检索增强是基于提出的问题在向量数据库中检索相应的片段，然后作为线索合并问题喂给大模型，然后输出。然后这里会出现一个问题：<strong>模型对于特定领域的知识没有得到提前学习的机会，说白了就是给了大模型很多材料，但是无法非常有效的使用这些材料</strong>。</li> <li>SFT：有监督微调是基于提供特定的QA对的方式来喂给大模型，然后能够让大模型额外扩充知识面的方式。但是这也会存在一个问题：<strong>这些QA对更多的是让大模型增加了额外文档的记忆，而忽略了在回答实际问题时使用文档的机会，要么没有正确处理在寻找合适的文档来学习时出现的错误</strong>。</li> <li>RAFT：基于检索增强的微调则是结合RAG+SFT提出的一种新的微调方案。他的优势： <ul> <li>过微调确保模型在特定领域的知识上得到良好的记忆和训练，从而达到对不准确的检索文档进行发现。</li> <li>通过训练模型来将“理解问题”、“检索知识”和“正确答案”进行关联，从而提高达模型回答的准确性。</li> </ul> </li> </ol> <p>这也就是整片文章中一致强调的RAFT其实是一种“开卷考试” + “特定领域的提前学习”。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft.png" alt="raft" /></p> <h4 id="12-raft如何训练">1.2 RAFT如何训练</h4> <p>区别于常规的SFT，RAFT在训练中加入了干扰的文档 + 正确的文档让模型来学习。<strong>这使得模型学习到的是基于记忆和文档的混合判断</strong>，参考论文中的“which is a mixture of both memorization and reading”。</p> <ul> <li>训练的内容分为2块： <ul> <li>找到核心依据：QA对 + 标准答案的文档 + 多个误导的文档 + 思维链</li> <li>正确的例子：QA对 + 标准答案的文档 + 思维链</li> </ul> </li> <li>训练的核心：通过思维链来解释找到的答案，从而基于上下文信息，思考其答案，并链接到相关文档。</li> </ul> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/raft_train.png" alt="raft_train" /></p> <h3 id="二-基于unsloth和lamma_index来实现faft">二. 基于unsloth和lamma_index来实现FAFT</h3> <h4 id="21-基于ollama和lamma_index来构建数据集">2.1 基于ollama和lamma_index来构建数据集</h4> <p>RAFT的数据集的特点是：</p> <ul> <li>QA对</li> <li>正确文档</li> <li>错误文档</li> <li>思维链</li> </ul> <p>所以我们需要一个能够提供思维链的大模型，帮助我们生成上述这些内容。</p> <ul> <li>模型：Qwen3-32B，选择这个千问模型是因为中文很友好+支持思维链+阿里的预训练的数据很顶</li> <li>调用框架：ollama，调用比如openai需要花钱，这个本地部署，调用不花钱！</li> </ul> <h4 id="22-安装相关依赖">2.2 安装相关依赖</h4> <p>这里需要使用以下几个深度学习相关的框架：</p> <ul> <li>lamma_index: 和langchain感觉很像，只是这个更加偏重于增强大型语言模型 (LLM) 处理广泛和异构数据集的能力。当然也能帮助我们构建raft数据集咯。</li> <li>unsloth:...<a class="read-more" href="./raft.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./graphrag.html">大模型的检索增强-NanoGraphRAG</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-06-09T08:00:00+08:00">June 9, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        less than 1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-rag和graphrag">一. RAG和GraphRAG</h3> <h4 id="11-什么是rag">1.1 什么是RAG</h4> <blockquote> <p>RAG（Retrieval Augmented Generation，检索增强生成）是一种将信息检索技术与生成式语言模型（LLM）结合的AI框架。它通过从外部知识库中检索相关信息，然后使用这些信息增强LLM的提示词（prompt），从而生成更准确、更相关、更全面的答案。﻿</p> </blockquote> <p>大模型为什么需要RAG：</p> <ul> <li>如果一个llm在pretrain之后没有做rag（外部检索）的话，其实往往可能存在幻觉。</li> <li>基座模型在专业领域知识不足，比如一些医药、法律等。</li> <li>外挂知识需要长期实时维护更新的。</li> </ul> <h4 id="12-rag在llm中langchain的例子">1.2 RAG在LLM中LangChain的例子</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/rag_lanchain.jpg" alt="LangChain" /> 如上图所示，整个RAG的过程分为三个部分：</p> <ul> <li>文本嵌入阶段：将本地文本进行分段后，利用embedding模型对其每个段落进行词嵌入，并将其vector存入向量数据库（比如FAISS、Chroma）中。</li> <li>请求阶段：对大模型进行请求之前，会将请求的文本同样利用embedding模型转成向量，然后会和向量数据库中比对相似度最高的本地文本段落，并将其作为关联的文本段放到prompt中。</li> <li>输出阶段：将提示词 + 本地文本关联段落 + 请求一起输入大模型，得到输出。</li> </ul> <h4 id="13-graphrag的定义及其优势">1.3 GraphRAG的定义及其优势</h4> <blockquote> <p>GraphRAG是一种基于知识图谱的检索增强技术，通过构建图模型的知识表达，将实体和关系之间的联系用图的形式进行展示，然后利用大语言模型LLM进行检索增强。 论文：<a href="https://arxiv.org/abs/2404.16130">From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a></p> </blockquote> <p>GraphRAG比RAG优势在哪：</p> <ul> <li>RAG过于局限：RAG仅能检索到与query相速度最高的文本片段，无法从全局出发来看整个本地文本。</li> <li>GraphRAG通过构建实体关系图谱实现了信息间的连接，能从全局出发，能更完整地理解和检索复杂的关联信息，从而生成更准确和全局性的结果。</li> </ul> <h4 id="14-graphrag的流程">1.4 GraphRAG的流程</h4> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/graphrag.png" alt="LangChain" /> 如上图所示，就是GraphRAG的处理流程图，其实总结起来就两个部分： 第一部分：构建知识图谱</p> <ul> <li>将本地文本进行分段</li> <li>对每个段落进行摘要提取：这里完全依赖于<strong>大模型的提取能力</strong></li> <li>实体和关系的提取：这里完全依赖于<strong>大模型的提取能力</strong>，实体和关系抽取可以参考本人之前写的《事件抽取实战》这篇文章</li> <li>构建知识图谱，写入数据库</li> </ul> <p>第二部分：利用构建的知识图谱回答问题</p> <ul> <li>社区检测：实际就是一种图聚类的方法，这里的“社区”，我们可以将其理解为一类具有相同特性的节点的集合。</li> <li>社区总结：给每个社区创建类似报告的摘要。利于理解整体的结构和语义。</li> <li>生成全局答案：给定用户查询，基于上一步生成的社区摘要可用于在多阶段过程中生成最终答案。</li> </ul> <h3 id="二-graphrag的轻量版本nano-graphrag">二. GraphRAG的轻量版本——nano-GraphRAG</h3> <p>对于GraphRAG而言，其封装的太死，代码量又很大，对于定制化的任务而言，不太好下手，因此推荐一个轻量化的版本——nano-GraphRAG。</p> <blockquote> <p>代码：https://github.com/gusye1234/nano-graphrag</p> </blockquote> <p>相较于GraphRAG的优势：</p> <ul> <li>代码量少：包含了tests + prompt也才只有1100行代码！</li> <li>更容易阅读</li> <li>给的例子太好用了，直接上手没有难度。</li> </ul> <h4 id="21-安装">2.1 安装</h4> <p>这里推荐不用官方推荐的pip install 来安装。因为这样会对于代码和prompt不好调整。 直接clone项目即可，然后安装其依赖<code...<a class="read-more" href="./graphrag.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html">大模型的微调和推理加速</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2025-05-27T08:00:00+08:00">May 27, 2025</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-大模型微调">一. 大模型微调</h3> <h4 id="11-微调的原因">1.1 微调的原因</h4> <p>在业务中直接使用大模型，往往会发现：</p> <ul> <li>模型对prompt非常敏感，需要不断调整，迭代prompt的过程很痛苦</li> <li>本身能力不满足独有的业务需求</li> <li>模型的更新/更换 导致相同的prompt却拿到不同的结果</li> </ul> <h4 id="12-微调的方式">1.2 微调的方式</h4> <ul> <li>zero-shot prompting（0样本）：撰写prompt，迭代prompt，获取答案。无需数据，无需额外开发、部署成本。</li> <li>few-shot prompting（1-10样本）：收集样例，迭代样例，获取答案。需要提供少量的样本（正反例）。</li> <li>adaptation（1k-1w样本）：收集数据，适配模型，部署模型。 <ul> <li>适用百亿参数以下的模型</li> <li>少量的适配特殊场景/任务的样本，这里其实可以利用更大参数、更优的大模型输出的结果来训练这类“小模型”</li> </ul> </li> <li>更深层次的微调： <ul> <li>领域预训练：用无监督领域数据继续训练基座模型</li> <li>全参数精调：用有监督领域数据精调基座模型</li> <li>检索增强：外挂知识库，这里比如一般的RAG，还有比较火热的GraphRAG。</li> <li>多智能体：多模型/agent共同完成任务。</li> </ul> </li> </ul> <h3 id="二-llm微调工具-unsloth">二. LLM微调工具-Unsloth</h3> <blockquote> <p>git地址：https://github.com/unslothai/unsloth</p> </blockquote> <p>选择unsloth作为微调工具的理由：</p> <ul> <li>训练更快</li> <li>显存占用更少</li> <li>迭代快，模型适配广，目前都能支持Qwen3了</li> </ul> <h4 id="21-依赖的安装">2.1 依赖的安装</h4> <blockquote> <p>这里爬了不少坑，因此记录下</p> </blockquote> <ol> <li>直接pip安装：<code class="language-plaintext highlighter-rouge">pip install unsloth</code>, 这里会默认安装最新的torch版本，而非适配于自身系统cuda版本的torch（用<code class="language-plaintext highlighter-rouge">nvcc -V</code>可查看cuda版本）</li> <li>重新安装torch，本人这里cuda是12.1的：<code class="language-plaintext highlighter-rouge">pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121</code></li> <li>重新安装对应cuda版本的xformers：<code class="language-plaintext highlighter-rouge">pip install -U xformers --index-url https://download.pytorch.org/whl/cu121</code></li> <li>如果需要微调Qwen3，那么对于transformers有版本要求：<code class="language-plaintext highlighter-rouge">pip install transformers==4.51.0 --no-deps</code></li> <li>改了transformers之后，那么也需要对应的trl版本更改：<code class="language-plaintext highlighter-rouge">pip install trl==0.17.0 --no-deps</code></li> <li>安装vllm:<code class="language-plaintext highlighter-rouge">pip install vllm==0.7 --no-deps</code></li> <li>这里会遇到unsloth和vllm版本不匹配的问题：<code...<a class="read-more" href="./%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83%E5%92%8C%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="爬虫" class="hidden tag-master">
		<h1>爬虫</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html">Selenium和webscraper爬虫</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2022-12-24T08:00:00+08:00">December 24, 2022</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        1 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-selenium爬虫">一. Selenium爬虫</h3> <h4 id="1-安装">1. 安装</h4> <blockquote> <p>Selenium 本身是一个自动化测试的工具，模拟人为在浏览器上进行操作，比如点击和下拉等等。</p> </blockquote> <p>安装的环境：</p> <ul> <li>python环境</li> <li>pip安装Selenium包：<code class="language-plaintext highlighter-rouge">pip install selenium</code></li> <li>chrome浏览器驱动：去<a href="https://chromedriver.chromium.org/downloads">官网</a>下载自己电脑已安装的浏览器所在的版本驱动</li> </ul> <p>我这边的chrome驱动装的是mac版本的，这里需要将其路径放到mac的环境变量中，下载后放到了<code class="language-plaintext highlighter-rouge">/usr/local/chromedriver</code>，</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim ~/.profile export PATH="$PATH:/usr/local/chromedriver" source ~/.profile </code></pre></div></div> <p>可以在控制台打<code class="language-plaintext highlighter-rouge">chromedriver</code>测试是否ok。</p> <h4 id="2-使用">2. 使用</h4> <blockquote> <p>这里的例子是的主要任务是：将给的头条url所在的公众号遍历其30条的文章标题和链接。</p> </blockquote> <p>所以我们需要拆解为2步：</p> <ul> <li>打开给定的url，并点击头条的公众号。</li> <li>另开一个页面，找到公众号下前30条文章的标题和链接（这里需要下拉才能看到后面的文章）。</li> </ul> <p>第一步：实例一个浏览器驱动，并找到公众号的XPath（这里推荐一个测试XPath的<strong>浏览器插件XPath Helper</strong>）</p> <pre><code class="language-python3">driver = webdriver.Chrome() driver.get(url) time.sleep(2) try: name = driver.find_element(By.XPATH,".//div[@class='article-meta']/span[@class='name']/a").get_attribute('href') except: driver.quit() driver.find_element(By.XPATH,".//div[@class='article-meta']/span[@class='name']/a").click() </code></pre> <p>由于点击了公众号后会出现一个新的页面，这里最好指定下现在的driver是归属于哪个页面的，不然写的xpath就会找不到元素。</p> <pre><code class="language-python3">list_windows = driver.window_handles print(list_windows) driver.close() driver.switch_to.window(list_windows[1]) #list_windows 存储了上一步中获取的窗口 time.sleep(2) # 防止页面还未加载完全 </code></pre> <p>第二步：找到所有的页面的文章（这里需要下拉才可以获取）</p> <pre><code class="language-python3"> data = [] titles = set() last_position = driver.execute_script("return window.pageYOffset;") # 执行下拉操作 scrolling = True count = 0...<a class="read-more" href="./Selenium%E5%92%8Cwebscraper%E7%88%AC%E8%99%AB.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

	
	<div id="面试" class="hidden tag-master">
		<h1>面试</h1>
		<div class="archive">
			<div class="post-list">
		    
			

				<div class="post">
					<a class="post-list-title" href="./%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html">面试基础总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-12-13T05:11:00+08:00">December 13, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        4 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<h3 id="一-操作系统">一. 操作系统</h3> <h4 id="11-并行和并发">1.1 并行和并发</h4> <p><strong>并发</strong>：在操作系统中，某一时间段，几个程序在同一个CPU上运行，但在任意一个时间点上，只有一个程序在CPU上运行。</p> <p><strong>并行</strong>：当操作系统有多个CPU时，一个CPU处理A线程，另一个CPU处理B线程，<strong>两个线程互相不抢占CPU资源，可以同时进行</strong>，这种方式成为并行。</p> <p>知乎的例子：</p> <ul> <li>你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。</li> <li>你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。</li> <li>你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。</li> </ul> <h4 id="12-进程和线程">1.2 进程和线程</h4> <h5 id="121-进程">1.2.1 进程</h5> <p>​ <strong>进程是资源分配的基本单位，理解为一个程序</strong>。所以我们一般都要求进程池的进程数小于等于CPU的核心数。</p> <p>​ 如果问<strong>单核CPU能否运行多进程？</strong>答案又是肯定的。单核CPU也可以运行多进程，只不过不是同时的，而是极快地在<strong>进程间来回切换实现的多进程</strong>。进<strong>程拥有自己的地址空间，全局变量，文件描述符，各种硬件等等资源</strong>。</p> <h5 id="122-线程">1.2.2 线程</h5> <p>​ <strong>线程</strong>：线程是依赖于进程的。<strong>如果说进程和进程之间相当于程序与程序之间的关系，那么线程与线程之间就相当于程序内的任务和任务之间的关系。</strong></p> <p>​ 一个程序内包含了多种任务。加上了线程之后，线程能够共享进程的大部分资源，并参与CPU的调度。意味着它能够在<strong>进程间进行切换，实现并发</strong>。</p> <h5 id="123-为什么要用多进程适用条件">1.2.3 为什么要用多进程，适用条件</h5> <p>​ 总是在运行一个进程上的任务，就会出现一个现象。就是任务不一定总是在执行 ”计算型“ 的任务，会有很大可能是在执行网络调用，阻塞了，CPU 岂不就浪费了？</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_1.jpg" alt="" /></p> <p>因此，多进程适用于<strong>CPU密集型任务(各种循环处理、计算等等)</strong>。多线程适用于<strong>IO密集型任务(文件处理、网络爬虫等)</strong>。</p> <h5 id="124-多进程通信">1.2.4 多进程通信</h5> <p><strong>管道pipe</strong>：管道是一种<strong>半双工</strong>的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指<strong>父子进程关系</strong>。类似于python的<code class="language-plaintext highlighter-rouge">multiprocessing.Pipe()</code></p> <p><strong>消息队列MessageQueue</strong>：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。类似于python的<code class="language-plaintext highlighter-rouge">multiprocessing.Queue()</code></p> <p><strong>共享存储SharedMemory</strong>：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。<strong>共享内存是最快的 IPC 方式</strong>，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。</p> <h5 id="125-python的多线程是真的多线程么">1.2.5 python的多线程是真的多线程么</h5> <p>​ Python在设计之初就考虑要在主循环中，同时只有一个线程在执行，就像单CPU的系统中运行多个进程那样，内存中可以存放多个程序，但任意时刻，只有一个程序在CPU中运行。同样地，虽然Python解释器可以运行多个线程，只有一个线程在解释器中运行。</p> <p>​ Python虚拟机的访问由<strong>全局解释器锁（GIL）</strong>来控制，正是这个锁能保证同时只有一个线程在运行。</p> <p><strong>Python的多进程多线程测试</strong>：</p> <ul> <li> <p>在一个4核CPU上开4线程，发现电脑的CPU利用率没有占满，大致相当于单核水平。</p> </li> <li> <p>在一个4核CPU上开4进程，发现CPU直接飙到了100%，说明进程是可以利用多核的！</p> <p>Python多线程相当于单核多线程，多线程有两个好处：<strong>CPU并行，IO并行</strong>，单核多线程相当于自断一臂。所以，在Python中，可以使用多线程，但不要指望能有效利用多核。</p> </li> </ul> <h5 id="126-多线程如何保证线程安全">1.2.6 多线程如何保证线程安全</h5> <p>当<strong>多个线程同时操作同一个共享全局变量</strong>的时候，就容易出现线程安全问题，线程安全问题只会影响到线程对同一个共享的全局变量的<strong>写操作</strong>。</p> <p>利用<strong>线程锁</strong>来保证同一个时刻，有且仅有一个线程对共享的全局变量进行写操作。且开始写操作前，需要<strong>加锁</strong>，完成后，需要<strong>解锁</strong>，让其他线程再对其进行写操作。</p> <h5 id="127-死锁问题">1.2.7 死锁问题</h5> <p>​ <strong>死锁</strong>是指两个或两个以上的进程（线程）在执行过程中，由于竞争资源或者由于<strong>彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去</strong>。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（线程）称为死锁进程（线程）。</p> <p><img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/interv_2.jpg" alt="" /></p> <p>死锁的<strong>4个必要条件</strong>：</p> <ul> <li>互斥条件：线程(进程)对于所分配到的资源具有排它性，即<strong>一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放</strong>。</li> <li>请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，<strong>对已获得的资源保持不放</strong>。</li> <li>不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，<strong>只有自己使用完毕后才释放资源</strong>。</li> <li>循环等待条件：当发生死锁时，所等待的线程(进程)必定会<strong>形成一个环路（类似于死循环），造成永久阻塞</strong></li> </ul> <p><strong>如何避免死锁？</strong></p> <p>只要破坏产生死锁的四个条件中的其中一个就可以了。</p> <ul> <li><strong>破坏互斥条件</strong>：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。</li> <li><strong>破坏请求与保持条件</strong>：一次性申请所有的资源。</li> <li><strong>破坏不剥夺条件</strong>：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</li>...<a class="read-more" href="./%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93.html"> read more</a>
					</div>
				</div>
			
			

				<div class="post">
					<a class="post-list-title" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html">深度学习算法面试总结</a>
					

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2020-06-12T23:21:00+08:00">June 12, 2020</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        2 minute read
      
    </span>
  
  
  </span>

					<div class="post-excerpt">
						<blockquote> <p>面试官会根据自己简历中提到的一些点进行提问，这里先自己对某些点进行深挖。</p> </blockquote> <h3 id="一数据处理">一.数据处理</h3> <p>海量数据：</p> <ul> <li>（1）数据量太大，无法短时间内处理完成</li> <li>（2）无法一次性将数据放入内存中。</li> </ul> <h4 id="11-缺失值处理">1.1 缺失值处理</h4> <ul> <li>填充固定值：选取某个固定值/默认值填充缺失值。</li> <li>填充均值：对每一列的缺失值，填充当列的均值。</li> <li>填充中位数：对每一列的缺失值，填充当列的中位数。</li> <li>填充众数：对每一列的缺失值，填充当列的众数。由于存在某列缺失值过多，众数为nan的情况，因此这里取的是每列删除掉nan值后的众数。</li> <li>填充上下条的数据：对每一条数据的缺失值，填充其上下条数据的值。</li> <li>填充插值得到的数据：用插值法拟合出缺失的数据，然后进行填充。插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。</li> </ul> <h3 id="二机器学习">二.机器学习</h3> <h4 id="21--svm和lr的区别与联系">2.1 SVM和LR的区别与联系？</h4> <p>SVM 和 LR 都是属于分类算法，不过 SVM 是通过划分超平面的方法来进行分类，而 LR 则是通过计算样本属于哪个类别的概率，从而达到分类效果</p> <h4 id="22--交叉熵函数系列问题与最大似然函数的关系和区别">2.2 交叉熵函数系列问题？与最大似然函数的关系和区别？</h4> <p>在二分类中，交叉熵函数和负最大似然函数的表达式是相同的，但是交叉熵函数是从信息论角度得到的，而最大似然函数则是从概率论角度得到的</p> <p>交叉熵涉及到2点：</p> <ul> <li>信息量：假设X是一个离散型随机变量，其取值集合为X，概率分布函数为p(x)=Pr(X=x),x∈X，我们定义事件X=x0的信息量为： I(x0)=−log(p(x0))，可以理解为，一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设： 事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219 事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014 可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。</li> <li>熵：假设小明的考试结果是一个0-1分布XA只有两个取值{0：不及格，1：及格}，在某次考试结果公布前，小明的考试结果有多大的不确定度呢？你肯定会说：十有八九不及格！因为根据先验知识，小明及格的概率仅有0.1,90%的可能都是不及格的。怎么来度量这个不确定度？求期望！不错，我们对所有可能结果带来的额外信息量求取均值（期望），其结果不就能够衡量出小明考试成绩的不确定度了吗。<strong>熵其实是信息量的期望值，它是一个随机变量的确定性的度量。熵越大，变量的取值越不确定，反之就越确定。</strong></li> <li>相对熵：称为<strong>KL散度</strong>，是两个随机分布间距离的度量。越小说明分布越一致。</li> <li>交叉熵：交叉熵与KL距离在行为上是等价的，都反映了分布p，q的相似程度。特别的，在logistic regression中， p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p)X∼B(1,p) q:待估计的模型，服从参数为q的0-1分布，即X∼B(1,q)两者的交叉熵为</li> </ul> <h4 id="23-svm的核函数">2.3 SVM的核函数</h4> <p>使用非线性核的支持向量机可以处理线性不可分的问题。通过核函数，支持向量机可以将特征向量映射到更高维的空间中，使得原本线性不可分的数据在映射之后的空间中变得线性可分，如下图所示，原本二维空间的线性不可分（异或问题）转成三维空间，就可以线性可分了。 <img src="https://raw.githubusercontent.com/yy2lyx/picgo/admin/img/int_1.jpg" alt="" /></p> <p>常用的核函数：线性核、多项式核、高斯核（RBF）、拉普拉斯核等等。核函数的选择其实才是SVM模型的最大变数。</p> <h4 id="24-l1和l2范数">2.4 L1和L2范数</h4> <p>范数的定义： \(\|\mathbf{x}\|_{p}:=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{1 / p}\) L1范数就是p=1,即： \(\|\boldsymbol{x}\|_{1}:=\sum_{i=1}^{n}\left|x_{i}\right|\)</p> <p>L2范数就是p = 2，即: \(\|\boldsymbol{x}\|_{2}:=\sqrt{x_{1}^{2}+\cdots+x_{n}^{2}}\)</p> <p>这里如果需要求解如何使得上述式子最小，无可避免三步走：求导，置零，解方程。因此L2范数计算就比L1范数计算更容易，因此L2范数应用较多。</p> <p>L1 和 L2 范数在机器学习上最主要的应用大概分下面两类：</p> <ul> <li>作为损失函数使用(计算回归问题中需要计算拟合的线和点之间的距离)，这里L1是LAD（最小绝对偏差），L2是最小二乘法</li> <li>作为正则项使用（防止过拟合）也即所谓 L1-regularization 和 L2-regularization：这里就是将x替换成权重w，</li> </ul> <p>这两个正则项最主要的不同，包括两点：如上面提到的，L2 计算起来更方便，而 L1 在特别是非稀疏向量上的计算效率就很低；还有就是 L1 最重要的一个特点，输出稀疏，会把不重要的特征直接置零，而 L2 则不会；最后，如之前多次提过，L2 有唯一解，而 L1 不是。</p> <h4 id="25-决策树">2.5 决策树</h4>...<a class="read-more" href="./%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html"> read more</a>
					</div>
				</div>
			
			</div>
		</div>
	</div>

<style>
.spinner {
  margin: 100px auto;
  width: 50px;
  height: 40px;
  text-align: center;
  font-size: 10px;
}

.spinner > div {
  background-color: var(--accent);
  height: 100%;
  width: 6px;
  display: inline-block;

  -webkit-animation: sk-stretchdelay 1.2s infinite ease-in-out;
  animation: sk-stretchdelay 1.2s infinite ease-in-out;
}

.spinner .rect2 {
  -webkit-animation-delay: -1.1s;
  animation-delay: -1.1s;
}

.spinner .rect3 {
  -webkit-animation-delay: -1.0s;
  animation-delay: -1.0s;
}

.spinner .rect4 {
  -webkit-animation-delay: -0.9s;
  animation-delay: -0.9s;
}

.spinner .rect5 {
  -webkit-animation-delay: -0.8s;
  animation-delay: -0.8s;
}

@-webkit-keyframes sk-stretchdelay {
  0%, 40%, 100% { -webkit-transform: scaleY(0.4) }
  20% { -webkit-transform: scaleY(1.0) }
}

@keyframes sk-stretchdelay {
  0%, 40%, 100% {
    transform: scaleY(0.4);
    -webkit-transform: scaleY(0.4);
  }  20% {
    transform: scaleY(1.0);
    -webkit-transform: scaleY(1.0);
  }
}
</style>
<div class="spinner">
  <div class="rect1"></div>
  <div class="rect2"></div>
  <div class="rect3"></div>
  <div class="rect4"></div>
  <div class="rect5"></div>
</div>




<div class="tag-cloud">
    
        <ul class="tags">
            
                
                <li><a href="./tag.html?tag=CV" class="tag">CV <span>(13)</span></a></li>
            
                
                <li><a href="./tag.html?tag=LLM" class="tag">LLM <span>(5)</span></a></li>
            
                
                <li><a href="./tag.html?tag=NLP" class="tag">NLP <span>(11)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E4%BB%A3%E7%A0%81" class="tag">代码 <span>(16)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E5%8D%9A%E5%AE%A2" class="tag">博客 <span>(3)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E5%9B%BE%E7%AE%97%E6%B3%95" class="tag">图算法 <span>(2)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" class="tag">机器学习 <span>(9)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="tag">深度学习 <span>(25)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E7%88%AC%E8%99%AB" class="tag">爬虫 <span>(1)</span></a></li>
            
                
                <li><a href="./tag.html?tag=%E9%9D%A2%E8%AF%95" class="tag">面试 <span>(2)</span></a></li>
            
    
        </ul>
</div>
  <div class="search-box">
  <div class="wrapper">
    <div class="search-grid">
      <form class="search-form">
        <div id="search-container">
          <input type="text" id="search-input" class="search" placeholder="Search">
        </div>
      </form>
      <ul id="results-container" class="results-search"></ul>
      <div class="icon-close-container">
        <span class="search-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
      </div>
    </div>
  </div>
</div>

  <div class="pagination clearfix">
  
  
</div>

  </div> <!-- End Wrapper -->
  




<footer class="main-footer">
    <div class="footer-wrapper">
        <div class="logo-symbol">
            <a class="logo-link" title="凡人炼丹传" href="./">
                <svg width="45px" height="45px" class="logo-symbol" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid meet" version="1.0" viewBox="0 0 649 649"><g fill="currentColor" stroke="none"><path d="M2938 6380 c-551 -53 -1031 -220 -1478 -514 -306 -201 -588 -470 -810 -771 -276 -374 -475 -850 -559 -1336 -64 -371 -53 -836 29 -1211 155 -712 552 -1347 1130 -1810 450 -360 1021 -589 1640 -659 58 -6 202 -12 320 -12 282 0 503 26 756 87 902 220 1680 841 2079 1661 303 622 402 1333 279 2005 -90 496 -313 984 -634 1390 -111 140 -378 404 -519 513 -456 352 -957 560 -1549 643 -126 17 -558 26 -684 14z m687 -220 c77 -11 189 -32 250 -46 127 -29 345 -94 345 -103 0 -4 -341 -188 -757 -409 l-757 -403 -41 22 c-22 13 -58 26 -79 29 l-40 5 -148 370 c-82 204 -150 377 -153 386 -10 29 325 119 570 153 169 24 174 24 430 21 183 -3 273 -8 380 -25z m-1292 -546 l157 -387 -24 -28 c-13 -16 -30 -44 -36 -64 -6 -19 -17 -35 -23 -35 -7 -1 -382 -54 -834 -119 -453 -64 -823 -115 -823 -111 0 3 43 62 95 132 269 358 584 630 980 844 90 49 321 153 341 154 6 0 81 -174 167 -386z m2026 347 l37 -20 129 -440 128 -440 -35 -39 c-20 -22 -37 -44 -39 -50 -3 -8 -290 13 -929 66 -775 65 -925 80 -928 92 -2 11 223 134 785 432 433 228 794 416 801 417 7 0 30 -8 51 -18z m204 -92 c420 -211 850 -600 1137 -1027 34 -51 60 -95 57 -98 -4 -4 -805 157 -859 172 -10 3 -18 12 -18 21 0 58 -78 133 -137 133 -18 0 -33 2 -33 5 0 3 -52 184 -116 403 -63 218 -117 405 -120 415 -3 9 -3 17 1 17 3 0 42 -19 88 -41z m-913 -894 c494 -41 904 -75 912 -75 7 -1 24 -23 36 -51 l24 -50 -169 -269 -168 -270 -44 0 c-24 0 -63 -9 -86 -21 l-42 -21 -679 402 c-373 222 -688 409 -699 416 -18 13 -18 14 -1 14 10 0 422 -34 916 -75z m-1175 18 l48 -48 -31 -225 c-18 -124 -60 -417 -94 -652 l-62 -428 -44 0 c-24 0 -51 -4 -61 -10 -16 -8 -146 87 -777 566 -418 317 -761 578 -763 580 -3 3 0 9 5 14 8 8 1633 247 1700 249 25 1 42 -9 79 -46z m915 -414 l690 -411 0 -38 0 -37 -147 -46 c-82 -26 -453 -148 -825 -271 l-676 -223 -22 30 -22 29 98 669 c82 557 101 669 114 669 8 0 31 9 50 19 19 11 38 20 43 20 4 1 318 -184 697 -410z m1959 175 c251 -53 457 -97 457 -98 9 -9 123 -247 153 -320 113 -272 189 -599 209 -901 l9 -130 -231 -273 c-224 -265 -232 -273 -264 -270 l-34 3 -418 1013 -419 1013 26 30 c15 16 33 29 41 29 8 0 220 -43 471 -96z m-593 2 c6 -5 804 -1949 802 -1952 -2 -2 -274 272 -605 609 l-600 612 13 32 c20 46 17 82 -9 128 l-23 41 170 271 171 272 40 -6 c22 -3 41 -6 41 -7z m-3341 -611 c402 -307 733 -561 737 -564 31 -26 -38 -31 -947 -65 -516 -19 -941 -33 -944 -30 -2 2 6 77 18 165 49 346 162 693 324 986 44 82 52 91 66 79 9 -7 345 -264 746 -571z m2710 -142 c17 -16 39 -32 48 -38 15 -9 13 -64 -23 -695 -22 -377 -40 -686 -40 -687 0 -2 -8 -3 -19 -3 -10 0 -30 -9 -45 -21 l-27 -21 -342 200 c-188 110 -542 317 -787 460 -245 144 -445 266 -445 273 0 8 312 116 820 285 451 150 822 272 824 273 2 1 18 -11 36 -26z m590 -425 c220 -222 500 -505 623 -629 l223 -225 -17 -31 -18 -30 -585 -82 c-322 -45 -602 -85 -621 -88 -31 -4 -37 -1 -53 27 -11 17 -34 39 -53 47 -19 9 -34 21 -34 27 -1 6 16 316 37 688 l37 678 26 9 c14 5 27 10 30 10 3 1 185 -180 405 -401z m-2587 -114 c-2 -9 -224 -178 -494 -375 l-492 -359 -38 16 c-26 11 -53 14 -84 10 -25 -3 -55 -7 -67 -8 -16 -2 -106 76 -362 316 -204 192 -341 327 -341 338 0 16 10 18 83 19 45 0 431 13 857 28 984 36 942 35 938 15z m59 -88 l22 -23 -104 -467 c-58 -256 -105 -468 -105 -470 0 -2 -14 -6 -32 -10 -17 -3 -47 -18 -65 -32 l-34 -26 -339 122 -338 122 -7 45 c-5 37 -3 47 12 58 10 7 229 169 488 359 258 190 472 346 475 346 3 0 15 -11 27 -24z m1013 -430 c421 -245 769 -452 775 -460 5 -8 7 -18 3 -21 -3 -4 -417 -41 -920 -84 l-913 -77 -16 26 c-9 15 -29 36 -45 47 l-28 21 104 465 105 465 43 7 c27 4 55 17 75 35 18 16 37 28 42 26 6 -2 354 -204 775 -450z m-2307 -276 c-7 -71 -4 -98 10 -126 l15 -30 -206 -248 -206 -248 -27 59 c-140 314 -228 733 -229 1086 l0 138 323 -303 c270 -254 322 -307 320 -328z m5277 366 c-17 -270 -58 -489 -135 -721 -38 -117 -134 -350 -140 -343 -1 2 -35 117 -75 256 l-72 253 26 25 c51 52 58 134 15 189 -21 26 -21 26 -2 48 11 12 102 120 203 240 100 120 184 216 186 214 2 -2 -1 -74 -6 -161z m-642 -487 l21 -41 -456 -782 c-251 -429 -461 -787 -467 -794 -9 -9 -19 -10 -42 -2 l-29 10 -174 676 -174 675 35 37 c20 20 40 51 45 67 l10 30 584 82 c321 44 594 82 605 82 16 1 27 -10 42 -40z m-4015 -145 c301 -109 327 -120 327 -142 0 -12 7 -39 15 -58 l15 -36 -411 -469 c-226 -259 -413 -468 -415 -466 -2 2 1 219 6 483 5 263 10 538 10 610 l0 132 29 12 c16 6 39 23 52 36 13 14 28 23 34 21 5 -2 157 -57 338 -123z m-517 -413 c-3 -262 -9 -527 -12 -589 -8 -134 -2 -135 -120 20 -93 121 -192 278 -272 428 l-61 115 215 257 c181 216 218 255 235 251 l22 -6 -7 -476z m4695 460 c3 -3 43 -133 88 -289 l82 -282 -62 -108 c-75 -130 -175 -278 -265 -392 -140 -176 -514 -528 -595 -558 -13 -5 -72 -13 -130 -17 l-105 -7 -16 40 -16 40 462 796 461 796 45 -6 c25 -4 48 -9 51 -13z m-1736 -69 c-6 -5 -361 -192 -790 -417 -429 -224 -806 -422 -838 -439 -52 -28 -59 -29 -70 -15 -17 22 -78 59 -99 59 -19 0 -16 -14 -68 300 -29 169 -38 246 -30 248 27 9 62 50 74 87 11 32 19 41 43 44 67 8 1683 139 1733 140 30 0 50 -3 45 -7z m90 -62 c10 -11 38 -26 62 -31 38 -10 44 -16 52 -48 90 -346 333 -1280 337 -1292 3 -11 -7 -23 -29 -36 -19 -11 -42 -38 -53 -60 l-19 -40 -1050 297 c-859 244 -1050 301 -1050 315 0 12 239 141 860 465 473 247 863 449 866 449 3 1 14 -8 24 -19z m-2076 -210 c13 0 21 -9 25 -27 10 -47 86 -497 86 -508 0 -5 -13 -19 -29 -29 -35 -24 -57 -59 -66 -108 -4 -22 -14 -39 -24 -42 -143 -41 -861 -236 -870 -236 -7 0 -11 5 -9 11 2 6 190 224 418 484 349 399 416 472 431 464 10 -5 27 -9 38 -9z m1376 -1065 c741 -208 1053 -300 1060 -312 6 -9 24 -32 41 -52 l31 -35 -30 -68 c-34 -77 -25 -71 -205 -139 -310 -116 -653 -180 -984 -183 -97 0 -178 1 -181 4 -89 106 -817 1053 -817 1063 0 18 9 27 23 21 7 -2 485 -137 1062 -299z m-1319 264 c31 -35 81 -51 134 -44 l46 6 380 -487 c208 -268 385 -496 392 -506 13 -17 10 -18 -45 -12 -640 65 -1267 346 -1732 776 l-61 57 42 12 c271 74 805 218 814 218 6 1 19 -9 30 -20z m2814 -563 c0 -5 -223 -138 -278 -165 -24 -13 -46 -20 -49 -18 -2 3 3 19 11 36 12 22 27 33 59 42 27 7 56 26 81 52 35 37 44 41 105 47 36 4 67 8 69 9 1 0 2 -1 2 -3z" transform="translate(0.000000,644.000000) scale(0.100000,-0.100000)"/></g></svg>
            </a>
        </div>
        <div class="copyright">
          <p>2026 &copy; 李小肥的YY</p>
        </div>
        <div class="footer-nav">
            <div>
                <a href="./archive.html">
                    文章
                </a>
            </div>
            <div>
                <a href="./tags.html">
                    标签
                </a>
            </div>
            <div>
                <a href="./about.html">
                    关于
                </a>
            </div>
        </div>
    </div>
</footer> <!-- End Footer -->

</div>

    <div class="top" title="Top">
      <svg aria-hidden="true" focusable="false" data-prefix="fal" data-icon="angle-up" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="svg-inline--fa fa-angle-up fa-w-8 fa-2x"><path fill="currentColor" d="M136.5 185.1l116 117.8c4.7 4.7 4.7 12.3 0 17l-7.1 7.1c-4.7 4.7-12.3 4.7-17 0L128 224.7 27.6 326.9c-4.7 4.7-12.3 4.7-17 0l-7.1-7.1c-4.7-4.7-4.7-12.3 0-17l116-117.8c4.7-4.6 12.3-4.6 17 .1z" class=""></path></svg>
    </div>
    




<!-- JS -->








<script>
(function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var logo = document.getElementById('logo');
    var nightModeOption = ('auto' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
    storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
    var data = storage.getItem('theme');
    try {
        data = JSON.parse(data ? data : '');
    } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
    }
    return data;
    }

    function handleThemeToggle(nightShift) {
    themeData.nightShift = nightShift;
    saveThemeData(themeData);
    html.dataset.theme = nightShift ? 'dark' : 'light';
    if (nightShift) {
        logo.setAttribute("src", "./assets/img/branding/MVM-logo-full-dark.svg");
    } else {
        logo.setAttribute("src", "./assets/img/branding/MVM-logo-full.svg");
    }
    setTimeout(function() {
        sw.checked = nightShift ? true : false;
    }, 50);
    }

    function autoThemeToggle() {
    // Next time point of theme toggle
    var now = new Date();
    var toggleAt = new Date();
    var hours = now.getHours();
    var nightShift = hours >= 19 || hours <=7;

    if (nightShift) {
        if (hours > 7) {
        toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
    } else {
        toggleAt.setHours(19);
    }

    toggleAt.setMinutes(0);
    toggleAt.setSeconds(0);
    toggleAt.setMilliseconds(0)

    var delay = toggleAt.getTime() - now.getTime();

    // auto toggle theme mode
    setTimeout(function() {
        handleThemeToggle(!nightShift);
    }, delay);

    return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
    };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
    handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
    var data = autoThemeToggle();

    // Toggle theme by local setting
    if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
    } else {
        handleThemeToggle(themeData.nightShift);
    }
    } else if (nightModeOption == 'manual') {
    handleThemeToggle(themeData.nightShift);
    } else {
    var nightShift = themeData.nightShift;
    if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
    }
    handleThemeToggle(nightShift);
    }
})();
</script>

<script src="./assets/js/jekyll-search.js"></script>
<script src="./assets/js/jquery-3.6.0.min.js"></script>







<script src="./assets/js/main.js"></script>
<script>
  SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('results-container'),
      json: './search.json',
      searchResultTemplate: '<li><a href="{url}" title="{description}">{title}</a><p>{description}</p></li>',
      noResultsText: 'No results found',
      fuzzy: false,
      exclude: ['Welcome']
    });
</script>


  <script src="./assets/js/infinite-jekyll.js"></script>



    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-R8SZS2YBZK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-R8SZS2YBZK');
</script>
  </body>
</html>
